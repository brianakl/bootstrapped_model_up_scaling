{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
    "from datasets import load_dataset\n",
    "import tqdm\n",
    "from transformers import GPT2TokenizerFast, BertTokenizerFast\n",
    "import re\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "from bus_nGPT import Decoder, TransformerLayer, AttentionHead, Rotary\n",
    "import tensorboard as tb\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "with open('base_512_fullrun.csv', 'r') as csvfile:\n",
    "    csvreader = csv.reader(csvfile)\n",
    "    next(csvreader)  # Skip header if present\n",
    "    for row in csvreader:\n",
    "        x.append(float(row[1]))  # Assuming x is in the first column\n",
    "        y.append(float(row[2]))  # Assuming y is in the second column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(x, y):\n",
    "    q1 = np.percentile(y, 25)\n",
    "    q3 = np.percentile(y, 75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - (1.5 * iqr)\n",
    "    upper_bound = q3 + (1.5 * iqr)\n",
    "    \n",
    "    mask = (y >= lower_bound) & (y <= upper_bound)\n",
    "    return np.array(x)[mask], np.array(y)[mask]\n",
    "\n",
    "x_clean, y_clean = remove_outliers(x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 100.0,\n",
       " 200.0,\n",
       " 300.0,\n",
       " 400.0,\n",
       " 500.0,\n",
       " 600.0,\n",
       " 700.0,\n",
       " 800.0,\n",
       " 900.0,\n",
       " 1000.0,\n",
       " 1100.0,\n",
       " 1200.0,\n",
       " 1300.0,\n",
       " 1400.0,\n",
       " 1500.0,\n",
       " 1600.0,\n",
       " 1700.0,\n",
       " 1800.0,\n",
       " 1900.0,\n",
       " 2000.0,\n",
       " 2100.0,\n",
       " 2200.0,\n",
       " 2300.0,\n",
       " 2400.0,\n",
       " 2500.0,\n",
       " 2600.0,\n",
       " 2700.0,\n",
       " 2800.0,\n",
       " 2900.0,\n",
       " 3000.0,\n",
       " 3100.0,\n",
       " 3200.0,\n",
       " 3300.0,\n",
       " 3400.0,\n",
       " 3500.0,\n",
       " 3600.0,\n",
       " 3700.0,\n",
       " 3800.0,\n",
       " 3900.0,\n",
       " 4000.0,\n",
       " 4100.0,\n",
       " 4200.0,\n",
       " 4300.0,\n",
       " 4400.0,\n",
       " 4500.0,\n",
       " 4600.0,\n",
       " 4700.0,\n",
       " 4800.0,\n",
       " 4900.0,\n",
       " 5000.0]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 200.,  300.,  400.,  500.,  600.,  700.,  800.,  900., 1000.,\n",
       "       1100., 1200., 1300., 1400., 1500., 1600., 1700., 1800., 1900.,\n",
       "       2000., 2100., 2200., 2300., 2400., 2500., 2600., 2700., 2800.,\n",
       "       2900., 3000., 3100., 3200., 3300., 3400., 3500., 3600., 3700.,\n",
       "       3800., 3900., 4000., 4100., 4200., 4300., 4400., 4500., 4600.,\n",
       "       4700., 4800., 4900., 5000.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.79791975, 5.71323061, 5.62147951, 5.58574152, 5.49655199,\n",
       "       5.46772575, 5.43948555, 5.42493868, 5.35012341, 5.31858444,\n",
       "       5.33466625, 5.28206825, 5.23734426, 5.22355175, 5.12709284,\n",
       "       5.13072968, 5.12743235, 5.09644651, 5.05150127, 5.02279711,\n",
       "       5.02692032, 4.96997356, 4.99134827, 4.98092365, 4.92580414,\n",
       "       4.91517115, 4.87730026, 4.85464954, 4.83703852, 4.85167789,\n",
       "       4.77732038, 4.81324863, 4.77854919, 4.80211639, 4.78536224,\n",
       "       4.72053003, 4.74282742, 4.73101807, 4.69938421, 4.70304871,\n",
       "       4.72219181, 4.70531654, 4.75033283, 4.73621702, 4.69918728,\n",
       "       4.68260193, 4.6792655 , 4.71579123, 4.68376923])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAIjCAYAAAA0vUuxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAACEIElEQVR4nOzdd3gUVRsF8DNbspveeycJSQi9h96RXpSuIIpYUKQoivoJiIIICoiKiAUbojQFFaX33msKkBASUkknPXu/P2JW1gSShSSbTc7vefYhO3N35p3kbtiTuXNHEkIIEBERERER0T3JDF0AERERERFRbcfgREREREREVAEGJyIiIiIiogowOBEREREREVWAwYmIiIiIiKgCDE5EREREREQVYHAiIiIiIiKqAIMTERERERFRBRiciIiIiIiIKsDgREREVW7NmjWQJAnR0dHVvq/o6GhIkoQ1a9ZU+77qMx8fHzz55JMP9FpJkjB37twqredh/fXXX2jevDnUajUkSUJ6erqhSyKiWo7BiagOKv3QevfDyckJ3bt3x7Zt23Taln7oXLJkSbnbWrJkSZkPwBqNBt999x3atWsHOzs7WFpaomHDhhg/fjyOHj1a5cdz/vx5TJw4Eb6+vlCr1bCwsEDz5s0xa9YsXL9+Xaftk08+qXPcVlZWaNasGT788EPk5+drj7cyj5r40K+PgoICLF++HC1atICVlRVsbGwQEhKCyZMnIywsTNvu8OHDmDt3Lj8IVoGtW7di0KBBcHZ2homJCezs7NClSxd8+OGHyMzM1Gnr4+NT5j3XuXNnbN68GUD578vyHj4+PvesZ+/evdp2P/zwQ7ltOnbsCEmS0Lhx4yr7PtSE/7435XI5vLy8MGzYMJw9e7ZK93X79m2MHDkSpqam+PTTT/H999/D3Ny8SvdBRHWPwtAFEFH1eeedd+Dr6wshBBITE7FmzRr0798fW7duxcCBAx94u1OnTsWnn36KIUOGYNy4cVAoFAgPD8e2bdvQoEEDtG/fvsqOYfXq1Xj++efh4OCAcePGISgoCEVFRbh48SK+++47LFu2DLm5uZDL5drXqFQqfPnllwCA9PR0bNy4Ea+88gpOnDiBr776Ct9//73OPj788EPExsZi6dKlOssdHR2r7DiqwqOPPopt27ZhzJgxeOaZZ1BYWIiwsDD8/vvv6NChA4KCggCUBKd58+bhySefhI2NjWGLNlIajQZPP/001qxZgyZNmuCFF16Ap6cnsrKycOTIEbz11lv4888/sWvXLp3XNW/eHDNnzgQA3Lp1C6tWrcLw4cOxcuVK9OnTp0zfmzRpEtq2bYvJkydrl1lYWFRYn1qtxtq1a/H444/rLI+Ojsbhw4ehVqsf9NANbsyYMejfvz+Ki4tx5coVrFy5Etu2bcPRo0fRvHnzKtnHiRMnkJWVhfnz56NXr15Vsk0iqgcEEdU533zzjQAgTpw4obM8NTVVKJVKMXbsWO2yqKgoAUAsXry43G0tXrxYABBRUVFCCCESEhKEJEnimWeeKdNWo9GIxMTEKjuOQ4cOCblcLrp06SIyMzPLrM/NzRVvvfWWKCoq0i6bMGGCMDc312lXXFwsWrduLQCIuLi4MtsZMGCA8Pb2rrK6q8Px48cFAPHee++VWVdUVCRSUlK0z//7MzOE0j5YVTXcuXPnnutK+/A333xTJfsSQoiFCxcKAGL69OlCo9GUWX/r1i3x/vvv6yzz9vYWAwYM0FkWHx8vzM3NRcOGDcvdj7m5uZgwYUKl69qzZ48AIIYPHy4UCoVITk7WWf/ee+8JZ2dn0alTJxESElLp7VaGt7e3XrXeDYCYM2fOfdvc63fRli1bBAAxefLkB9r33bKzs4UQQnz77bfl/o6sim0TUd3FoXpE9YiNjQ1MTU2hUDz4yeaoqCgIIdCxY8cy60qHJ93P3UMDv/jiC/j5+UGlUqFNmzY4ceKETtt58+ZBkiT8+OOPsLS0LLMttVqN+fPn65xtKo9MJkO3bt20+38YhYWFsLOzw8SJE8usy8zMhFqtxiuvvKJdtmLFCoSEhMDMzAy2trZo3bo11q5dq/d+r127BgDlft/lcjns7e0BAHPnzsWrr74KAPD19S0z7PCbb75Bjx494OTkBJVKhUaNGmHlypVltunj44OBAwfi4MGDaNu2LdRqNRo0aIDvvvuuTNtLly6hR48eMDU1hYeHB959911oNJoy7X777TcMGDAAbm5uUKlU8PPzw/z581FcXKzTrlu3bmjcuDFOnTqFLl26wMzMDG+88QaAkjOITz75JKytrWFjY4MJEyZUekhi6VC5Q4cOYcaMGXB0dIS5uTmGDRuG5ORkbbucnBwsWrQIISEhWLx4MSRJKrMtV1dXvPbaaxXu08XFBcHBwYiKiqpUjZU1ZMgQqFQqrF+/Xmf52rVrMXLkyHLfE0VFRZg/f772Pefj44M33ngD+fn5Ou2EEHj33Xfh4eEBMzMzdO/eHZcuXSq3jvT0dEybNg2enp5QqVTw9/fHokWLyv35P6gePXoAgM738NixY3jkkUdgbW0NMzMzdO3aFYcOHdJ53dy5cyFJEi5fvoyxY8fC1tYWnTp1Qrdu3TBhwgQAQJs2bSBJks61W+vXr0erVq1gamoKBwcHPP7444iLi9PZ9pNPPgkLCwtcu3YN/fv3h6WlJcaNGweg5Pfgiy++iPXr16NRo0YwNTVFaGgoLly4AABYtWoV/P39oVar0a1btzK/kw4cOIARI0bAy8sLKpUKnp6emD59OnJzc8utIS4uDkOHDoWFhQUcHR3xyiuvlHlPaTQaLF++HE2aNIFarYajoyMeeeQRnDx5UqfdDz/8oD12Ozs7jB49Gjdv3qzMj4moXuBQPaI6LCMjAykpKRBCICkpCStWrEB2dnaZ4T368Pb2BlDy4WLEiBEwMzN7oO2sXbsWWVlZePbZZyFJEj744AMMHz4c169fh1KpRE5ODnbv3o1u3brBw8PjgestVRo8SgPGg1IqlRg2bBg2bdqEVatWwcTERLvu119/RX5+PkaPHg2gZJjh1KlT8dhjj+Hll19GXl4ezp8/j2PHjmHs2LF67bf0+/7jjz+iY8eO9wy/w4cPR0REBH766ScsXboUDg4OAP4ddrhy5UqEhIRg8ODBUCgU2Lp1K1544QVoNBpMmTJFZ1tXr17FY489hqeffhoTJkzA119/jSeffBKtWrVCSEgIACAhIQHdu3dHUVERXn/9dZibm+OLL76AqalpmdrWrFkDCwsLzJgxAxYWFti9ezfefvttZGZmYvHixTptb9++jX79+mH06NF4/PHH4ezsDCEEhgwZgoMHD+K5555DcHAwNm/erP0QXFkvvfQSbG1tMWfOHERHR2PZsmV48cUX8fPPPwMADh48iPT0dLzyyisVhvKKFBYW4ubNmw/d7/7LzMwMQ4YMwU8//YTnn38eAHDu3DlcunQJX375Jc6fP1/mNZMmTcK3336Lxx57DDNnzsSxY8ewcOFCXLlyRXsdFgC8/fbbePfdd9G/f3/0798fp0+fRp8+fVBQUKCzvZycHHTt2hVxcXF49tln4eXlhcOHD2P27NmIj4/HsmXLquRY//ve3b17N/r164dWrVphzpw5kMlk2j8IHDhwAG3bttV5/YgRIxAQEIAFCxZACIGAgAAEBgbiiy++0A5n9vPzA1DSRydOnIg2bdpg4cKFSExMxPLly3Ho0CGcOXNGZ+hrUVER+vbti06dOmHJkiU6vwsPHDiALVu2aN9TCxcuxMCBAzFr1ix89tlneOGFF5CWloYPPvgATz31FHbv3q197fr165GTk4Pnn38e9vb2OH78OFasWIHY2NgyQbm4uBh9+/ZFu3btsGTJEuzcuRMffvgh/Pz8tP0CgHbYab9+/TBp0iQUFRXhwIEDOHr0KFq3bg0AeO+99/C///0PI0eOxKRJk5CcnIwVK1agS5cuZY6dqN4y6PkuIqoWpcOk/vtQqVRizZo1Om31HaonhBDjx48XAIStra0YNmyYWLJkibhy5Uqlaivdn729vUhNTdUu/+233wQAsXXrViGEEOfOnRMAxLRp08ps4/bt2yI5OVn7yM/P164rHapXuu7q1atiwYIFQpIk0bRp03Jr0neo3t9//61Ta6n+/fuLBg0aaJ8PGTKkyoZLaTQa0bVrVwFAODs7izFjxohPP/1U3Lhxo0zb+w3Vy8nJKbOsb9++OnULUTIsC4DYv3+/dllSUpJQqVRi5syZ2mXTpk0TAMSxY8d02llbW5epobx9P/vss8LMzEzk5eVpl5Ue5+eff67T9tdffxUAxAcffKBdVlRUJDp37lypoXql74tevXrpDL+bPn26kMvlIj09XQghxPLlywUA8euvv+q8vqioSKffJScn62zH29tb9OnTR7vu3LlzYvTo0QKAeOmll8qt6UGH6q1fv178/vvvQpIkERMTI4QQ4tVXX9X+HLt27arT986ePSsAiEmTJuls75VXXhEAxO7du4UQJT87ExMTMWDAAJ1je+ONNwQAnVrnz58vzM3NRUREhM42X3/9dSGXy7V1CaHfUL158+aJ5ORkkZCQIPbu3StatGghAIiNGzcKjUYjAgICRN++fXXqy8nJEb6+vqJ3797aZXPmzBEAxJgxY8rsq7zhzAUFBcLJyUk0btxY5Obmapf//vvvAoB4++23tcsmTJggAIjXX3+9zLZLf9fe3fdXrVolAAgXFxedYcezZ8+u1Ptk4cKFQpIknfd7aQ3vvPOOTtsWLVqIVq1aaZ/v3r1bABBTp04ts93S72F0dLSQy+VlhgJfuHBBKBSKcocIE9VHHKpHVId9+umn2LFjB3bs2IEffvgB3bt3x6RJk7Bp06aH2u4333yDTz75BL6+vti8eTNeeeUVBAcHo2fPnmWGtNzLqFGjYGtrq33euXNnANDOklc6Y1l5F8o3aNAAjo6O2seWLVt01t+5c0e7zt/fH2+88QZCQ0N1/qr+MHr06AEHBwftGQoASEtLw44dOzBq1CjtMhsbG8TGxpYZgvggJEnC33//jXfffRe2trb46aefMGXKFHh7e2PUqFGVHq5295mg0jOSXbt2xfXr15GRkaHTtlGjRtqfC1By1iowMFBnJsM///wT7du31/krv6Ojo3bY0r32nZWVhZSUFHTu3Bk5OTk6swICJRN8/Hc45J9//gmFQqHzl3S5XI6XXnqpUsdeavLkyTrD7zp37ozi4mLcuHEDwL373oULF3T6naOjI27fvq3TZvv27dp1zZo1w/r16/HEE09g0aJFetVYGX369IGdnR3WrVsHIQTWrVuHMWPGlNv2zz//BADMmDFDZ3npRBZ//PEHAGDnzp0oKCjASy+9pPM9mjZtWpltrl+/Hp07d4atrS1SUlK0j169eqG4uBj79+9/oOOaM2cOHB0d4eLigm7duuHatWtYtGgRhg8fjrNnzyIyMhJjx47F7du3tfu8c+cOevbsif3795cZJvjcc89Var8nT55EUlISXnjhBZ3JNQYMGICgoCDt9+hud/fFu/Xs2VNndsR27doBKJng5e5hx6XL735P3f0+uXPnDlJSUtChQwcIIXDmzJky+/rv8XXu3Flnexs3boQkSZgzZ06Z15b+jDdt2gSNRoORI0fq/CxdXFwQEBCAPXv2lHucRPUNh+oR1WFt27bVDsMASmaratGiBV588UUMHDhQZ5hZRe7+ECWTyTBlyhRMmTIFt2/fxqFDh/D5559j27ZtGD16NA4cOFDh9ry8vHSel4aotLQ0ANB+uMjOzi7z2t9++w2FhYU4d+6czvVEpdRqNbZu3Qqg5AO4r69vlQz3K6VQKPDoo49i7dq1yM/Ph0qlwqZNm1BYWKgTnF577TXs3LkTbdu2hb+/P/r06YOxY8eWe51SZahUKrz55pt48803ER8fj3379mH58uX45ZdfoFQq7zk99d0OHTqEOXPm4MiRI8jJydFZl5GRAWtra+3z//6MgJKfU+nPCABu3Lih/fB3t8DAwDLLLl26hLfeegu7d+8uM5X3f0Obu7t7mf5548YNuLq6lgk05e3rfh607/n7+2PHjh0AgO+++67MDHlAyQfhd999F5IkwczMDMHBwdU2xEmpVGLEiBFYu3Yt2rZti5s3b95zCOiNGzcgk8ng7++vs9zFxQU2Njba0Fj6b0BAgE47R0dHnT90AEBkZCTOnz9/z9knk5KSHui4Jk+ejBEjRkAmk2mn3FepVNp9Arjv8MyMjAydWn19fSu139JjL68/BQUF4eDBgzrLFArFPX+v/LePlb6vPD09y11+93sqJiYGb7/9NrZs2aKzHCj7Pim9Xulu/32PXrt2DW5ubrCzsyu3VqDk+yr+GcZYHqVSec/XEtUnDE5E9YhMJkP37t2xfPlyREZGIiQkRPuX1f9eeFyq9MP1vaY3tre3x+DBgzF48GB069YN+/btw40bN7TX5NzLva4dEUIAKPmQqlAocPHixTJtunbtCgD3vM5HLpdX+xTDo0ePxqpVq7Bt2zYMHToUv/zyC4KCgtCsWTNtm+DgYISHh+P333/HX3/9hY0bN+Kzzz7D22+/jXnz5j3U/l1dXTF69Gg8+uijCAkJwS+//II1a9bcd+KPa9euoWfPnggKCsJHH30ET09PmJiY4M8//8TSpUvL/KW+op+RPtLT09G1a1dYWVnhnXfegZ+fH9RqNU6fPo3XXnutzL7Lu0aqqlR0XKXTul+8eBFDhgzRrrewsND2q/9+iC7l4OBQo9Nbjx07Fp9//jnmzp2LZs2aoVGjRvdtX95EFw9Ko9Ggd+/emDVrVrnrGzZs+EDbDQgIuOf3sLSfLF68+J5Tk/83WFdXX1KpVJDJyh+4c68+VlHfKy4uRu/evZGamorXXnsNQUFBMDc3R1xcHJ588slKv0f1pdFoIEkStm3bVu42KzNFPlF9wOBEVM8UFRUB+Pev6Y6OjjAzM0N4eHi57cPDw2FmZqadZOB+WrdujX379iE+Pr7C4FQRc3NzbRCLi4uDu7v7Q22vqnXp0gWurq74+eef0alTJ+zevRtvvvlmmXbm5uYYNWoURo0ahYKCAgwfPhzvvfceZs+eXSX32lEqlWjatCkiIyO1Q2vu9eF469atyM/Px5YtW3T+Iv4ww3C8vb21ZwHu9t/+tHfvXty+fRubNm1Cly5dtMv1mW3O29sbu3btQnZ2ts4HuXv13QfVuXNnWFtbY926dZg9e/Y9PxzXBp06dYKXlxf27t173+GA3t7e0Gg0iIyMRHBwsHZ5YmIi0tPTte/X0n8jIyPRoEEDbbvk5OQyZz/8/PyQnZ1do0GxdBIHKyurKt9v6bGHh4drZ/IrFR4e/tC/0yrjwoULiIiIwLfffovx48drl5ee6XwQfn5++Pvvv5GamnrPs05+fn4QQsDX1/eBAy9RfVB7/zcgoipXWFiI7du3w8TERPvhSS6Xo0+fPti6dStiYmJ02sfExGDr1q3o06eP9q+QCQkJuHz5cpltFxQUYNeuXeUOB3pQb7/9NoqLi/H444+XO2TvQc58VBWZTIbHHnsMW7duxffff4+ioiKdYXoAylz/YmJigkaNGkEIgcLCQgDQXt+TkpJy3/1FRkaW+fkAJWdyjhw5AltbW+2QHXNzc+26u5X+DO/+vmVkZOCbb76pxBGXr3///jh69CiOHz+uXZacnIwff/yxwn0XFBTgs88+02tfRUVFOtOnFxcXY8WKFQ9afrnMzMwwa9YsXLx4Ea+//nq5/cyQfe9ukiTh448/xpw5c/DEE0/cs13//v0BoMxMdx999BGAkut4AKBXr15QKpVYsWKFzjGWN0PeyJEjceTIEfz9999l1qWnp2v/SFOVWrVqBT8/PyxZsqTc3wl3Tyuvr9atW8PJyQmff/65zhTt27Ztw5UrV7Tfo+pU3vtECIHly5c/8DYfffRRCCHKPctdup/hw4dDLpdj3rx5Zfq2EKLM7zKi+opnnIjqsG3btmkvuk9KSsLatWsRGRmJ119/HVZWVtp2CxYsQPv27dGyZUtMnjwZPj4+iI6OxhdffAFJkrBgwQJt29jYWLRt2xY9evRAz5494eLigqSkJPz00084d+4cpk2bVqmzU5XRuXNnfPLJJ3jppZcQEBCAcePGISgoCAUFBYiIiMCPP/4IExMTuLi4VMn+9DVq1CisWLECc+bMQZMmTXT+kg+UXLzv4uKCjh07wtnZGVeuXMEnn3yCAQMGaK+jOX78OLp37445c+Zg7ty599zXuXPnMHbsWPTr1w+dO3eGnZ0d4uLi8O233+LWrVtYtmyZ9kNXq1atAABvvvkmRo8eDaVSiUGDBqFPnz4wMTHBoEGD8OyzzyI7OxurV6+Gk5MT4uPjH+h7MGvWLHz//fd45JFH8PLLL2unI/f29taZErtDhw6wtbXFhAkTMHXqVEiShO+//16vADJo0CB07NgRr7/+OqKjo9GoUSNs2rSpzHUfVeH111/HlStXsHjxYmzfvh2PPvooPDw8kJaWhtOnT2P9+vVwcnKqkrOGD2vIkCE6QwrL06xZM0yYMAFffPGFdtjk8ePH8e2332Lo0KHo3r07AGjvA1Q6fXb//v1x5swZbNu2rcz7+tVXX8WWLVswcOBA7TT1d+7cwYULF7BhwwZER0dX2e+CUjKZDF9++SX69euHkJAQTJw4Ee7u7oiLi8OePXtgZWWlvb5RX0qlEosWLcLEiRPRtWtXjBkzRjsduY+PD6ZPn16lx1KeoKAg+Pn54ZVXXkFcXBysrKywcePGMmf79NG9e3c88cQT+PjjjxEZGYlHHnkEGo0GBw4cQPfu3fHiiy/Cz88P7777LmbPno3o6GgMHToUlpaWiIqKwubNmzF58uRyryclqndqcgo/IqoZ5U1HrlarRfPmzcXKlSt1pvEtdeXKFTFq1Cjh5OQkFAqFcHJyEqNHjy4zzXhmZqZYvny56Nu3r/Dw8BBKpVJYWlqK0NBQsXr16nK3fbf7TX+Oe0xZfObMGTF+/Hjh5eUlTExMhLm5uWjatKmYOXOmuHr1qk7b0unI9aHvdOSlNBqN8PT0FADEu+++W2b9qlWrRJcuXYS9vb1QqVTCz89PvPrqqyIjI0PbpnR66Yqmak5MTBTvv/++6Nq1q3B1dRUKhULY2tqKHj16iA0bNpRpP3/+fOHu7i5kMpnOdMdbtmwRTZs2FWq1Wvj4+IhFixaJr7/+usyUyN7e3mLAgAFlttu1a1fRtWtXnWXnz58XXbt2FWq1Wri7u4v58+eLr776qsw2Dx06JNq3by9MTU2Fm5ubmDVrlnZq9z179ujs417TuN++fVs88cQTwsrKSlhbW4snnnhCnDlzRq/pyO+eglqIf38Gd9dQavPmzaJ///7C0dFRKBQKYWNjIzp16iQWL16snb68ou/Z/TzMdOT3U973sLCwUMybN0/4+voKpVIpPD09xezZs3WmghdCiOLiYjFv3jzh6uoqTE1NRbdu3cTFixeFt7d3mVqzsrLE7Nmzhb+/vzAxMREODg6iQ4cOYsmSJaKgoEDbrjJ9vKJbI9ztzJkzYvjw4dr3lre3txg5cqTYtWuXtk3pdOTJycllXn+vviCEED///LNo0aKFUKlUws7OTowbN07ExsbqtLnf7xkAYsqUKZU6tvJ+npcvXxa9evUSFhYWwsHBQTzzzDPa2zPc3cfvVUPpcd+tqKhILF68WAQFBQkTExPh6Ogo+vXrJ06dOqXTbuPGjaJTp07C3NxcmJubi6CgIDFlyhQRHh5e7rES1TeSELVkvAEREREREVEtxWuciIiIiIiIKsDgREREREREVAEGJyIiIiIiogoYPDjFxcXh8ccfh729PUxNTdGkSROcPHnynu337t0LSZLKPBISEmqwaiIiIiIiqk8MOh15WloaOnbsiO7du2Pbtm1wdHREZGQkbG1tK3xteHi4znTKTk5O1VkqERERERHVYwYNTosWLYKnp6fOzRd9fX0r9VonJyfY2NhUU2VERERERET/Mmhw2rJlC/r27YsRI0Zg3759cHd3xwsvvIBnnnmmwtc2b94c+fn5aNy4MebOnYuOHTuW2y4/P1/nDuAajQapqamwt7eHJElVdixERERERGRchBDIysqCm5sbZLIKrmIy5E2kVCqVUKlUYvbs2eL06dNi1apVQq1WizVr1tzzNWFhYeLzzz8XJ0+eFIcOHRITJ04UCoWizE3cSpXeCI4PPvjggw8++OCDDz744KO8x82bNyvMLga9Aa6JiQlat26Nw4cPa5dNnToVJ06cwJEjRyq9na5du8LLywvff/99mXX/PeOUkZEBLy8vREVFwdLS8uEO4CEVFhZiz5496N69O5RKZaVe88qG89gVloLZjwRgZGvPaq6QapsH6TNUv7HPkL7YZ0hf7DOkr9rUZ7KysuDr64v09HRYW1vft61Bh+q5urqiUaNGOsuCg4OxceNGvbbTtm1bHDx4sNx1KpUKKpWqzHI7OzudySUMobCwEGZmZrC3t690pzG3tIZMlQNTC2vY29tXc4VU2zxIn6H6jX2G9MU+Q/pinyF91aY+U7r/ylzCY9DpyDt27Ijw8HCdZREREfD29tZrO2fPnoWrq2tVllZryWUlP9QijcFOFBIRERER1TsGPeM0ffp0dOjQAQsWLMDIkSNx/PhxfPHFF/jiiy+0bWbPno24uDh89913AIBly5bB19cXISEhyMvLw5dffondu3dj+/bthjqMGlUanDSGG2FJRERERFTvGDQ4tWnTBps3b8bs2bPxzjvvwNfXF8uWLcO4ceO0beLj4xETE6N9XlBQgJkzZyIuLg5mZmZo2rQpdu7cie7duxviEGqcXOIZJyIiIiKimmbQ4AQAAwcOxMCBA++5fs2aNTrPZ82ahVmzZlVzVbWXQv7PGScGJyIiIiKiGmPQa5xIfzKecSIiIiIiqnEMTkZGe40TgxMRERERUY1hcDIynFWPiIiIiKjmMTgZmdLJIYo5qx4RERERUY1hcDIyck4OQURERERU4xicjAynIyciIiIiqnkMTkZGwckhiIiIiIhqHIOTkZFxcggiIiIiohrH4GRktGecODkEEREREVGNYXAyMtozTsUMTkRERERENYXBychwOnIiIiIioprH4GRkSm+AW8xrnIiIiIiIagyDk5FhcCIiIiIiqnkMTkaGk0MQEREREdU8Bicjw8khiIiIiIhqHoOTkeEZJyIiIiKimsfgZGRkEm+AS0RERERU0xicjIxCzskhiIiIiIhqGoOTkSk948TgRERERERUcxicjAynIyciIiIiqnkMTkZGweBERERERFTjGJyMjHaoHmfVIyIiIiKqMQxORqZ0cggNzzgREREREdUYBicjw+nIiYiIiIhqHoOTkVHISn5kvMaJiIiIiKjmMDgZmX9yE4MTEREREVENYnAyMtozTpwcgoiIiIioxjA4GRk5zzgREREREdU4Bicjo52OnMGJiIiIiKjGMDgZGU4OQURERERU8xicjAwnhyAiIiIiqnkMTkaGZ5yIiIiIiGoeg5OR0U4OwVn1iIiIiIhqDIOTkZHzjBMRERERUY1jcDIycs6qR0RERERU4xicjIxczuBERERERFTTGJyMDM84ERERERHVPAYnIyPj5BBERERERDWOwcnIlE5HLgSg4VknIiIiIqIaweBkZEqH6gE860REREREVFMYnIxM6eQQAK9zIiIiIiKqKQxORkbnjBODExERERFRjWBwMjJyGYfqERERERHVNAYnI6MTnIoZnIiIiIiIagKDk5G5KzfxjBMRERERUQ1hcDIykiRpzzrxGiciIiIioprB4GSESieIYHAiIiIiIqoZDE5GiGeciIiIiIhqFoOTEWJwIiIiIiKqWQxORqg0OBUxOBERERER1QgGJyNUGpw0nFWPiIiIiKhGMDgZIQ7VIyIiIiKqWQxORoiz6hERERER1SwGJyPEM05ERERERDWLwckIcXIIIiIiIqKaxeBkhDg5BBERERFRzWJwMkLaM07FDE5ERERERDWBwckIlU4OwTNOREREREQ1g8HJCPEaJyIiIiKimsXgZIS01zgxOBERERER1QgGJyPEM05ERERERDWLwckI8T5OREREREQ1i8HJCHE6ciIiIiKimsXgZIRKZ9XjUD0iIiIioprB4GSEODkEEREREVHNYnAyQpwcgoiIiIioZjE4GSGecSIiIiIiqlkMTkaIZ5yIiIiIiGoWg5MRKp0copiz6hERERER1QgGJyMkl/8TnIo1Bq6EiIiIiKh+YHAyQv+ecTJwIURERERE9QSDkxFScHIIIiIiIqIaxeBkhGScHIKIiIiIqEYxOBmh0qF6Gk4OQURERERUIxicjFDp5BBFvMiJiIiIiKhGMDgZIUu1AgCQeiffwJUQEREREdUPDE5GqKGTJQAgLCHLwJUQEREREdUPDE5GKNDl3+AkeJ0TEREREVG1Y3AyQv5OFpDLJGTkFiIxk8P1iIiIiIiqG4OTEVIr5fB1MAcAhCVkGrgaIiIiIqK6j8HJSJUO1wvndU5ERERERNWOwclIBTlzgggiIiIioprC4GSk7p4ggoiIiIiIqheDk5EKdrUCAFxLykZhscbA1RARERER1W0MTkbK3cYU5iZyFBRrEJ1yx9DlEBERERHVaQxORkomk9Dwn+F6Vzhcj4iIiIioWjE4GbEg7cx6nJKciIiIiKg6MTgZsSCXkuucOCU5EREREVH1YnAyYpxZj4iIiIioZjA4GbHSoXqxabnIyis0cDVERERERHUXg5MRszEzgbOVCgAQkcizTkRERERE1YXByciVXufE4XpERERERNWHwcnI/TuzHoMTEREREVF1YXAyctoJIuIZnIiIiIiIqguDk5H7d2a9TAghDFwNEREREVHdxOBk5PydLCCXScjMK0JCZp6hyyEiIiIiqpMYnIycSiFHAwdzAJwggoiIiIioujA41QG8zomIiIiIqHoxONUB/86sl2ngSoiIiIiI6iYGpzqA93IiIiIiIqpeDE51QOlQvWvJ2Sgs1hi4GiIiIiKiuofBqQ7wsDWFhUqBwmKBqJQ7hi6HiIiIiKjOYXCqAyRJQkNnCwDAlXhe50REREREVNUYnOqIINeS65zCeZ0TEREREVGVM3hwiouLw+OPPw57e3uYmpqiSZMmOHny5H1fs3fvXrRs2RIqlQr+/v5Ys2ZNzRRbi/07sx6DExERERFRVTNocEpLS0PHjh2hVCqxbds2XL58GR9++CFsbW3v+ZqoqCgMGDAA3bt3x9mzZzFt2jRMmjQJf//9dw1WXvsEOv9zLycGJyIiIiKiKqcw5M4XLVoET09PfPPNN9plvr6+933N559/Dl9fX3z44YcAgODgYBw8eBBLly5F3759q7Xe2qx0SvK49Fxk5hXCSq00cEVERERERHWHQYPTli1b0LdvX4wYMQL79u2Du7s7XnjhBTzzzDP3fM2RI0fQq1cvnWV9+/bFtGnTym2fn5+P/Px87fPMzJLJEwoLC1FYWPjwB/EQSvdfFXWYKQEXKxUSMvNxOTYNrbzvfdaOjFdV9hmqH9hnSF/sM6Qv9hnSV23qM/rUYNDgdP36daxcuRIzZszAG2+8gRMnTmDq1KkwMTHBhAkTyn1NQkICnJ2ddZY5OzsjMzMTubm5MDU11Vm3cOFCzJs3r8x2tm/fDjMzs6o7mIewY8eOKtmOrUyGBMiwcddRJLqIKtkm1U5V1Weo/mCfIX2xz5C+2GdIX7Whz+Tk5FS6rUGDk0ajQevWrbFgwQIAQIsWLXDx4kV8/vnn9wxO+po9ezZmzJihfZ6ZmQlPT0/06dMHVlZWVbKPB1VYWIgdO3agd+/eUCoffmjdRXkErhyMhomjD/r3D66CCqm2qeo+Q3Uf+wzpi32G9MU+Q/qqTX2mdDRaZRg0OLm6uqJRo0Y6y4KDg7Fx48Z7vsbFxQWJiYk6yxITE2FlZVXmbBMAqFQqqFSqMsuVSqXBf1ClqqqWEHcbAEBEUnatOTaqHrWp/5JxYJ8hfbHPkL7YZ0hftaHP6LN/g86q17FjR4SHh+ssi4iIgLe39z1fExoail27duks27FjB0JDQ6ulRmMS6PLvzHpCcKgeEREREVFVMWhwmj59Oo4ePYoFCxbg6tWrWLt2Lb744gtMmTJF22b27NkYP3689vlzzz2H69evY9asWQgLC8Nnn32GX375BdOnTzfEIdQqfo4WUMgkZOUVIT4jz9DlEBERERHVGQYNTm3atMHmzZvx008/oXHjxpg/fz6WLVuGcePGadvEx8cjJiZG+9zX1xd//PEHduzYgWbNmuHDDz/El19+Wa+nIi9lopChgaM5AN4Il4iIiIioKhn0GicAGDhwIAYOHHjP9WvWrCmzrFu3bjhz5kw1VmW8glysEJGYjSsJmege5GTocoiIiIiI6gSDnnGiqld6nRPPOBERERERVR0GpzomiMGJiIiIiKjKMTjVMaVnnK4lZ6OgSGPgaoiIiIiI6gYGpzrG3cYUlioFCosFrqdkG7ocIiIiIqI6gcGpjpEkidc5ERERERFVMQanOujuG+ESEREREdHDY3CqgzhBBBERERFR1WJwqoOCXK0AAGHxmQauhIiIiIiobmBwqoMaOpeccbqVkYeM3EIDV0NEREREZPwYnOoga1Ml3KzVAICIRA7XIyIiIiJ6WAxOdRQniCAiIiIiqjoMTnUUr3MiIiIiIqo6DE51FGfWIyIiIiKqOgxOdZT2JriJWRBCGLgaIiIiIiLjxuBURzVwsIBCJiErrwi3MvIMXQ4RERERkVFjcKqjTBQy+DtZAOB1TkRERERED4vBqQ7jzHpERERERFWDwakOC+QEEUREREREVYLBqQ7jzHpERERERFWDwakOC3IpuZfTteRsFBRpDFwNEREREZHxYnCqw1yt1bBUK1CkEbiWnG3ocoiIiIiIjBaDUx0mSRKH6xERERERVQEGpzqOM+sRERERET08Bqc6rvQ6p7AE3suJiIiIiOhBMTjVcRyqR0RERET08Bic6riG/wSn+Iw8ZOQUGrgaIiIiIiLjxOBUx1mplXC3MQUAhCfyrBMRERER0YNgcKoH/h2ux+uciIiIiIgeBINTPVA6s94VXudERERERPRAGJzqgUBOEEFERERE9FAYnOqB0inJIxKyIIQwcDVERERERMaHwakeaOBoDqVcQlZ+EeLScw1dDhERERGR0WFwqgeUchn8HC0AAGHxHK5HRERERKQvBqd6QjuzHqckJyIiIiLSG4NTPRH4z3VOYZwggoiIiIhIbwxO9USQK+/lRERERET0oBic6onSoXrXku8gv6jYwNUQERERERkXBqd6wsVKDSu1AsUagWtJdwxdDhERERGRUWFwqickSdLezyk8kcP1iIiIiIj0weBUj5Re53T0WqqBKyEiIiIiMi4MTvVIn0YuAICfT97EgchkA1dDRERERGQ8GJzqkU4BDniivTcAYMYv53A7O9/AFRERERERGQcGp3rmzQHBCHCyQHJWPl7dcB5CCEOXRERERERU6zE41TNqpRwrxraAiUKG3WFJ+PZwtKFLIiIiIiKq9Ric6qEgFyu82T8YALBgWxiuxHOWPSIiIiKi+2FwqqfGh3qjZ5ATCoo0mPrTGeQW8Ka4RERERET3wuBUT0mShA8eawpHSxUik7Lx3p+XDV0SEREREVGtxeBUj9lbqPDRyGYAgB+OxmD7pQQDV0REREREVDsxONVznQMc8WyXBgCAWRvPIyEjz8AVERERERHVPgxOhJl9AtHY3QrpOYWY/vNZFGs4RTkRERER0d0YnAgmChk+Ht0CZiZyHLl+G6v2XzN0SUREREREtQqDEwEAGjhaYO7gEADAR9sjcPZmumELIiIiIiKqRRicSGtEKw8MaOqKIo3Ay+vOIDu/yNAlERERERHVCgxOpCVJEhYMawJ3G1PcuJ2Dt3+7aOiSiIiIiIhqBQYn0mFtqsTy0c0hk4BNp+Pw29k4Q5dERERERGRwDE5URmsfO0ztGQAAeHPzRcTczjFwRUREREREhsXgROV6sbs/WnvbIju/CC//fAZFxRpDl0REREREZDAMTlQuhVyGZaObw1KtwJmYdCzfFWnokoiIiIiIDIbBie7Jw9YMC4c3AQB8sucqjl6/beCKiIiIiIgMQ+/g9Ndff+HgwYPa559++imaN2+OsWPHIi0trUqLI8Mb2NQNI1p5QAjglfXncIdTlBMRERFRPaR3cHr11VeRmZkJALhw4QJmzpyJ/v37IyoqCjNmzKjyAsnw5gwOgYetKWLTcvH+tjBDl0NEREREVOP0Dk5RUVFo1KgRAGDjxo0YOHAgFixYgE8//RTbtm2r8gLJ8CxUCnzwaFMAwPdHb+DwtRQDV0REREREVLP0Dk4mJibIySmZnnrnzp3o06cPAMDOzk57Jorqng7+DhjXzgsA8NrG8xyyR0RERET1it7BqVOnTpgxYwbmz5+P48ePY8CAAQCAiIgIeHh4VHmBVHvM7h8MdxtT3EzNxaK/OGSPiIiIiOoPvYPTJ598AoVCgQ0bNmDlypVwd3cHAGzbtg2PPPJIlRdItYeFSoFF/wzZ++7IDRy5xln2iIiIiKh+UOj7Ai8vL/z+++9lli9durRKCqLarVOAA8a288LaYzGYtfEc/p7WBWYmencjIiIiIiKjovcZp9OnT+PChQva57/99huGDh2KN954AwUFBVVaHNVOs/sFaYfsffBXuKHLISIiIiKqdnoHp2effRYREREAgOvXr2P06NEwMzPD+vXrMWvWrCovkGofS7US7z9acmPcNYejeWNcIiIiIqrz9A5OERERaN68OQBg/fr16NKlC9auXYs1a9Zg48aNVV0f1VKdAxwxpq0nAGDWhvPIKeAse0RERERUd+kdnIQQ0Gg0AEqmI+/fvz8AwNPTEykpvL9PffJG/2C4WasRk5rDIXtEREREVKfpHZxat26Nd999F99//z327dunnY48KioKzs7OVV4g1V4lQ/ZKZtlbczgaxzhkj4iIiIjqKL2D07Jly3D69Gm8+OKLePPNN+Hv7w8A2LBhAzp06FDlBVLt1qWhI0a3+WfI3kYO2SMiIiKiuknveaSbNm2qM6teqcWLF0Mul1dJUWRc3hgQjH0RybhxOweL/w7HnEEhhi6JiIiIiKhK6X3GqdSpU6fwww8/4IcffsDp06ehVquhVCqrsjYyElZqJRYO/3eWveNRqQauiIiIiIioaukdnJKSktC9e3e0adMGU6dOxdSpU9G6dWv07NkTycnJ1VEjGYFugU4Y2doDQgCzNpxDbkGxoUsiIiIiIqoyegenl156CdnZ2bh06RJSU1ORmpqKixcvIjMzE1OnTq2OGslIvDWwEVyt1Yi+nYMl2znLHhERERHVHXoHp7/++gufffYZgoODtcsaNWqETz/9FNu2bavS4si4WKmVWPDPkL2vD0XhRDSH7BERERFR3aB3cNJoNOVey6RUKrX3d6L6q3ugE0a0Kh2yd55D9oiIiIioTtA7OPXo0QMvv/wybt26pV0WFxeH6dOno2fPnlVaHBmntwY2gouVGlEpd/Ahh+wRERERUR2gd3D65JNPkJmZCR8fH/j5+cHPzw++vr7IzMzExx9/XB01kpGxNv13lr2vDkVxlj0iIiIiMnp638fJ09MTp0+fxs6dOxEWFgYACA4ORq9evaq8ODJe3YOc8FgrD2w4FYvHvzqGyZ0b4IXufjAz0bvLEREREREZ3AN9ipUkCb1790bv3r21y8LCwjB48GBERERUWXFk3N4e1AiJmXk4EJmCT/ZcxYZTsXhjQDAGNXWFJEmGLo+IiIiIqNIe+Aa4/5Wfn49r165V1eaoDrBSK/HdU22x6olW8LA1RUJmHqb+dAajVh3FpVsZhi6PiIiIiKjSqiw4EZVHkiT0DXHBzhldMbN3Q6iVMhyPTsWgFQfx1q8XkHanwNAlEhERERFViMGJaoRaKcdLPQOwe2Y3DGzqCo0Afjgag25L9uK7I9EoKuZU9kRERERUezE4UY1yszHFJ2NbYt3k9ghysURGbiHe/u0SBq44iCPXbhu6PCIiIiKiclV6cghbW9v7XtBfVFRUJQVR/dC+gT1+f6kTfjoegyXbIxCWkIUxq49iQFNXvNE/GO42poYukYiIiIhIq9LBadmyZdVYBtVHCrkMT4T6YGBTN3y0IwI/HruBP87HY9eVRLzQzR+TuzSAWik3dJlERERERJUPThMmTKjOOqgeszU3wfyhjTGmrRfmbr2E41Gp+GhHBPaGJ+HnZ0OhlHNEKREREREZFj+RUq3RyM0KP09ujxVjWsBKrcDpmHR8todT3BMRERGR4TE4Ua0iSRIGNXPD/KGNAQArdkfiQizv+UREREREhsXgRLXS4GZuGNDEFUUagRm/nEVeYbGhSyIiIiKieozBiWolSZIwf2hjOFioEJmUjY92RBi6JCIiIiKqxxicqNayMzfBokebAABWH7iOY9d5nyciIiIiMoxKz6pXqri4GGvWrMGuXbuQlJQEjUajs3737t1VVhxRz2BnjGztgV9OxuKVDeew7eUusFDp3W2JiIiIiB6K3p9AX375ZaxZswYDBgxA48aN73tTXKKq8L+BjXDo6m3cTM3Fe39cwcLhTQxdEhERERHVM3oHp3Xr1uGXX35B//79q6MeojIs1UosGdEMY1YfxU/HY9AnxBndA50MXRYRERER1SN6X+NkYmICf3//6qiF6J5C/ezxVEdfAMBrG84jPafAwBURERERUX2id3CaOXMmli9fDiFEddRDdE+zHgmEn6M5krLy8fZvlwxdDhERERHVI3oP1Tt48CD27NmDbdu2ISQkBEqlUmf9pk2bqqw4oruplXJ8NLI5hq88jC3nbqFviAsGNHU1dFlEREREVA/oHZxsbGwwbNiw6qiFqELNPG0wpZsfPt59FW/9egFtfG3hZKk2dFlEREREVMfpHZy++eab6qiDqNJe7BGAXWFJuHQrE7M3XsCXE1pzdkciIiIiqlYPfAPc5ORkHDx4EAcPHkRycnJV1kR0XyYKGT4a2Rwmchl2hSVh/clYQ5dERERERHWc3sHpzp07eOqpp+Dq6oouXbqgS5cucHNzw9NPP42cnJzqqJGojEAXS8zs0xAAMG/rJdxMZd8jIiIiouqjd3CaMWMG9u3bh61btyI9PR3p6en47bffsG/fPsycObM6aiQq16TODdDGxxZ3Corxyvpz0Gg40yMRERERVQ+9g9PGjRvx1VdfoV+/frCysoKVlRX69++P1atXY8OGDXpta+7cuZAkSecRFBR0z/Zr1qwp016t5sQA9ZVcJmHJiGYwM5HjWFQqvjkcbeiSiIiIiKiO0ntyiJycHDg7O5dZ7uTk9EBD9UJCQrBz585/C1LcvyQrKyuEh4drn3NSgPrN294cbw4IxpubL+KDv8LQtaEj/J0sDF0WEREREdUxep9xCg0NxZw5c5CXl6ddlpubi3nz5iE0NFTvAhQKBVxcXLQPBweH+7aXJEmnfXkhjuqXsW290LWhI/KLNJj5y1kUFWsMXRIRERER1TF6n3Favnw5+vbtCw8PDzRr1gwAcO7cOajVavz99996FxAZGQk3Nzeo1WqEhoZi4cKF8PLyumf77OxseHt7Q6PRoGXLlliwYAFCQkLu2T4/Px/5+fna55mZmQCAwsJCFBYW6l1vVSrdv6HrqAveHRKMASvScC42A+9vu4IZvfyhlD/wpJG1FvsM6Yt9hvTFPkP6Yp8hfdWmPqNPDZIQQu8r6nNycvDjjz8iLCwMABAcHIxx48bB1NRUr+1s27YN2dnZCAwMRHx8PObNm4e4uDhcvHgRlpaWZdofOXIEkZGRaNq0KTIyMrBkyRLs378fly5dgoeHR7n7mDt3LubNm1dm+dq1a2FmZqZXvVS7nUyW8P1VOQDATiXQw02Ddo4CJnIDF0ZEREREtVJOTg7Gjh2LjIwMWFlZ3bftAwWn6pKeng5vb2989NFHePrppytsX1hYiODgYIwZMwbz588vt015Z5w8PT2RkpJS4TenuhUWFmLHjh3o3bs3lEqlQWupC4QQ+P7YTXy29zpu3ykAANibm+DJUC+Ma+cJS7Xxf4/ZZ0hf7DOkL/YZ0hf7DOmrNvWZzMxMODg4VCo4VWqo3pYtW9CvXz8olUps2bLlvm0HDx5c+Ur/w8bGBg0bNsTVq1cr1V6pVKJFixb3ba9SqaBSqcp9raF/UKVqUy3G7unOfhjX3gfrT97E5/uuIy49Fx/uvIovDkTj8VBvPNXRF46WZfuDsWGfIX2xz5C+2GdIX+wzpK/a0Gf02X+lgtPQoUORkJAAJycnDB069J7tJElCcXFxpXf+X9nZ2bh27RqeeOKJSrUvLi7GhQsX0L9//wfeJ9U9aqUcT4T6YHRbL2w9dwsr915DZFI2Vu69hq8PRmFka09M7tIAnnYcqklERERElVOpq+c1Gg2cnJy0X9/roW9oeuWVV7Bv3z5ER0fj8OHDGDZsGORyOcaMGQMAGD9+PGbPnq1t/84772D79u24fv06Tp8+jccffxw3btzApEmT9Nov1Q9KuQzDW3rg72ldsHp8a7TwskF+kQbfH72Bbkv2YvrPZxGekGXoMomIiIjICOg97dh3332nc81QqYKCAnz33Xd6bSs2NhZjxoxBYGAgRo4cCXt7exw9ehSOjo4AgJiYGMTHx2vbp6Wl4ZlnnkFwcDD69++PzMxMHD58GI0aNdL3MKgekckk9G7kjE3Pd8BPz7RH5wAHFGsENp+JQ99l+zHp2xM4dSPN0GUSERERUS2m93TkEydOxCOPPKI9A1UqKysLEydOxPjx4yu9rXXr1t13/d69e3WeL126FEuXLq309onuJkkSQv3sEepnjwuxGVi57yq2XUzAzitJ2HklCe187fBcVz90C3TkjZWJiIiISIfewUkIUe6HytjYWFhbW1dJUUTVrYmHNT4b1wrXkrOxat81bD4Th2NRqTgWlYogF0s827UBBjZ1q5P3giIiIiIi/VU6OLVo0QKSJEGSJPTs2RMKxb8vLS4uRlRUFB555JFqKZKouvg5WuCDx5pheu+G+PpgFNYei0FYQham/3wOi/8Kx9OdG2B0G0+Yq/T+GwMRERER1SGV/jRYOpve2bNn0bdvX1hYWGjXmZiYwMfHB48++miVF0hUE1ytTfHmgEZ4sXsAfjh2A98cisatjDzM//0yPt4VifGh3pjQwQcOFsY/lTkRERER6a/SwWnOnDkAAB8fH4waNQpqtbraiiIyFGszJaZ098fTnXyx6XQcvth/DdG3c7Bi91V8sf86RrT2wDOdG8Db3tzQpRIRERFRDdL7Ao4JEyYwNFGdp1bKMbadF3bN7IaV41qimYc18os0+OFoDLov2Yspa0/jQmyGocskIiIiohqi94UbxcXFWLp0KX755RfExMSgoKBAZ31qamqVFUdkaHKZhH5NXPFIYxccvZ6KVfuvYW94Mv44H48/zsejo789nuzgi/YN7GCp5t3SiYiIiOoqvYPTvHnz8OWXX2LmzJl466238OabbyI6Ohq//vor3n777eqokcjg7p7K/Ep8Jr7Yfx1bzt3Coau3cejqbcgkINjVCm187NDW1w5tfOzgaMnroYiIiIjqCr2D048//ojVq1djwIABmDt3LsaMGQM/Pz80bdoUR48exdSpU6ujTqJaI9jVCktHNcfMPg3x9cFo7LySiJjUHFy6lYlLtzKx5nA0AMDXwRxtfGy1YcrLzoz3hyIiIiIyUnoHp4SEBDRp0gQAYGFhgYyMkus8Bg4ciP/9739VWx1RLeZha4a3BzXC24MaISEjDyeiU3EiOhXHo1IRnpiFqJQ7iEq5g19OxgIAnCxVaONrh7Y+JWekglwsIZMxSBEREREZA72Dk4eHB+Lj4+Hl5QU/Pz9s374dLVu2xIkTJ6BScWgS1U8u1moMauaGQc3cAAAZOYU4FZOK41FpOBGdivOx6UjKytdeGwUA7jam+PaptvB3srjfpomIiIioFtA7OA0bNgy7du1Cu3bt8NJLL+Hxxx/HV199hZiYGEyfPr06aiQyOtZmSvQIckaPIGcAQF5hMc7eTMeJqFQcj07F6RtpiEvPxeTvTmLzlI6wNuXEEkRERES1md7B6f3339d+PWrUKHh5eeHIkSMICAjAoEGDqrQ4orpCrZSjfQN7tG9gDwBIyc7HkE8O4XrKHUz96Qy+frIN5By2R0RERFRr6X0fp/8KDQ3FjBkzGJqI9OBgocKqJ1pBrZRhX0QyPvgrzNAlEREREdF9VOqM05YtWyq9wcGDBz9wMUT1SWN3ayx+rBle+ukMVu2/jiBXSwxr4WHosoiIiIioHJUKTkOHDtV5LkkShBBllgElN8glosoZ1MwNYQmZ+HTPNby28QIaOFigmaeNocsiIiIiov+o1FA9jUajfWzfvh3NmzfHtm3bkJ6ejvT0dGzbtg0tW7bEX3/9Vd31EtU5M3sHolewEwqKNJj8/UkkZeYZuiQiIiIi+g+9r3GaNm0ali9fjr59+8LKygpWVlbo27cvPvroI978lugByGQSlo5qDn8nCyRm5uPZH04hv4hnbomIiIhqE72D07Vr12BjY1NmubW1NaKjo6ugJKL6x1KtxOrxrWGlVuBMTDre2nyxzHBYIiIiIjIcvYNTmzZtMGPGDCQmJmqXJSYm4tVXX0Xbtm2rtDii+sTXwRyfjG0JmQSsPxWLbw5FG7okIiIiIvqH3sHp66+/Rnx8PLy8vODv7w9/f394eXkhLi4OX331VXXUSFRvdGnoiDf6BwMA3vvzCg5Gphi4IiIiIiICHuAGuP7+/jh//jx27NiBsLCSe88EBwejV69e2pn1iOjBPd3JF5fjM7HpdBymrD2NLS92hLe9uaHLIiIiIqrX9A5OQMnU43369EGfPn2quh6iek+SJCwY1gTXk+/g7M10PPPdSWx6oSMsVA/0diUiIiKiKlCpT2Iff/wxJk+eDLVajY8//vi+bTmzHtHDUyvlWPVEKwxacRARidmY/vNZrHq8laHLIiIiIqq3KhWcli5dinHjxkGtVmPp0qX3bCdJEoMTURVxtlJj1ROtMOqLo9hxORFLd0ZgavcGhi6LiIiIqF6qVHCKiooq92siql4tvGyxcFgTzFx/Dit2X0WAo5mhSyIiIiKql/SeVY+IatajrTwwqZMvAOC1TRcRe8fABRERERHVQ5U64zRjxoxKb/Cjjz564GKIqHyv9wtCeGIWDkSm4MswOdrFZqC1r4OhyyIiIiKqNyoVnM6cOVOpjXE6cqLqoZDL8MmYlhj8yUHcSM3BY6uOoVewM2b0bohGblaGLo+IiIiozqtUcNqzZ09110FEFbA2U+LHp1tj5pq9OJEiw84ridh5JREDmrpieq+G8HeyMHSJRERERHUWr3EiMiLOVmqM9ddg20sdMaiZGwDgj/Px6LN0H2b+cg4xt3OqdH9CCKTdKajSbRIREREZowe6o+bJkyfxyy+/ICYmBgUFuh+qNm3aVCWFEdG9NXA0x4oxLfBCNz98tCMCOy4nYuPpWPx2Ng6j2njixR7+cLU2faBtx6Xn4tDVFBy6moLD124jOSsfj7f3wtxBIVDI+bcWIiIiqp/0Dk7r1q3D+PHj0bdvX2zfvh19+vRBREQEEhMTMWzYsOqokYjuIdjVCqvHt8a5m+n4cEcE9kck48djMVh/KhaPt/PG89384Gipuu820nMKcOTabRz8JyhFpZSdtu+HozGITcvFJ2NbwkL1QH9vISIiIjJqen8CWrBgAZYuXYopU6bA0tISy5cvh6+vL5599lm4urpWR41EVIFmnjb47qm2OHb9Nj7cHoHj0an4+lAUfjoeg4kdfTC5SwPYmJkAAHILinHyRmpJULp6GxdvZUCIf7clk0q219HPAR387ZF2pxAz15/F3vBkPLbyML6Z2OaBz2YRERERGSu9g9O1a9cwYMAAAICJiQnu3LkDSZIwffp09OjRA/PmzavyIomocto1sMfPz7bHwaspWLI9AudupuOzvdfw/ZEbGNrCHVeTsnHqRhoKijU6rwtwskBHfwd09HdAuwZ2sFIrddZ72Jri6W9PIiwhC0M/PYSvJrRBY3frmjw0IiIiIoPSOzjZ2toiKysLAODu7o6LFy+iSZMmSE9PR05O1V6YTkT6kyQJnQMc0cnfATuvJOHD7eEIS8jC90dvaNu4WqvRwc8BnQLs0cHPAc5W6vtus5mnDTa/0AFPrTmByKRsjFx1BJ+MbYEeQc7VfThEREREtYLewalLly7YsWMHmjRpghEjRuDll1/G7t27sWPHDvTs2bM6aiSiByBJEno3ckbPICf8cSEeh6/dRiNXS3Twd0ADB3O977vmaWeGDc93wJQfT+Pg1RRM+vYk5g4OwfhQn+o5ACIiIqJapNLB6eLFi2jcuDE++eQT5OXlAQDefPNNKJVKHD58GI8++ijeeuutaiuUiB6MTCZhUDM37fTlD8PaVIlvJrbBm5sv4JeTsXj7t0u4cTsHb/QPhlzGG2ATERFR3VXp4NS0aVO0adMGkyZNwujRowEAMpkMr7/+erUVR0S1j1Iuw6JHm8Lb3hyL/w7HVwejcDM1B8tGN4eZCWfcIyIiorqp0jdl2bdvH0JCQjBz5ky4urpiwoQJOHDgQHXWRkS1lCRJmNLdHx+PaQEThQzbLydi9BdHkZSVZ+jSiIiIiKpFpYNT586d8fXXXyM+Ph4rVqxAdHQ0unbtioYNG2LRokVISEiozjqJqBYa3MwNaye1g62ZEudjMzDs08OISMwydFlEREREVa7SwamUubk5Jk6ciH379iEiIgIjRozAp59+Ci8vLwwePLg6aiSiWqy1jx02v9ARvg7miEvPxaMrD+PQ1RRDl0VERERUpfQOTnfz9/fHG2+8gbfeeguWlpb4448/qqouIjIiPg7m2PR8B7T1sUNWXhEmfH0cv5y4aeiyiIiIiKrMAwen/fv348knn4SLiwteffVVDB8+HIcOHarK2ojIiNiam+D7SW0xpLkbijQCszaexztbLyO/qNjQpRERERE9NL2mwLp16xbWrFmDNWvW4OrVq+jQoQM+/vhjjBw5Eubm5tVVIxEZCZVCjmWjmsPbzgwf776Krw9F4UR0KlaMaQEfB/6OICIiIuNV6eDUr18/7Ny5Ew4ODhg/fjyeeuopBAYGVmdtRGSEJEnCjD6BaOphg1c3nMOFuAwM+PgA3hvWBENbuBu6PCIiIqIHUumhekqlEhs2bEBsbCwWLVrE0ERE99WrkTP+fLkz2vra4U5BMab9fBYzfzmHO/lFhi6NiIiISG+VDk5btmzBkCFDIJfLq7MeIqpDXK1N8dMz7TGtVwBkErDxdCwGrTiIS7cyDF0aERERkV4ealY9IqKKyGUSpvVqiJ+eaQ8XKzWup9zBsE8P49vD0RBCGLo8IiIiokphcCKiGtGugT22vdwZvYKdUVCswZwtlzD5+1NIu1Ng6NKIiIiIKsTgREQ1xtbcBKvHt8LcQY1gIpdhx+VE9P/4AI5dv23o0oiIiIjui8GJiGqUJEl4sqMvNr3QAQ0czBGfkYcxq49i+c5IFGs4dI+IiIhqJwYnIjKIxu7W2PpSJzza0gMaASzdGYGxq48iPiPX0KURERERlcHgREQGY65S4MORzfDRyGYwM5HjWFQq+i8/gOU7I3HoagqyOXU5ERER1RKVvgEuEVF1Gd7SAy28bPHST6dxMS4TS3dGAABkEhDkYoWW3jZo5W2LVl528LQzhSRJBq6YiIiI6hsGJyKqFXwdzLHx+Q7YcCoWx66n4tSNNMSl5+JyfCYux2fih6MxAAAHCxValQYpb1uEuFlDreT95YiIiKh6MTgRUa2hUsgxrp03xrXzBgAkZubh9I00nLqRhlMxabgYl4GU7Hz8fSkRf19KBACYyGVo7G6FVt62eLy9N7ztzQ15CERERFRHMTgRUa3lbKVGvyau6NfEFQCQV1iMi3EZJUHqRhpOx6QhJbsAp2PScTomHVvO3cKOGV1hpVYauHIiIiKqaxiciMhoqJVytPaxQ2sfOwCAEAIxqTk4dSMNy3ZGIiY1B4v/Csf8oY0NXCkRERHVNZxVj4iMliRJ8LY3x/CWHnj/0SYAgB+O3cCpG2kGroyIiIjqGgYnIqoTOvg5YEQrDwgBvLHpAgqKNIYuiYiIiOoQBiciqjPe6B8Me3MThCdmYfWB64Yuh4iIiOoQBiciqjNszU3w9qBGAIDluyIRlXLHwBURERFRXcHgRER1yuBmbugc4ICCIg3e2HQBQghDl0RERER1AIMTEdUpkiThvaFNoFbKcOT6bWw4FWvokoiIiKgOYHAiojrHy94M03s1BAC89+cVpGTnG7giIiIiMnYMTkRUJz3dyReNXK2QnlOId3+/bOhyiIiIyMgxOBFRnaSQy7BweBPIJODXs7ewLyLZ0CURERGREWNwIqI6q5mnDZ7s4AsAeHPzBeQUFBm4IiIiIjJWDE5EVKfN7NMQ7jamiE3LxfKdkYYuh4iIiIwUgxMR1WnmKgXmDw0BAHx5MAqXbmUYuCIiIiIyRgxORFTn9QhyxoCmrijWCMzedAHFGt7biYiIiPTD4ERE9cKcQY1gqVbgfGwGvj0cbehyiIiIyMgwOBFRveBkqcYb/YMBAEu2hyMuPdfAFREREZExYXAionpjVGtPtPWxQ05BMf7360UIwSF7REREVDkMTkRUb8hkEhYMbwwTuQy7w5Lw54UEQ5dERERERoLBiYjqFX8nSzzfzQ8AMGfLJWTkFBq4IiIiIjIGDE5EVO+80N0PDRzNkZKdj/f/CnugbQghONSPiIioHlEYugAiopqmUsixcFgTjPriKH46HoO2vrawM1chM7cQWXlFyMorRGZe6df/PM8t0i7LzCtEdn4RJJTcJ8pSpYCFWgFzlQIWKgUs1SX/WqiUsFArYKGSa7+2VCng52gBL3szQ38biIiISA8MTkRUL7VrYI8xbT3x0/GbmP7zuQfahgC04Qp63FdXkoBBTd0wtWcA/J0sHmjfREREVLMYnIio3nr9kWBcTcpGQmYeLFVKWKoVsDL951+17r+Wat31luqSX5/ZeUXIzi/6999/Hln/PL/zz7qsf/7NyC3E5fhMbDl3C7+fv4Whzd0xtWcAfBzMDfzdICIiovthcCKiesvaTIn1z3V4qG04Wer/mku3MrBsZyR2XE7EpjNx+O3cLQxv4Y6XegRwCB8REVEtxckhiIhqWIibNVaPb42tL3ZCjyAnFGsE1p+KRY8P92L2pvOITcsxdIlERET0HwxOREQG0sTDGl8/2QabX+iALg0dUaQR+On4TXRfshdv/XoB8Rm5hi6RiIiI/sHgRERkYC28bPHdU22x4blQdPS3R2GxwA9HY9D1g72Yu+USkjLzDF0iERFRvcfgRERUS7T2scOPk9pj3eT2aOtrh4JiDdYcjkbnD/Zg/u+XkZyVb+gSiYiI6i0GJyKiWqZ9A3v8PLk91k5qh1betsgv0uCrg1HovmQvfjsbZ+jyiIiI6iUGJyKiWkiSJHTwd8CG50Lx3VNt0dTDGtn5RXh53VnM2nAOOQVFhi6RiIioXmFwIiKqxSRJQpeGjtj8Qke83DMAMgn45WQsBq04iCvxmYYuj4iIqN5gcCIiMgJymYTpvRvix0nt4WylwrXkOxjy6SH8cPQGhBCGLo+IiKjOY3AiIjIioX72+HNqZ3QPdERBkQZv/XoRU9aeRkZuoaFLIyIiqtMYnIiIjIy9hQpfTWiDtwYEQymX8OeFBAz4+ADOxKQZujQiIqI6i8GJiMgIyWQSJnVugA3PdYCXnRli03Ix4vMj+HzfNWg0HLpHRERU1RiciIiMWDNPG/w+tRMGNnVFkUbg/W1heHLNCaRk855PREREVYnBiYjIyFmplVgxpgXeH94EaqUM+yOS0W/5ARy6mmLo0oiIiOoMBiciojpAkiSMbuuFLS92QkNnCyRn5ePxr47ho52RKObIPSIioofG4EREVIc0dLbEb1M6YUxbTwgBrNwXhRWX5Dh5gxNHEBERPQwGJyKiOsbURI6Fw5tixZgWMFfJEZUlYcyXJ/DYysPYHZbI+z4RERE9AAYnIqI6alAzN/zxYgeEOmmglEs4eSMNT605iX7LD+C3s3EoKtYYukQiIiKjweBERFSHuduYYrSfBntmdMbkLg1gbiJHWEIWXl53Ft0/3Ivvj95AXmGxocskIiKq9RiciIjqAWcrNd7oH4zDr/fEK30aws7cBDdTc/G/Xy+i06I9+GzvVWTmFRq6TCIiolqLwYmIqB6xNlPixR4BOPRaD8wbHAJ3G1OkZOfjg7/C0XHhbiz6KwxJWXkPvH0hBIp5A14iIqqDFIYugIiIap6piRwTOvhgbDsvbD13Cyv3XkNkUjZW7r2Grw5GYUQrDzze3hsySUJGbqH2kZ5TgMzSr+9anpHz79cqhQyv9wvCE6E+hj5MIiKiKsPgRERUjynlMgxv6YGhzd2xKywJn+29ijMx6fjxWAx+PBbzQNssKijG/367hPScQrzYwx+SJFVx1URERDWPwYmIiCCTSejdyBm9gp1wPCoVn+29hiPXb8PcRA5rUyWszUxK/jVVwuaff0uW3/W1qRI2ZkqsO34Ty3dF4sMdEUjPLcRbA4IZnoiIyOgZNDjNnTsX8+bN01kWGBiIsLCwe75m/fr1+N///ofo6GgEBARg0aJF6N+/f3WXSkRUL0iShHYN7NGugf0Db2N674awNlXind8v46uDUcjMLcTC4U2gkPOyWiIiMl4G/18sJCQE8fHx2sfBgwfv2fbw4cMYM2YMnn76aZw5cwZDhw7F0KFDcfHixRqsmIiIKvJUJ18sGdEMMglYfyoWL649g/wiTntORETGy+DBSaFQwMXFRftwcHC4Z9vly5fjkUcewauvvorg4GDMnz8fLVu2xCeffFKDFRMRUWU81soDn41rBRO5DH9dSsCkb08ip6DI0GURERE9EINf4xQZGQk3Nzeo1WqEhoZi4cKF8PLyKrftkSNHMGPGDJ1lffv2xa+//nrP7efn5yM/P1/7PDMzEwBQWFiIwkLD3rOkdP+GroOMB/sM6cvQfaZnoD1WP9ECz689iwORKRi3+ihWP9ES1qZKg9RDFTN0nyHjwz5D+qpNfUafGiQhhMFuuLFt2zZkZ2cjMDAQ8fHxmDdvHuLi4nDx4kVYWlqWaW9iYoJvv/0WY8aM0S777LPPMG/ePCQmJpa7j/KuowKAtWvXwszMrOoOhoiI7ik6C1h1RY6cYgmuZgIvBBfDysTQVRERUX2Xk5ODsWPHIiMjA1ZWVvdta9AzTv369dN+3bRpU7Rr1w7e3t745Zdf8PTTT1fJPmbPnq1zliozMxOenp7o06dPhd+c6lZYWIgdO3agd+/eUCr511eqGPsM6as29ZleiVmY+O1pxGflY3WUJb59sjU8bE0feHtRKXfw+/kEHLp2G7ZmSgQ4W6ChkwUaOlvAx94cJgqDj0Y3SrWpz5BxYJ8hfdWmPlM6Gq0yDD5U7242NjZo2LAhrl69Wu56FxeXMmeWEhMT4eLics9tqlQqqFSqMsuVSqXBf1ClalMtZBzYZ0hftaHPhHjYYcNzHTDuq6OISc3F6C+P44en2yHAuewIg3tJyMjD7+dvYcu5Wzgfm6GzbmdYsvZrhUyCr4M5GrpYoqGTJQJdLNDQ2RLe9uaQyzg1emXUhj5DxoV9hvRVG/qMPvuvVcEpOzsb165dwxNPPFHu+tDQUOzatQvTpk3TLtuxYwdCQ0NrqEIiInoYXvZm2PBcBzzx1TFEJGZj5KojWDOxLZp52tzzNek5Bdh2MQFbzt7C0ajbKB1gLpdJ6OTvgP5NXJBbUIzwxGxEJGYhIiELWflFiEzKRmRSNv5AvHZbJgoZ/B0tEOhiiYbOlhjS3A1uNg9+1ouIiOoPgwanV155BYMGDYK3tzdu3bqFOXPmQC6Xa69hGj9+PNzd3bFw4UIAwMsvv4yuXbviww8/xIABA7Bu3TqcPHkSX3zxhSEPg4iI9OBspcbPk0Px5JoTOHczHWNXH8WXE9og1O/fe0flFBRh55UkbDl7C/siklBY/O/luG18bDG4mRv6N3GFvUXZEQVCCMRn5JWEqMQshCeUBKrIpCzkFWpwOT4Tl+NLhmasPnAd3zzZ5r7BjYiICDBwcIqNjcWYMWNw+/ZtODo6olOnTjh69CgcHR0BADExMZDJ/h2j3qFDB6xduxZvvfUW3njjDQQEBODXX39F48aNDXUIRET0AGzNTfDjpHaY/N1JHL52GxO+OY6PRzeHSiHHb2fjsP1yInIK/r3vU7CrFQY3c8OgZq7wsL3/xD6SJMHNxhRuNqboFuikXV6sEYhNy0F4QhYik7Kx9dwthCVkYczqo1j5eCt0behYbcdLRETGz6DBad26dfddv3fv3jLLRowYgREjRlRTRUREVFMsVAp8/WQbTP3pDLZfTsRzP5zWWe9lZ4bBzdwwuLkbGupxHdS9yGUSvO3N4W1vjj4hwIQOPnju+1M4eDUFT685gSUjmmFoC/eH3g8REdVNteoaJyIiql/USjk+G9cSr2+6gA2nYuFgocLApq4Y0twNzT1tIEnVN5FDaXB7Zf05bDl3C9N+PovkrHw806VBte2TiIiMF4MTEREZlEIuw+LHmuKlHv5wtzGFQl5z04ibKGRYNqo5HCxU+PpQFN778wqSs/Px+iNBkHH2PSIiugtvckFERAYnSSXD6GoyNJWSyST8b2AwXu8XBAD4Yv91zFx/DoXFmhqvhYiIai8GJyIiqvckScJzXf3w4YhmkMskbD4Th6e/PYk7+UWGLo2IiGoJBiciIqJ/PNrKA19OaA1TpRz7I5IxdvVR3M7ON3RZRERUCzA4ERER3aV7oBPWPtMOtmZKnIvNwGOfH8HN1BxDl0VERAbG4ERERPQfLbxsseH5DnC3MUVUyh0MX3kYl29lGrosIiIyIAYnIiKicvg5WmDTCx0Q5GKJ5Kx8jFp1BEeu3TZ0WUREZCAMTkRERPfgbKXGz8+Goq2vHbLyizDh6+P480K8ocsiIiIDYHAiIiK6D2tTJb57qi36hjijoFiDKWtP4/WN5/HjsRs4GZ2KzLxCQ5dIREQ1gDfAJSIiqoBaKcdn41rhf79dxNpjMVh34ibWnbipXe9uY4qGzhYIdLFCkIslGjpbws/JHCqF3IBVExFRVWJwIiIiqgS5TMJ7Qxuje6ATTkanIiwhCxGJWYjPyENcei7i0nOxJzxZp30DB3M0dLFEkLMlAl0s0dbXDjZmJgY8CiIielAMTkRERJUkSRJ6N3JG70bO2mUZOYUIT8wqeSRkIiIhG2EJmcjMK0JkUjYik7LxB0qui7JUKTDrkUCMbecNuUwy1GEQEdEDYHAiIiJ6CNZmSrT1tUNbXzvtMiEEEjLzEJ6QpX2cuZmOqJQ7+N9vl7DhdBwWDGuMEDdrA1ZORET6YHAiIiKqYpIkwdXaFK7WpugW6AQAKNYI/HD0Bhb/HY5zN9Mx+JNDmNjBB9N7N4S5iv8dExHVdpxVj4iIqAbIZRImdPDBrpldMaCJK4o1Al8ejEKvj/bh70sJhi6PiIgqwOBERERUg5yt1Ph0XEt8M7ENPO1MEZ+Rh2e/P4VJ355EXHquocsjIqJ7YHAiIiIygO6BTtg+rSte6OYHhUzCziuJ6P3RPqzefx1FxRpDl0dERP/B4ERERGQgpiZyzHokCH++3BltfGyRU1CM9/68gkGfHMKZmDRDl0dERHdhcCIiIjKwhs6W+HlyKBY92gQ2Zkpcic/E8JWH8davF5CRW2jo8oiICAxOREREtYJMJmFUGy/smtEVj7b0gBDAD0dj0PPDffjlxE3kFBQZukQionqNwYmIiKgWsbdQ4cORzfDTM+3RwNEcKdn5mLXxPNq8uxOvrj+Ho9dvQ6MRhi6TiKje4Y0jiIiIaqFQP3tse7kzvjkUjbXHYhCTmoP1p2Kx/lQsPGxNMbylBx5t6Q5ve3NDl0pEVC8wOBEREdVSKoUcz3X1w7NdGuBEdBo2norFHxfiEZuWi493ReLjXZFo42OLR1t6oH9TV1iplYYumYiozmJwIiIiquUkSUJbXzu09bXD3MEh+PtSAjaejsXBqyk4EZ2GE9FpmLPlEvqGuOCxVh7o6O8AuUwydNlERHUKgxMREZERMTWRY2gLdwxt4Y6EjDxsPhOHjadjcTUpG1vO3cKWc7fgYqX+p40bAp0tIUkMUURED4vBiYiIyEi5WKvxfDc/PNe1Ac7HZmDDqVhsOXcLCZl5+HzfNXy+7xrcbUzRLdAR3QOd0MHfHmYmVftfvxACV5OycTw6Fdl5RZjQwQdqpbxK90FEVBswOBERERk5SZLQzNMGzTxt8NbAYOy+koSNp+NwIDIZcem5+PFYDH48FgMTuQztGtihe6ATugc5wddB/4klioo1uHQrEyeiU3E8KhUnolORlvPvvaYiErOxZERTnuUiojqHwYmIiKgOUSnk6NfEFf2auCK3oBhHr9/GnvAk7A5LQmxaLg5EpuBAZAre+f0yvO3N0D3QCd0CHdG+gX25Z4ryCotx9mY6TkSl4nh0Kk7fSMOdgmKdNmqlDM08bHDyRho2no5FsKslJnVuUFOHTERUIxiciIiI6ihTEzm6B5WcXZo3WOBa8h3sDU/CnvAkHI9KxY3bOVhzOBprDkdDrZShg58DuvjbIS5NwuXtkTgVk47zsRkoKNbobNdKrUAbn5LJKtr42qGxmzVMFDKsORSFuVsvY8GfV+DnZIHugU4GOnIioqrH4ERERFQPSJIEfycL+DtZYFLnBsjOL8KhqyklQSosGQmZedgdVnJmCpADYVHa1zpZqrSz+rXxsUOgsyVk5czaN6GDD8ISsrDuxE1MXXsGm6d0hL+TRQ0eJRFR9WFwIiIiqocsVAr0DXFB3xAXCCEQnpiFPWHJ2B2WiJjEVHQKdke7Bg5o52sHLzuzSl2zJEkS3hnSGNeSs3EiOg2TvzuJzS90hLUZ7y9FRMZPZugCiIiIyLAkSUKQixWe7+aHtU+3wRvNi/H+sMYY2doT3vbmek30YKKQYeXjreBuY4rrKXfw0rozKPrPUD8iImPE4ERERERVysFChS/Gt4KpUo79Ecl4f1uYoUsiInpoDE5ERERU5ULcrPHRyGYAgC8PRmH9yZsGroiI6OEwOBEREVG16NfEFS/3DAAAvLn5Ik7dSKuybe8JT8KsDedw9PrtKtsmEdH9MDgRERFRtXm5ZwAeCXFBQbEGz35/CvEZuQ+1veiUO3h6zQlM/OYEfjkZi9FfHMVz35/Cjdt3qqhiIqLyMTgRERFRtZHJJHw4shmCXCyRkp2Pyd+dQu5/bqBbGTkFRVj8dxj6LN2PXWFJUMgkdAt0hEwC/rqUgN4f7cfCP68gM6+wGo7i3xo0GlFt2yei2o3TkRMREVG1MlcpsHp8awz59BAuxGVg1sbz+Hh080rN1ieEwNbz8VjwxxUkZOYBADoHOGDOoBD4O1kgPCEL7/5xGQciU7Bq/3VsOBWLGX0aYlRrTyjkD//34bzCYmy7GI+fT9zE0eupcLAwQSd/B3Rp6IhOAQ5wslQ/9D6IyDgwOBEREVG187Qzw8pxLTHuy2PYeu4WglwsMaW7/31fcyU+E3O3XMKxqNR/tmGK/w1ohN6NnLWhK9DFEt891RZ7wpPw7h9XcD35Dt7cfBHfH7mBtwY0QqcAB71rFULgQlwGfjl5E7+dvYWsvCLtupTsAvx69hZ+PXsLABDkYomuDR3ROcARrX1soVbK9d4fERkHBiciIiKqEe0a2OOdIY3xxuYLWLI9HA2dLdG7kXOZduk5BVi6IwLfH70BjQDUShle6OaPyV0alBtMJElCjyBndA5wxA9Hb2DZzkiEJWTh8a+OoVewE97oH4wGjhYV1pd2pwC/no3DzyduIiwhS7vcw9YUI1t7YkhzN8Rn5OFAZDL2R6Tg4q0MhCVkISwhC6v2X4daKUM7X3t0Dig5IxXgZKHXPbCIqHZjcCIiIqIaM7adF8ISMvHdkRuYtu4MNk/piIbOlgCAYo3AzyduYvHfYUjLKblWaUATV8zuHwQPW7MKt62UyzCxoy+GtXDHsp2R+OHoDey8koS94ckYH+qDl3sGwNpMqfMajUbg0LUU/HziJrZfSkTBPzfrNVHI8EiIC0a18URoA3vIZCUByNveHO0b2OPVvsDt7HwcunYb+yOScSAyGYmZ+dgXkYx9EcnAH1fgYqVG5wAHdG7oiN7BzjA14dkoImPG4EREREQ16n8DGyEyMRtHrt/GpG9P4rcpHXE9JRtztlzCxbhMAEBDZwvMHRSCDv76D7WzMTPB3MEheLy9Nxb8eQW7w5Lw9aEobDoTi+m9GmJsOy8kZeVj/cmbWH8yFnHp/87018jVCqPalJxdsjEzue9+7C1UGNzMDYObuUEIgcikbOyPSMb+yBQcu34bCZl5WH8qFutPxSLIxRI/Tw4tE9yIyHgwOBEREVGNUspl+GxcSwz+9CBiUnMw4OMDuJVRMvGDpVqBGb0b4vH23lA+5OQO/k4W+PrJNtgfkYx3/7iMiMSScPbpnqtIzs6H+GeCPCu1AkNbuGNka080drd+oH1JkoSGzpZo6GyJSZ0bIK+wGCeiU3EgMgUbT8UiLCELT645jh+ebgdzFT9+ERkjvnOJiIioxtmam+DL8W0w/LNDuJWRB0kCRrbyxKuPBMLBQlWl++rS0BF/+nXGuhM38dGOCCRl5QMAOvjZY1QbT/QNcanySR3USjk6B5RMGjG8pTtGrTqKMzHpeOa7k/j6yTacRILICDE4ERERkUEEulji6yfbYMOpWDze3hvNPG2qbV8KuQyPt/fGoGZuOHLtNhq5WsHLvuLrpqpCkIsVvn2qLcatPorD127jxbVnsPLxlg99Ro2IahbfsURERGQw7RrYY/GIZtUamu5mbarEI41daiw0lWruaYMvJ7SBiUKGnVcS8er6c7yZLpGRYXAiIiIiqgGhfvZYOa4lFDIJv569hf/9dhFCMDwRGQsGJyIiIqIa0jPYGR+Nag5JAn48FoMP/g43dElEVEkMTkREREQ1aHAzN7w3tAkAYOXea/hs71UDV0QVycgt5NBK4uQQRERERDVtbDsvZOcXYsGfYfjgr3BYqhR4ItTH0GXRf2TkFmL2pvP480ICLNUKtPK2RWtvW7TytkNzTxve1LieYXAiIiIiMoDJXfyQlVeEFbuv4n+/XYKFWoFhLTweapt5hcU4GJmCwmINGrtbw8PWFJIkVVHF9cuZmDS89NMZxKaV3CA5K68Ie8OTsTc8GQCgkEkIcbNCax+7kjDlYwsnS7UhS6ZqxuBEREREZCAzejdEVl4R1hyOxivrz8PMRIG+IS56bUMIgVM30rDpTBx+P3cLmXlF2nVWagVC3KwR4maFxu7WaOxuBV8HC8hlDFP3otEIrD5wHYv/DkeRRsDLzgzLRjeHUibDyRupOBmdhpM3UpGYmY9zsRk4F5uBrw5GAQC87MzQ2scWrb3t0NrHFv6OFpDxe11nMDgRERERGYgkSXh7YCNk5xdhw6lYvLT2DL5+sg06BThU+Nobt+9g0+k4/Ho2Djdu52iXu1qrYWdugojELGTmFeHI9ds4cv22dr2pUo5gV0uEuJUEqRA3awQ4W0Cl4LCzlOx8zPzlHPZFlJxVGtjUFQuGN4GVWgkAaOJhjYkdfSGEQGxaLk7dSNOGqfDELMSk5iAmNQebTscBAGzMlBjf3hsvdPfnTY/rAAYnIiIiIgOSySS8P7wJ7uQXYdvFBDzz3Un8MKkdWnnblmmbkVOI3y/cwqbTcTh1I0273NxEjkcau+LRlu5o38AeMpmEgiINIpOycCkuE5duZeDirUxcic9ETkExTsek43RMuvb1SrmEhs6W6OjvgEmdfevlkLPDV1Mw7eezSMrKh1opw9xBIRjVxrPcoY6SJMHTzgyedmYY2sIdQMn1UGdi0krCVHQaztxMQ3pOIT7efRWbz8Zh3uAQ9AhyrunDoirE4ERERERkYAq5DMtGN0f2tydxIDIFE785jnWTQ9HIzQoFRRrsDU/C5jNx2HUlCQXFGgCATAI6BThieAt39AlxhpmJ7sc6E4Xsn2F61gA8AQDFGoGolDu4dCsDl25l4mJcyb8ZuYW4dCsTl25l4vsjNzChgw+e69oANmYmNf2tqHFFxRp8vCsSK/ZchRBAgJMFPh3XEg2dLfXajrWpEt0CndAt0AkAUFiswfZLiZj/+2XcTM3FU2tOoncjZ8wZ1AgetjV7A2aqGgxORERERLWASiHHqidaYfxXx3HyRhrGf30MjzR2wR/n45GWU6htF+RiiUdbemBIczc4Wel3Zkguk+DvZAF/JwsMaV5ypqR02Nm52HR8eSAKZ2+m4/N91/Dj0Rt4urMvnu7kC8t/hqoZWsztHGy/nIDo23fQytsWnQMc4WCheuDtxWfk4uWfzuJ4dCoAYHQbT8wZFFIls+Up5TIMaOqKboGO+HhXJL46GIUdlxNxIDIZL/UIwDOdG8BEwTsDGRMGJyIiIqJawsxEga8ntsGYL47i0q1M/HA0BgDgaKnC0OZuGNbCA43crKp0n3cPOxvQxBW7riRhyfZwhCVkYdnOSHx7OBrPdfXD+FCfGp9+WwiBS7cysf1SArZfTkRYQpZ2Xen3JsTNCl0aOqJLgCNaedtWOozsupKIV9afQ1pOISxUCiwY3gSDm7lV+TGYqxSY3T8Yj7bywFu/XsTxqFQs/jscG0/HYv6QxujoX/H1bLVVRm4hFDIJ5qr6ESnqx1ESERERGQkrtRLfPdUWr2+6AHMTOYa19EBHP3so5NV/dkKSJPRq5IweQU7482I8PtoRgevJd7BwWxi+PBiFF7v7Y3Rbz2qdSKKoWIPj0anYfikROy4nIi49V7tOLpPQztcOgS6WOHY9FZfjM7VDDFfuvQZzEzlC/ezRpaEjOgc4wsferMw1SgVFGry/LQxfHyqZCa+JuzVWjGkBHwfzajsmAGjobImfJ7fHr2fj8N4fYbiefAfjvjyGQc3c8NaAYDjrefbQkPKLivHlgSh8svsq5DIJz3RugKc7+8Kijgeoun10REREREbI3kKF1eNbG2z/MpmEgU3d8EiICzaficPyXZGITcvFnC2X8MX+63i5ZwCGt3SvsjCXW1CM/ZHJ2H4pEbvCEpF+19BEU6UcXRs6ok9ISaC7+7qr5Kx8HLyajP0RKTgQmYyU7ALsvJKEnVeSAACedqboEuCILg0d0cHPHql3CvDi2jO4EJcBAHiqoy9e6xdYYzMKSpKEYS080CPIGR9tD8f3R29g67lb2BOWhOm9G2JCqHeNBOSHsT8iGXO3XML1lDvaZUt3RuDbI9F4oZsfHm/vXWdnEGRwIiIiIqJyKeQyjGjtiSHN3fHzyZv4ZHck4tJzMWvjeXy+7xqm9W6IvkGVH2pWrBHIzitCZl4hMvMKcSU+C9svJWB/ZDLyCjXadrZmSvQMdkbfEBd08ne45xBBR0sVhrXwwLAWHtBoBC7HZ+JAZAr2RyTj5I1U3EzNxY/HYvDjsRgoZBIUcgl5hRrYmCmx5LFm6NXIMLPcWZsqMW9IY4xo7Yk3f72IczfTMf/3y1h/8ibeHdoYrX3sDFLX/cSl52L+1sv461ICAMDBQoU3+gfBRCHDR9sjcD3lDt794wq+OhiFqT0D8FgrDyhreQjUF4MTEREREd2XiUKGJ9p7Y0QrD3x/5AZW7ruG6yl3MPWnMwh0tkAjUwk390chp1CDzLxCZOUVISuvCJm5JV+XLsvOL7rnPtxtTNEnpCQstfa21fvMi0wm/XOTX2s8380Pd/KLcPT6beyPSMaByBRcT7mDIo1AGx9bLB/dAm42pg/7bXlojd2tsfn5Dvj55E0s+isMYQlZeOzzIxjRygPPd/ODr4N5udOh16TSYXkrdkcir1ADuUzChFAfTOsdoL2/1SMhLth4OhbLd0biVkYeZm+6gC/2X8f03g0xsIlrnbkJMIMTEREREVWKWinHM10aYEw7L3xzMApfHLiO8MRshEMOREdWejsqhQyWaiVcrdXoHuSEviHOaORqVaUhwVylQM9gZ/QMLjmrdDM1B0lZ+WjmYV2rhsPJZBLGtPVC3xAXLNoWhp9P3sT6U7FYfyoW7jam6BzggM4Bjujob1/j08PvDU/CvK2XEfXPsLy2PnZ4Z2gIglx0JyhRyGUY1cYLQ5q748djMfh0z1VE/ROsP9tzFa/2DUSPICeDh8CHxeBERERERHqxUCnwUs8APBHqja8OXMO+c1fh5+0BGzMTWKqVsFIrYKVWwlKtKHluWvJvyXNFjV1TdLfSmQNrKztzEyx6rClGtvHEsp0ROHY9FXHpuVh34ibWnbgJSQKaulujc4AjOgU4oKVX5WcQ1NfN1BzM//0ytl9OBFAyJPLN/sEY0tztvuFHrZTj6U6+GNXGE18fjMLq/dcRlpCFp789iVbetni1byDaN7CvlpprAoMTERERET0QGzMTTO3hD/+8CPTv3xhKZe2435Mxa+Vti++fboecgiIci0rFwciSiS8iErNxLjYD52Iz8MmeqzAzkSO0gT06/XNGys/x4Yf15RUWY/X+6/hkz1XkF5UMy3uygw+m9QrQ615eFioFpvYMwBPtvfH5/mtYcygap26kYfQXR9E5wAEzevo/VJ2GwuBERERERFTLmJko0D3QCd0DnQAACRl5OHi1JEQdjEzB7TsF2BWWhF1hJTMIulqr0TnAAb4OFrBQK2CpUsBCpYCFuuRfS/W/z8s747cnLAlzt17Cjds5AIB2vnZ4Z0hjBLpYPvAx2JqbYHa/YDzV0Rcrdkdi3fGbOBCZggORKWhmJ0PT0Fz4OhlP2GZwIiIiIiKq5Vys1XislQcea1Uyg+CVhJIZBA9GpuB4dCriM/Lwy8nYSm3LRC7TBqrSey9djs8EADhZqvDmgGAMbnb/YXn6cLZS492hTfBM5wZYtjMSv56Nw8U0CQKiSrZfUxiciIiIiIiMiEwmIcTNGiFu1niuqx9yC4pxIjoVh6/dRnJWPrLzC5GdX4Ts/GJk5/3zdV4R7hQUAwAKijVIvVOA1DsF2m0qZBImdvTB1J76DcvTh7e9OZaOao5JHb3w/Z8H4Wlbe685Kw+DExERERGRETM1kaNLw5Ib/d5PsUbgTkFJiMrOL9JOEX8nvwiNXK3g42BeI/U2dLZEqLNxnW0CGJyIiIiIiOoFuUyClVqpvf8S6af2TGJPRERERERUSzE4ERERERERVYDBiYiIiIiIqAIMTkRERERERBVgcCIiIiIiIqoAgxMREREREVEFGJyIiIiIiIgqwOBERERERERUAQYnIiIiIiKiCjA4ERERERERVYDBiYiIiIiIqAIMTkRERERERBVgcCIiIiIiIqoAgxMREREREVEFGJyIiIiIiIgqwOBERERERERUAQYnIiIiIiKiCjA4ERERERERVYDBiYiIiIiIqAIMTkRERERERBVgcCIiIiIiIqoAgxMREREREVEFGJyIiIiIiIgqwOBERERERERUAQYnIiIiIiKiCjA4ERERERERVYDBiYiIiIiIqAIMTkRERERERBVgcCIiIiIiIqoAgxMREREREVEFGJyIiIiIiIgqwOBERERERERUAQYnIiIiIiKiCjA4ERERERERVYDBiYiIiIiIqAK1Jji9//77kCQJ06ZNu2ebNWvWQJIknYdara65IomIiIiIqF5SGLoAADhx4gRWrVqFpk2bVtjWysoK4eHh2ueSJFVnaURERERERIY/45SdnY1x48Zh9erVsLW1rbC9JElwcXHRPpydnWugSiIiIiIiqs8MfsZpypQpGDBgAHr16oV33323wvbZ2dnw9vaGRqNBy5YtsWDBAoSEhNyzfX5+PvLz87XPMzIyAACpqakoLCx8+AN4CIWFhcjJycHt27ehVCoNWgsZB/YZ0hf7DOmLfYb0xT5D+qpNfSYrKwsAIISosK1Bg9O6detw+vRpnDhxolLtAwMD8fXXX6Np06bIyMjAkiVL0KFDB1y6dAkeHh7lvmbhwoWYN29emeW+vr4PVTsREREREdUNWVlZsLa2vm8bSVQmXlWDmzdvonXr1tixY4f22qZu3bqhefPmWLZsWaW2UVhYiODgYIwZMwbz588vt81/zzhpNBqkpqbC3t7e4NdHZWZmwtPTEzdv3oSVlZVBayHjwD5D+mKfIX2xz5C+2GdIX7WpzwghkJWVBTc3N8hk97+KyWBnnE6dOoWkpCS0bNlSu6y4uBj79+/HJ598gvz8fMjl8vtuQ6lUokWLFrh69eo926hUKqhUKp1lNjY2D1V7VbOysjJ4pyHjwj5D+mKfIX2xz5C+2GdIX7Wlz1R0pqmUwYJTz549ceHCBZ1lEydORFBQEF577bUKQxNQErQuXLiA/v37V1eZREREREREhgtOlpaWaNy4sc4yc3Nz2Nvba5ePHz8e7u7uWLhwIQDgnXfeQfv27eHv74/09HQsXrwYN27cwKRJk2q8fiIiIiIiqj8MPqve/cTExOiMNUxLS8MzzzyDhIQE2NraolWrVjh8+DAaNWpkwCofnEqlwpw5c8oMJSS6F/YZ0hf7DOmLfYb0xT5D+jLWPmOwySGIiIiIiIiMhcFvgEtERERERFTbMTgRERERERFVgMGJiIiIiIioAgxOREREREREFWBwMqBPP/0UPj4+UKvVaNeuHY4fP27okqgG7N+/H4MGDYKbmxskScKvv/6qs14Igbfffhuurq4wNTVFr169EBkZqdMmNTUV48aNg5WVFWxsbPD0008jOztbp8358+fRuXNnqNVqeHp64oMPPqjuQ6NqsnDhQrRp0waWlpZwcnLC0KFDER4ertMmLy8PU6ZMgb29PSwsLPDoo48iMTFRp01MTAwGDBgAMzMzODk54dVXX0VRUZFOm71796Jly5ZQqVTw9/fHmjVrqvvwqBqsXLkSTZs21d5cMjQ0FNu2bdOuZ3+h+3n//fchSRKmTZumXcY+Q/81d+5cSJKk8wgKCtKur5N9RpBBrFu3TpiYmIivv/5aXLp0STzzzDPCxsZGJCYmGro0qmZ//vmnePPNN8WmTZsEALF582ad9e+//76wtrYWv/76qzh37pwYPHiw8PX1Fbm5udo2jzzyiGjWrJk4evSoOHDggPD39xdjxozRrs/IyBDOzs5i3Lhx4uLFi+Knn34SpqamYtWqVTV1mFSF+vbtK7755htx8eJFcfbsWdG/f3/h5eUlsrOztW2ee+454enpKXbt2iVOnjwp2rdvLzp06KBdX1RUJBo3bix69eolzpw5I/7880/h4OAgZs+erW1z/fp1YWZmJmbMmCEuX74sVqxYIeRyufjrr79q9Hjp4W3ZskX88ccfIiIiQoSHh4s33nhDKJVKcfHiRSEE+wvd2/Hjx4WPj49o2rSpePnll7XL2Wfov+bMmSNCQkJEfHy89pGcnKxdXxf7DIOTgbRt21ZMmTJF+7y4uFi4ubmJhQsXGrAqqmn/DU4ajUa4uLiIxYsXa5elp6cLlUolfvrpJyGEEJcvXxYAxIkTJ7Rttm3bJiRJEnFxcUIIIT777DNha2sr8vPztW1ee+01ERgYWM1HRDUhKSlJABD79u0TQpT0EaVSKdavX69tc+XKFQFAHDlyRAhREthlMplISEjQtlm5cqWwsrLS9pNZs2aJkJAQnX2NGjVK9O3bt7oPiWqAra2t+PLLL9lf6J6ysrJEQECA2LFjh+jatas2OLHPUHnmzJkjmjVrVu66utpnOFTPAAoKCnDq1Cn06tVLu0wmk6FXr144cuSIASsjQ4uKikJCQoJO37C2tka7du20fePIkSOwsbFB69attW169eoFmUyGY8eOadt06dIFJiYm2jZ9+/ZFeHg40tLSauhoqLpkZGQAAOzs7AAAp06dQmFhoU6/CQoKgpeXl06/adKkCZydnbVt+vbti8zMTFy6dEnb5u5tlLbh7yXjVlxcjHXr1uHOnTsIDQ1lf6F7mjJlCgYMGFDm58o+Q/cSGRkJNzc3NGjQAOPGjUNMTAyAuttnGJwMICUlBcXFxTodBQCcnZ2RkJBgoKqoNij9+d+vbyQkJMDJyUlnvUKhgJ2dnU6b8rZx9z7IOGk0GkybNg0dO3ZE48aNAZT8TE1MTGBjY6PT9r/9pqI+ca82mZmZyM3NrY7DoWp04cIFWFhYQKVS4bnnnsPmzZvRqFEj9hcq17p163D69GksXLiwzDr2GSpPu3btsGbNGvz1119YuXIloqKi0LlzZ2RlZdXZPqOo8T0SEdEDmzJlCi5evIiDBw8auhSq5QIDA3H27FlkZGRgw4YNmDBhAvbt22fosqgWunnzJl5++WXs2LEDarXa0OWQkejXr5/266ZNm6Jdu3bw9vbGL7/8AlNTUwNWVn14xskAHBwcIJfLy8wskpiYCBcXFwNVRbVB6c//fn3DxcUFSUlJOuuLioqQmpqq06a8bdy9DzI+L774In7//Xfs2bMHHh4e2uUuLi4oKChAenq6Tvv/9puK+sS92lhZWdXZ/wTrMhMTE/j7+6NVq1ZYuHAhmjVrhuXLl7O/UBmnTp1CUlISWrZsCYVCAYVCgX379uHjjz+GQqGAs7Mz+wxVyMbGBg0bNsTVq1fr7O8ZBicDMDExQatWrbBr1y7tMo1Gg127diE0NNSAlZGh+fr6wsXFRadvZGZm4tixY9q+ERoaivT0dJw6dUrbZvfu3dBoNGjXrp22zf79+1FYWKhts2PHDgQGBsLW1raGjoaqihACL774IjZv3ozdu3fD19dXZ32rVq2gVCp1+k14eDhiYmJ0+s2FCxd0QveOHTtgZWWFRo0aadvcvY3SNvy9VDdoNBrk5+ezv1AZPXv2xIULF3D27Fnto3Xr1hg3bpz2a/YZqkh2djauXbsGV1fXuvt7xiBTUpBYt26dUKlUYs2aNeLy5cti8uTJwsbGRmdmEaqbsrKyxJkzZ8SZM2cEAPHRRx+JM2fOiBs3bgghSqYjt7GxEb/99ps4f/68GDJkSLnTkbdo0UIcO3ZMHDx4UAQEBOhMR56eni6cnZ3FE088IS5evCjWrVsnzMzMOB25kXr++eeFtbW12Lt3r860rzk5Odo2zz33nPDy8hK7d+8WJ0+eFKGhoSI0NFS7vnTa1z59+oizZ8+Kv/76Szg6OpY77eurr74qrly5Ij799FNOFWykXn/9dbFv3z4RFRUlzp8/L15//XUhSZLYvn27EIL9hSp296x6QrDPUFkzZ84Ue/fuFVFRUeLQoUOiV69ewsHBQSQlJQkh6mafYXAyoBUrVggvLy9hYmIi2rZtK44ePWrokqgG7NmzRwAo85gwYYIQomRK8v/973/C2dlZqFQq0bNnTxEeHq6zjdu3b4sxY8YICwsLYWVlJSZOnCiysrJ02pw7d0506tRJqFQq4e7uLt5///2aOkSqYuX1FwDim2++0bbJzc0VL7zwgrC1tRVmZmZi2LBhIj4+Xmc70dHRol+/fsLU1FQ4ODiImTNnisLCQp02e/bsEc2bNxcmJiaiQYMGOvsg4/HUU08Jb29vYWJiIhwdHUXPnj21oUkI9heq2H+DE/sM/deoUaOEq6urMDExEe7u7mLUqFHi6tWr2vV1sc9IQghhmHNdRERERERExoHXOBERERER/b+duwmJcovjOP6d6YoTjFE7h0hlCCoXQg+9SUFEhQXRC2MlBCHRQEUYtAgMLMaKUKigRRISGSS9mGQSLSIhkEKqhUNviEStlAijRSVZ0V3cmIt047nBvfnC9wPP4sw555lzZjP8+D/PkUIYnCRJkiQphMFJkiRJkkIYnCRJkiQphMFJkiRJkkIYnCRJkiQphMFJkiRJkkIYnCRJkiQphMFJkiRJkkIYnCRJE86bN2/YvXs3RUVF5OfnU1hYSEVFBffu3QMgEonQ0dExtouUJE0qf4z1AiRJ+lWpVIqRkREuXLhAMpnk9evXdHV1MTQ0NNZLkyRNUlacJEkTyrt37+ju7qahoYEVK1ZQXFzMokWLqK2tZf369ZSUlACwadMmIpFIrg1w48YNgiAgFouRTCbJZDJ8+fIl1x+JRGhqamLt2rVMnTqVZDLJtWvXcv0jIyPs3buXRCJBLBajuLiY48eP/66tS5LGkMFJkjShxONx4vE4HR0dfPr06Yf+hw8fAnD+/HkGBwdz7e7ubrZv386+fft49uwZZ8+epaWlhWPHjo2aX1dXRyqVIpvNsm3bNqqqqnj+/DkAp0+fprOzk6tXr9LX10dra+uoYCZJmrwi3759+zbWi5Ak6Ve0t7eTTqcZHh4mCAKWL19OVVUVZWVlwF+Vo+vXr7Nx48bcnFWrVrFy5Upqa2tzn128eJEDBw4wMDCQm7dr1y6amppyY5YsWUIQBJw5c4aamhqePn3KnTt3iEQiv2ezkqRxwYqTJGnCSaVSDAwM0NnZyZo1a7h79y5BENDS0vLTOdlslvr6+lzFKh6Pk06nGRwc5OPHj7lx5eXlo+aVl5fnKk7V1dX09vYyZ84campquH379v+yP0nS+GNwkiRNSLFYjNWrV1NXV8f9+/eprq7m8OHDPx3//v17MpkMvb29uevx48f09/cTi8X+1XcGQcDLly85cuQIw8PDbNmyhcrKyv9qS5KkcczgJEmaFEpLS/nw4QMAeXl5fP36dVR/EAT09fUxe/bsH65o9O+/w56enlHzenp6mDdvXq49bdo0tm7dSnNzM1euXKG9vZ23b9/+jzuTJI0HHkcuSZpQhoaG2Lx5Mzt27KCsrIyCggIePXpEY2MjGzZsAKCkpISuri6WLl1Kfn4+M2bM4NChQ6xbt46ioiIqKyuJRqNks1mePHnC0aNHc/dva2tjwYIFLFu2jNbWVh48eMC5c+cAOHnyJIlEgvnz5xONRmlra6OwsJDp06ePxU8hSfqNDE6SpAklHo+zePFiTp06xYsXL/j8+TOzZs0inU5z8OBBAE6cOMH+/ftpbm5m5syZvHr1ioqKCm7evEl9fT0NDQ3k5eUxd+5cdu7cOer+mUyGy5cvs2fPHhKJBJcuXaK0tBSAgoICGhsb6e/vZ8qUKSxcuJBbt26NqlhJkiYnT9WTJOm7fzqNT5Ik8B0nSZIkSQplcJIkSZKkEL7jJEnSdz69Lkn6GStOkiRJkhTC4CRJkiRJIQxOkiRJkhTC4CRJkiRJIQxOkiRJkhTC4CRJkiRJIQxOkiRJkhTC4CRJkiRJIf4EL4kDVh2GuFMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x, y)\n",
    "# plt.yscale('log')\n",
    "plt.ylim([4.5, 6.5])\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.yticks([4.5, 5, 5.5, 6, 6.5])\n",
    "plt.title('BUS nGPT vs. Standard nGPT Model Performance')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 22:35:49.166974: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732941349.185029  202481 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732941349.190484  202481 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-29 22:35:49.208146: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments, EvalPrediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('stanfordnlp/snli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = BertTokenizerFast.from_pretrained('google-bert/bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tok(examples[\"premise\"] + examples['hypothesis'] , padding=False, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_acc(eval: EvalPrediction):\n",
    "    return {\n",
    "        'accuracy' : (np.argmax(\n",
    "            eval.predictions,\n",
    "            axis=1) == eval.label_ids).astype(\n",
    "            np.float32).mean().item()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tok = dataset.map(tokenize_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_func(example):\n",
    "    return {'label': example['label']} if example['label'] >= 0 else {'label':-example['label']}\n",
    "\n",
    "test_tok = test_tok.map(abs_func, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([183416, 183549, 183187]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(test_tok['train']['label'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_202481/1794072402.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load('101M-512-std-model-512con.pt')\n",
      "/home/brian/Desktop/school/extra/transformer_pretrain/transfer_transformers/NLP/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of  Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_202481/1794072402.py:16: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('101M-512-std-model-512con.pt')\n",
    "model.to('cuda')\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "\toutput_dir=\"output\", \n",
    "\tevaluation_strategy=\"steps\", \n",
    "\tnum_train_epochs = 2,\n",
    "\twarmup_steps = 10,\n",
    "\tlogging_steps = 2000,\n",
    "\tsave_steps = 2000,\n",
    "\tload_best_model_at_end = True,\n",
    "\tlearning_rate = 5e-4,\n",
    "    per_device_train_batch_size=64\n",
    "\t)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=test_tok['train'],\n",
    "    eval_dataset=test_tok['validation'],\n",
    "    tokenizer=tok,\n",
    "    compute_metrics=compute_acc\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51c2bdfaffe743ee901ccb9a5bdaa52a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17194 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided ['label']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/school/extra/transformer_pretrain/transfer_transformers/NLP/lib/python3.10/site-packages/transformers/trainer.py:2123\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2121\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2124\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/school/extra/transformer_pretrain/transfer_transformers/NLP/lib/python3.10/site-packages/transformers/trainer.py:2427\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2425\u001b[0m update_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2426\u001b[0m num_batches \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps \u001b[38;5;28;01mif\u001b[39;00m update_step \u001b[38;5;241m!=\u001b[39m (total_updates \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m remainder\n\u001b[0;32m-> 2427\u001b[0m batch_samples, num_items_in_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_batch_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_batches\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2428\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch_samples):\n\u001b[1;32m   2429\u001b[0m     step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/school/extra/transformer_pretrain/transfer_transformers/NLP/lib/python3.10/site-packages/transformers/trainer.py:5045\u001b[0m, in \u001b[0;36mTrainer.get_batch_samples\u001b[0;34m(self, epoch_iterator, num_batches)\u001b[0m\n\u001b[1;32m   5043\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_batches):\n\u001b[1;32m   5044\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 5045\u001b[0m         batch_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m   5046\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m   5047\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/school/extra/transformer_pretrain/transfer_transformers/NLP/lib/python3.10/site-packages/accelerate/data_loader.py:552\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 552\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/school/extra/transformer_pretrain/transfer_transformers/NLP/lib/python3.10/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/Desktop/school/extra/transformer_pretrain/transfer_transformers/NLP/lib/python3.10/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/Desktop/school/extra/transformer_pretrain/transfer_transformers/NLP/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/school/extra/transformer_pretrain/transfer_transformers/NLP/lib/python3.10/site-packages/transformers/data/data_collator.py:271\u001b[0m, in \u001b[0;36mDataCollatorWithPadding.__call__\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, features: List[Dict[\u001b[38;5;28mstr\u001b[39m, Any]]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m--> 271\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[43mpad_without_fast_tokenizer_warning\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m batch:\n\u001b[1;32m    280\u001b[0m         batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/school/extra/transformer_pretrain/transfer_transformers/NLP/lib/python3.10/site-packages/transformers/data/data_collator.py:66\u001b[0m, in \u001b[0;36mpad_without_fast_tokenizer_warning\u001b[0;34m(tokenizer, *pad_args, **pad_kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mdeprecation_warnings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsking-to-pad-a-fast-tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 66\u001b[0m     padded \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpad_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpad_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# Restore the state of the warning.\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     tokenizer\u001b[38;5;241m.\u001b[39mdeprecation_warnings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsking-to-pad-a-fast-tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m warning_state\n",
      "File \u001b[0;32m~/Desktop/school/extra/transformer_pretrain/transfer_transformers/NLP/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3458\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.pad\u001b[0;34m(self, encoded_inputs, padding, max_length, pad_to_multiple_of, padding_side, return_attention_mask, return_tensors, verbose)\u001b[0m\n\u001b[1;32m   3456\u001b[0m \u001b[38;5;66;03m# The model's main input name, usually `input_ids`, has been passed for padding\u001b[39;00m\n\u001b[1;32m   3457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_input_names[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m encoded_inputs:\n\u001b[0;32m-> 3458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3459\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou should supply an encoding or a list of encodings to this method \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3460\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthat includes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_input_names[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but you provided \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(encoded_inputs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3461\u001b[0m     )\n\u001b[1;32m   3463\u001b[0m required_input \u001b[38;5;241m=\u001b[39m encoded_inputs[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_input_names[\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m   3465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m required_input \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(required_input, Sized) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(required_input) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n",
      "\u001b[0;31mValueError\u001b[0m: You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided ['label']"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'premise': 'This church choir sings to the masses as they sing joyous songs from the book at a church.',\n",
       " 'hypothesis': 'The church has cracks in the ceiling.',\n",
       " 'label': 1,\n",
       " 'input_ids': [[101,\n",
       "   2023,\n",
       "   2277,\n",
       "   6596,\n",
       "   10955,\n",
       "   2000,\n",
       "   1996,\n",
       "   11678,\n",
       "   2004,\n",
       "   2027,\n",
       "   6170,\n",
       "   6569,\n",
       "   3560,\n",
       "   2774,\n",
       "   2013,\n",
       "   1996,\n",
       "   2338,\n",
       "   2012,\n",
       "   1037,\n",
       "   2277,\n",
       "   1012,\n",
       "   1996,\n",
       "   2277,\n",
       "   2038,\n",
       "   15288,\n",
       "   1999,\n",
       "   1996,\n",
       "   5894,\n",
       "   1012,\n",
       "   102]],\n",
       " 'token_type_ids': [[0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0]],\n",
       " 'attention_mask': [[1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1]]}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tok[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_fn(x):\n",
    "    ids, lab = [], []\n",
    "    for i in x:\n",
    "        ids.append(i['input_ids'])\n",
    "        lab.append(i['label'])\n",
    "    return torch.tensor(ids), torch.tensor(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "DL = DataLoader(test_tok, batch_size=32, shuffle=True, collate_fn=col_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'premise': 'A man is celebrating his victory while smiling and shooting champagne in the air with his teammate.', 'hypothesis': 'A man is celebrating his victory while smiling and shooting champagne in the air', 'label': 0, 'input_ids': [101, 1037, 2158, 2003, 12964, 2010, 3377, 2096, 5629, 1998, 5008, 12327, 1999, 1996, 2250, 2007, 2010, 10809, 1012, 1037, 2158, 2003, 12964, 2010, 3377, 2096, 5629, 1998, 5008, 12327, 1999, 1996, 2250, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'An emergency worker directs a man pulling a sled with emergency equipment on a snowy path.', 'hypothesis': 'An emergency worker works at a crash scene.', 'label': 1, 'input_ids': [101, 2019, 5057, 7309, 23303, 1037, 2158, 4815, 1037, 22889, 2098, 2007, 5057, 3941, 2006, 1037, 20981, 4130, 1012, 2019, 5057, 7309, 2573, 2012, 1037, 5823, 3496, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'A man wearing an oxford shirt, sunglasses, and a hat smirks.', 'hypothesis': 'A man with his outfit', 'label': 0, 'input_ids': [101, 1037, 2158, 4147, 2019, 4345, 3797, 1010, 17072, 1010, 1998, 1037, 6045, 15081, 2015, 1012, 1037, 2158, 2007, 2010, 11018, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'A crowd of people shopping at a street market in an urban area with buildings and a statue in background.', 'hypothesis': 'The crowd of people are inside a mall.', 'label': 2, 'input_ids': [101, 1037, 4306, 1997, 2111, 6023, 2012, 1037, 2395, 3006, 1999, 2019, 3923, 2181, 2007, 3121, 1998, 1037, 6231, 1999, 4281, 1012, 1996, 4306, 1997, 2111, 2024, 2503, 1037, 6670, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'A female within the foreground is heading towards a large white colored pillar that is apart of a large building with people are loitering or waiting on the steps of said building.', 'hypothesis': 'There are several people outside of a building.', 'label': 0, 'input_ids': [101, 1037, 2931, 2306, 1996, 18921, 16365, 2003, 5825, 2875, 1037, 2312, 2317, 6910, 14809, 2008, 2003, 4237, 1997, 1037, 2312, 2311, 2007, 2111, 2024, 8840, 21646, 2075, 2030, 3403, 2006, 1996, 4084, 1997, 2056, 2311, 1012, 2045, 2024, 2195, 2111, 2648, 1997, 1037, 2311, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'Three children are playing on a swing in the garden.', 'hypothesis': 'Three children are playing on a blue swing set.', 'label': 1, 'input_ids': [101, 2093, 2336, 2024, 2652, 2006, 1037, 7370, 1999, 1996, 3871, 1012, 2093, 2336, 2024, 2652, 2006, 1037, 2630, 7370, 2275, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'A black dog is swimming with a ball in his mouth.', 'hypothesis': 'The dog is asleep in the grass.', 'label': 2, 'input_ids': [101, 1037, 2304, 3899, 2003, 5742, 2007, 1037, 3608, 1999, 2010, 2677, 1012, 1996, 3899, 2003, 6680, 1999, 1996, 5568, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'A woman in a spaghetti strap tank wearing a flower in her hair is staring towards the right.', 'hypothesis': 'A woman is looking at something to her right.', 'label': 0, 'input_ids': [101, 1037, 2450, 1999, 1037, 26666, 16195, 4951, 4147, 1037, 6546, 1999, 2014, 2606, 2003, 4582, 2875, 1996, 2157, 1012, 1037, 2450, 2003, 2559, 2012, 2242, 2000, 2014, 2157, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'Woman is looking something.', 'hypothesis': 'A woman is looking', 'label': 0, 'input_ids': [101, 2450, 2003, 2559, 2242, 1012, 1037, 2450, 2003, 2559, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'A dirty, shirtless homeless man sits on the sidewalk, holding his cup up to passerby asking for change.', 'hypothesis': 'A homeless man begs.', 'label': 0, 'input_ids': [101, 1037, 6530, 1010, 3797, 3238, 11573, 2158, 7719, 2006, 1996, 11996, 1010, 3173, 2010, 2452, 2039, 2000, 3413, 2121, 3762, 4851, 2005, 2689, 1012, 1037, 11573, 2158, 27591, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'A female in the middle of a vehicle is holding a camera and is pointing it towards the backseat.', 'hypothesis': 'A girl is inside a vehicle.', 'label': 0, 'input_ids': [101, 1037, 2931, 1999, 1996, 2690, 1997, 1037, 4316, 2003, 3173, 1037, 4950, 1998, 2003, 7302, 2009, 2875, 1996, 19978, 1012, 1037, 2611, 2003, 2503, 1037, 4316, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'A worker shoveling dirt into a wheelbarrow.', 'hypothesis': 'A worker uses a shovel.', 'label': 0, 'input_ids': [101, 1037, 7309, 24596, 2075, 6900, 2046, 1037, 5217, 8237, 10524, 1012, 1037, 7309, 3594, 1037, 24596, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'Two men prepare a fish at a dock.', 'hypothesis': 'Two men are cleaning their fish', 'label': 0, 'input_ids': [101, 2048, 2273, 7374, 1037, 3869, 2012, 1037, 8946, 1012, 2048, 2273, 2024, 9344, 2037, 3869, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'Two African American men laughing with aprons on, while a third man wearing a chef jacket is on a cellular phone.', 'hypothesis': 'Three African American men work together in the food industry.', 'label': 1, 'input_ids': [101, 2048, 3060, 2137, 2273, 5870, 2007, 20376, 2015, 2006, 1010, 2096, 1037, 2353, 2158, 4147, 1037, 10026, 6598, 2003, 2006, 1037, 12562, 3042, 1012, 2093, 3060, 2137, 2273, 2147, 2362, 1999, 1996, 2833, 3068, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'A young man in a backwards baseball cap balances his skateboard on the edge of the concrete.', 'hypothesis': 'The man breaks his skateboard', 'label': 2, 'input_ids': [101, 1037, 2402, 2158, 1999, 1037, 11043, 3598, 6178, 5703, 2015, 2010, 17260, 6277, 2006, 1996, 3341, 1997, 1996, 5509, 1012, 1996, 2158, 7807, 2010, 17260, 6277, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'People dressed in traditional Japanese garb walk in a procession through a courtyard paved with paving stones.', 'hypothesis': \"People dressed like circus clowns entertain at a child's birthday party.\", 'label': 2, 'input_ids': [101, 2111, 5102, 1999, 3151, 2887, 11721, 15185, 3328, 1999, 1037, 14385, 2083, 1037, 10119, 12308, 2007, 28007, 6386, 1012, 2111, 5102, 2066, 9661, 15912, 2015, 20432, 2012, 1037, 2775, 1005, 1055, 5798, 2283, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'A man in a navy blue shirt is tossing a boy with a large smile on his face high into the air.', 'hypothesis': 'A man tossing a child into the air.', 'label': 0, 'input_ids': [101, 1037, 2158, 1999, 1037, 3212, 2630, 3797, 2003, 15021, 1037, 2879, 2007, 1037, 2312, 2868, 2006, 2010, 2227, 2152, 2046, 1996, 2250, 1012, 1037, 2158, 15021, 1037, 2775, 2046, 1996, 2250, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'A man in orange and a man in a light blue top are walking down the street towards something.', 'hypothesis': 'Two men are watchin TV inside', 'label': 2, 'input_ids': [101, 1037, 2158, 1999, 4589, 1998, 1037, 2158, 1999, 1037, 2422, 2630, 2327, 2024, 3788, 2091, 1996, 2395, 2875, 2242, 1012, 2048, 2273, 2024, 3422, 2378, 2694, 2503, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'People enjoying food outside of a restaurant.', 'hypothesis': \"Some people enjoying their brunch together in the outdoor seating area of a restaurant for mother's day.\", 'label': 1, 'input_ids': [101, 2111, 9107, 2833, 2648, 1997, 1037, 4825, 1012, 2070, 2111, 9107, 2037, 7987, 4609, 2818, 2362, 1999, 1996, 7254, 10747, 2181, 1997, 1037, 4825, 2005, 2388, 1005, 1055, 2154, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'Guy in uniform standing on the side of a boat moving through the water.', 'hypothesis': 'A man in the Navy stands on a boat in the cool air.', 'label': 1, 'input_ids': [101, 3124, 1999, 6375, 3061, 2006, 1996, 2217, 1997, 1037, 4049, 3048, 2083, 1996, 2300, 1012, 1037, 2158, 1999, 1996, 3212, 4832, 2006, 1037, 4049, 1999, 1996, 4658, 2250, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': \"A man in a gray shirt and blue shorts is standing outside of an old fashioned ice cream shop named Sara's Old Fashioned Ice Cream, holding his bike up, with a wood like table, chairs, benches in front of him.\", 'hypothesis': 'A man is riding his bike', 'label': 1, 'input_ids': [101, 1037, 2158, 1999, 1037, 3897, 3797, 1998, 2630, 9132, 2003, 3061, 2648, 1997, 2019, 2214, 13405, 3256, 6949, 4497, 2315, 7354, 1005, 1055, 2214, 13405, 3256, 6949, 1010, 3173, 2010, 7997, 2039, 1010, 2007, 1037, 3536, 2066, 2795, 1010, 8397, 1010, 19571, 1999, 2392, 1997, 2032, 1012, 1037, 2158, 2003, 5559, 2010, 7997, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'A group of men in blue shirts, banded hats, and red bandannas stand in a group.', 'hypothesis': 'a bunch of eagles are eating a bug', 'label': 2, 'input_ids': [101, 1037, 2177, 1997, 2273, 1999, 2630, 11344, 1010, 25264, 16717, 1010, 1998, 2417, 24112, 9516, 2015, 3233, 1999, 1037, 2177, 1012, 1037, 9129, 1997, 8125, 2024, 5983, 1037, 11829, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'an old shoemaker in his factory', 'hypothesis': 'The shoemaker is getting ready for his 16th birthday.', 'label': 2, 'input_ids': [101, 2019, 2214, 10818, 8571, 1999, 2010, 4713, 10760, 10818, 8571, 2003, 2893, 3201, 2005, 2010, 5767, 5798, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'At least six individuals are on a team wearing helmets and knee pads while rollerblading around a skating rink.', 'hypothesis': \"People don't know how to skate.\", 'label': 2, 'input_ids': [101, 2012, 2560, 2416, 3633, 2024, 2006, 1037, 2136, 4147, 22674, 1998, 6181, 19586, 2096, 11220, 28522, 4667, 2105, 1037, 10080, 18416, 1012, 2111, 2123, 1005, 1056, 2113, 2129, 2000, 17260, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'A man is shooting a gun outdoors, on what looks like a beautiful sunny day.', 'hypothesis': 'A man is shooting a bow and arrow on a rainy day.', 'label': 2, 'input_ids': [101, 1037, 2158, 2003, 5008, 1037, 3282, 19350, 1010, 2006, 2054, 3504, 2066, 1037, 3376, 11559, 2154, 1012, 1037, 2158, 2003, 5008, 1037, 6812, 1998, 8612, 2006, 1037, 16373, 2154, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'A couple is sitting down smiling, with the woman linking arms with the man.', 'hypothesis': 'A couple is sitting down and smiling.', 'label': 0, 'input_ids': [101, 1037, 3232, 2003, 3564, 2091, 5629, 1010, 2007, 1996, 2450, 11383, 2608, 2007, 1996, 2158, 1012, 1037, 3232, 2003, 3564, 2091, 1998, 5629, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'A man with a blue helmet and orange shirt.', 'hypothesis': 'A man wears a helmet.', 'label': 0, 'input_ids': [101, 1037, 2158, 2007, 1037, 2630, 10412, 1998, 4589, 3797, 1012, 1037, 2158, 11651, 1037, 10412, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'A man and a young girl swimming.', 'hypothesis': 'a mother and son eating lunch', 'label': 2, 'input_ids': [101, 1037, 2158, 1998, 1037, 2402, 2611, 5742, 1012, 1037, 2388, 1998, 2365, 5983, 6265, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'Three men are working with their bikes in the shoulder of a road.', 'hypothesis': 'The men are driving cars.', 'label': 2, 'input_ids': [101, 2093, 2273, 2024, 2551, 2007, 2037, 18105, 1999, 1996, 3244, 1997, 1037, 2346, 1012, 1996, 2273, 2024, 4439, 3765, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'A person in blue is the only person currently throwing their ball at a bowling alley.', 'hypothesis': 'The person is eating nachos.', 'label': 2, 'input_ids': [101, 1037, 2711, 1999, 2630, 2003, 1996, 2069, 2711, 2747, 6886, 2037, 3608, 2012, 1037, 9116, 8975, 1012, 1996, 2711, 2003, 5983, 6583, 9905, 2015, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'Three children in a black dog kennel.', 'hypothesis': 'Kids are in a cage.', 'label': 1, 'input_ids': [101, 2093, 2336, 1999, 1037, 2304, 3899, 6358, 11877, 1012, 4268, 2024, 1999, 1037, 7980, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'A child and a parent or older sibling going for a hike.', 'hypothesis': \"It is the child's first time hiking.\", 'label': 1, 'input_ids': [101, 1037, 2775, 1998, 1037, 6687, 2030, 3080, 22941, 2183, 2005, 1037, 21857, 1012, 2009, 2003, 1996, 2775, 1005, 1055, 2034, 2051, 13039, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}]\n",
      "32\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m DL:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(x)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/school/extra/transformer_pretrain/transfer_transformers/NLP/lib/python3.10/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/Desktop/school/extra/transformer_pretrain/transfer_transformers/NLP/lib/python3.10/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/Desktop/school/extra/transformer_pretrain/transfer_transformers/NLP/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[51], line 4\u001b[0m, in \u001b[0;36mcol_fn\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(x)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(x))\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "for x in DL:\n",
    "    print(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = load_dataset('Salesforce/wikitext', 'wikitext-103-raw-v1')\n",
    "# data1 = load_dataset('Skylion007/openwebtext')\n",
    "data = load_dataset('bookcorpus/bookcorpus')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_bf16_supported()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 74004228\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"he 'd seen the movie almost by mistake , considering he was a little young for the pg cartoon , but with older cousins , along with her brothers , mason was often exposed to things that were older .\"}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train'].__getitem__(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data['train']\n",
    "# validation = data['validation']\n",
    "# test = data['test']\n",
    "# validation_owt = data1['train']['text'][int(0.8*len(data1['train']['text']))+1:int(0.9*len(data1['train']['text']))]\n",
    "# test_owt = data1['train']['text'][int(0.9*len(data1['train']['text']))+1:]\n",
    "# train_owt = data1['train']['text'][:int(0.8*len(data1['train']['text']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 74004228\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bos_token = \"<|BOS|>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def data_clean(input: list[str], seq_len=135) -> str:\n",
    "    ret = \"\"\n",
    "    for line in input:\n",
    "        if len(line) == 0:  continue\n",
    "        # remove @'s surrounding some characters\n",
    "        line = re.sub(r' @([.,\\-])@ ', r'\\1', line)\n",
    "        # find titles of articles and add bos_token\n",
    "        matches = re.match(r'^ = ?(.+?) =?\\n', line)    # this finds all title and subsection text\n",
    "        if matches != None:\n",
    "            c = line.count('=')\n",
    "            if c == 2:\n",
    "                # start new article\n",
    "                ret += \" \" + bos_token\n",
    "        ret += line\n",
    "\n",
    "    ret = ret.split(\" \")\n",
    "    chunks = []\n",
    "    curr_chunk = []\n",
    "    cur_len = 0\n",
    "    \n",
    "    for word in ret:\n",
    "        if cur_len > seq_len:\n",
    "            chunks.append(\" \". join(curr_chunk))\n",
    "            curr_chunk = [word]\n",
    "            cur_len = 1\n",
    "\n",
    "        else:\n",
    "            curr_chunk.append(word)\n",
    "            cur_len += 1\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_join = data_clean(train['text']) + data_clean(train_owt)\n",
    "# val_join = data_clean(validation['text']) + data_clean(validation_owt)\n",
    "# test_join = data_clean(test['text']) + data_clean(test_owt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_all(ex):\n",
    "    return tokenizer(ex['text'], truncation=False, padding=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5098ef9a19c48cc98bb99306d9d4774",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/74004228 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1119 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tok_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumn_names\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/school/extra/transformer_pretrain/transfer_transformers/NLP/lib/python3.10/site-packages/datasets/arrow_dataset.py:560\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[1;32m    555\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[1;32m    558\u001b[0m }\n\u001b[1;32m    559\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 560\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    562\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/school/extra/transformer_pretrain/transfer_transformers/NLP/lib/python3.10/site-packages/datasets/arrow_dataset.py:3055\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3050\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[1;32m   3051\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3052\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[1;32m   3053\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3054\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m-> 3055\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m rank, done, content \u001b[38;5;129;01min\u001b[39;00m Dataset\u001b[38;5;241m.\u001b[39m_map_single(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdataset_kwargs):\n\u001b[1;32m   3056\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[1;32m   3057\u001b[0m                 shards_done \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/school/extra/transformer_pretrain/transfer_transformers/NLP/lib/python3.10/site-packages/datasets/arrow_dataset.py:3458\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   3454\u001b[0m indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m   3455\u001b[0m     \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mslice\u001b[39m(i, i \u001b[38;5;241m+\u001b[39m batch_size)\u001b[38;5;241m.\u001b[39mindices(shard\u001b[38;5;241m.\u001b[39mnum_rows)))\n\u001b[1;32m   3456\u001b[0m )  \u001b[38;5;66;03m# Something simpler?\u001b[39;00m\n\u001b[1;32m   3457\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3458\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[43mapply_function_on_filtered_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3461\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_same_num_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mshard\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_indexes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3462\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3463\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3464\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NumExamplesMismatchError:\n\u001b[1;32m   3465\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetTransformationNotAllowedError(\n\u001b[1;32m   3466\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3467\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/school/extra/transformer_pretrain/transfer_transformers/NLP/lib/python3.10/site-packages/datasets/arrow_dataset.py:3320\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[0;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   3318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_rank:\n\u001b[1;32m   3319\u001b[0m     additional_args \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (rank,)\n\u001b[0;32m-> 3320\u001b[0m processed_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[1;32m   3322\u001b[0m     processed_inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   3323\u001b[0m         k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mkeys_to_format\n\u001b[1;32m   3324\u001b[0m     }\n",
      "Cell \u001b[0;32mIn[29], line 2\u001b[0m, in \u001b[0;36mtoken_all\u001b[0;34m(ex)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtoken_all\u001b[39m(ex):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mex\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/school/extra/transformer_pretrain/transfer_transformers/NLP/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3021\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   3019\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   3020\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 3021\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3022\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3023\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[0;32m~/Desktop/school/extra/transformer_pretrain/transfer_transformers/NLP/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3109\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   3104\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3105\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch length of `text`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match batch length of `text_pair`:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3106\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text_pair)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3107\u001b[0m         )\n\u001b[1;32m   3108\u001b[0m     batch_text_or_text_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(text, text_pair)) \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m text\n\u001b[0;32m-> 3109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3111\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3123\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3127\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3128\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3129\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3130\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_plus(\n\u001b[1;32m   3132\u001b[0m         text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[1;32m   3133\u001b[0m         text_pair\u001b[38;5;241m=\u001b[39mtext_pair,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3151\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3152\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/school/extra/transformer_pretrain/transfer_transformers/NLP/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3311\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   3301\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   3302\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   3303\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m   3304\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3308\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3309\u001b[0m )\n\u001b[0;32m-> 3311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3313\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3315\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3317\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3318\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3322\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3327\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3329\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3330\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3331\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/school/extra/transformer_pretrain/transfer_transformers/NLP/lib/python3.10/site-packages/transformers/models/gpt2/tokenization_gpt2_fast.py:127\u001b[0m, in \u001b[0;36mGPT2TokenizerFast._batch_encode_plus\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m is_split_into_words \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_split_into_words\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_prefix_space \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_split_into_words, (\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou need to instantiate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with add_prefix_space=True \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto use it with pretokenized inputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    125\u001b[0m )\n\u001b[0;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/school/extra/transformer_pretrain/transfer_transformers/NLP/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py:517\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens)\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_text_or_text_pairs has to be a list or a tuple (got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(batch_text_or_text_pairs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    514\u001b[0m     )\n\u001b[1;32m    516\u001b[0m \u001b[38;5;66;03m# Set the truncation and padding strategy and restore the initial configuration\u001b[39;00m\n\u001b[0;32m--> 517\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_truncation_and_padding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenizer\u001b[38;5;241m.\u001b[39mencode_special_tokens \u001b[38;5;241m!=\u001b[39m split_special_tokens:\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenizer\u001b[38;5;241m.\u001b[39mencode_special_tokens \u001b[38;5;241m=\u001b[39m split_special_tokens\n",
      "File \u001b[0;32m~/Desktop/school/extra/transformer_pretrain/transfer_transformers/NLP/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py:450\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast.set_truncation_and_padding\u001b[0;34m(self, padding_strategy, truncation_strategy, max_length, stride, pad_to_multiple_of, padding_side)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;66;03m# Set truncation and padding on the backend tokenizer\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m truncation_strategy \u001b[38;5;241m==\u001b[39m TruncationStrategy\u001b[38;5;241m.\u001b[39mDO_NOT_TRUNCATE:\n\u001b[0;32m--> 450\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _truncation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    451\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenizer\u001b[38;5;241m.\u001b[39mno_truncation()\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tok_dataset = train.map(token_all, batched=True, remove_columns=train.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedSentenceDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tokenized_dataset, max_length=128):\n",
    "        self.tokenized_dataset = tokenized_dataset\n",
    "        self.max_length = max_length\n",
    "        self.samples = self._create_samples()\n",
    "\n",
    "    def _create_samples(self):\n",
    "        samples = []\n",
    "        current_sample = []\n",
    "        current_length = 0\n",
    "\n",
    "        for sentence in self.tokenized_dataset[\"input_ids\"]:\n",
    "            sentence_length = len(sentence)\n",
    "\n",
    "            if current_length + sentence_length <= self.max_length:\n",
    "                current_sample.extend(sentence)\n",
    "                current_length += sentence_length\n",
    "            else:\n",
    "                if current_length > 0:\n",
    "                    # Pad the current sample if needed\n",
    "                    padding_length = self.max_length - current_length\n",
    "                    current_sample.extend([tokenizer.pad_token_id] * padding_length)\n",
    "                    samples.append(current_sample)\n",
    "\n",
    "                # Start a new sample with the current sentence\n",
    "                current_sample = sentence[:self.max_length]\n",
    "                current_length = min(sentence_length, self.max_length)\n",
    "\n",
    "            # If we've reached exactly max_length, add the sample and reset\n",
    "            if current_length == self.max_length:\n",
    "                samples.append(current_sample)\n",
    "                current_sample = []\n",
    "                current_length = 0\n",
    "\n",
    "        # Add the last sample if it's not empty\n",
    "        if current_length > 0:\n",
    "            padding_length = self.max_length - current_length\n",
    "            current_sample.extend([tokenizer.pad_token_id] * padding_length)\n",
    "            samples.append(current_sample)\n",
    "\n",
    "        return samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ids = torch.tensor(self.samples[idx])\n",
    "        attention_mask = (input_ids != tokenizer.pad_token_id).long()\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask\n",
    "        }\n",
    "\n",
    "# Create the combined sentence dataset\n",
    "combined_dataset = CombinedSentenceDataset(tokenized_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 737084/737084 [05:41<00:00, 2156.80it/s]\n"
     ]
    }
   ],
   "source": [
    "train_tok = [tokenizer(chunk, truncation=False, return_tensors='pt')['input_ids'] for chunk in tqdm.tqdm(train)]\n",
    "# val_tok = [tokenizer(chunk, max_length=129, truncation=True, return_tensors='pt')['input_ids'] for chunk in val_join]\n",
    "# test_tok = [tokenizer(chunk, max_length=129, truncation=True, return_tensors='pt')['input_ids'] for chunk in test_join]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_tok, 'data/train_data_bookcorp.pt')\n",
    "# torch.save(val_tok, 'data/val_data_token_owt.pt')\n",
    "# torch.save(test_tok, 'data/test_data_token_owt.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "737084"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_tok)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
