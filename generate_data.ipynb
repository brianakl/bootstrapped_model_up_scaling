{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
    "from datasets import load_dataset\n",
    "import tqdm\n",
    "from transformers import GPT2TokenizerFast, BertTokenizerFast\n",
    "import re\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "from bus_nGPT import Decoder, TransformerLayer, AttentionHead, Rotary\n",
    "import tensorboard as tb\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "with open('base_512_fullrun.csv', 'r') as csvfile:\n",
    "    csvreader = csv.reader(csvfile)\n",
    "    next(csvreader)  # Skip header if present\n",
    "    for row in csvreader:\n",
    "        x.append(float(row[1]))  # Assuming x is in the first column\n",
    "        y.append(float(row[2]))  # Assuming y is in the second column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(x, y):\n",
    "    q1 = np.percentile(y, 25)\n",
    "    q3 = np.percentile(y, 75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - (1.5 * iqr)\n",
    "    upper_bound = q3 + (1.5 * iqr)\n",
    "    \n",
    "    mask = (y >= lower_bound) & (y <= upper_bound)\n",
    "    return np.array(x)[mask], np.array(y)[mask]\n",
    "\n",
    "x_clean, y_clean = remove_outliers(x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 100.0,\n",
       " 200.0,\n",
       " 300.0,\n",
       " 400.0,\n",
       " 500.0,\n",
       " 600.0,\n",
       " 700.0,\n",
       " 800.0,\n",
       " 900.0,\n",
       " 1000.0,\n",
       " 1100.0,\n",
       " 1200.0,\n",
       " 1300.0,\n",
       " 1400.0,\n",
       " 1500.0,\n",
       " 1600.0,\n",
       " 1700.0,\n",
       " 1800.0,\n",
       " 1900.0,\n",
       " 2000.0,\n",
       " 2100.0,\n",
       " 2200.0,\n",
       " 2300.0,\n",
       " 2400.0,\n",
       " 2500.0,\n",
       " 2600.0,\n",
       " 2700.0,\n",
       " 2800.0,\n",
       " 2900.0,\n",
       " 3000.0,\n",
       " 3100.0,\n",
       " 3200.0,\n",
       " 3300.0,\n",
       " 3400.0,\n",
       " 3500.0,\n",
       " 3600.0,\n",
       " 3700.0,\n",
       " 3800.0,\n",
       " 3900.0,\n",
       " 4000.0,\n",
       " 4100.0,\n",
       " 4200.0,\n",
       " 4300.0,\n",
       " 4400.0,\n",
       " 4500.0,\n",
       " 4600.0,\n",
       " 4700.0,\n",
       " 4800.0,\n",
       " 4900.0,\n",
       " 5000.0]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 200.,  300.,  400.,  500.,  600.,  700.,  800.,  900., 1000.,\n",
       "       1100., 1200., 1300., 1400., 1500., 1600., 1700., 1800., 1900.,\n",
       "       2000., 2100., 2200., 2300., 2400., 2500., 2600., 2700., 2800.,\n",
       "       2900., 3000., 3100., 3200., 3300., 3400., 3500., 3600., 3700.,\n",
       "       3800., 3900., 4000., 4100., 4200., 4300., 4400., 4500., 4600.,\n",
       "       4700., 4800., 4900., 5000.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.79791975, 5.71323061, 5.62147951, 5.58574152, 5.49655199,\n",
       "       5.46772575, 5.43948555, 5.42493868, 5.35012341, 5.31858444,\n",
       "       5.33466625, 5.28206825, 5.23734426, 5.22355175, 5.12709284,\n",
       "       5.13072968, 5.12743235, 5.09644651, 5.05150127, 5.02279711,\n",
       "       5.02692032, 4.96997356, 4.99134827, 4.98092365, 4.92580414,\n",
       "       4.91517115, 4.87730026, 4.85464954, 4.83703852, 4.85167789,\n",
       "       4.77732038, 4.81324863, 4.77854919, 4.80211639, 4.78536224,\n",
       "       4.72053003, 4.74282742, 4.73101807, 4.69938421, 4.70304871,\n",
       "       4.72219181, 4.70531654, 4.75033283, 4.73621702, 4.69918728,\n",
       "       4.68260193, 4.6792655 , 4.71579123, 4.68376923])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams[\"axes.formatter.limits\"] = (-99, 99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3237/744830094.py:11: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  plt.legend()\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3gAAAIjCAYAAABRULnOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAACS9UlEQVR4nOzdd1RU19oG8GcqvXeQJqA0FSsWEHvvJvaaYm5iiaIxmuRaotfEzxg1amzRGE2MJXYTu8beOxZABZQqRbrUOd8fyEQCKIMMQ3l+a80yc+aU98CZyTzsffYWCYIggIiIiIiIiKo9saYLICIiIiIioorBgEdERERERFRDMOARERERERHVEAx4RERERERENQQDHhERERERUQ3BgEdERERERFRDMOARERERERHVEAx4RERERERENQQDHhERERERUQ3BgEdERLXWxo0bIRKJEB4ervZjhYeHQyQSYePGjWo/Vm3m5OSEMWPGlGtbkUiEOXPmVGg9b+vQoUPw8fGBtrY2RCIRkpOTNV0SEVVxDHhEpDGFX65ffVhaWqJ9+/Y4ePBgkXULvxx/9913Je7ru+++K/ZFXaFQYNOmTfD19YWpqSkMDAxQr149jBo1ChcvXqzw87l9+zbGjh0LZ2dnaGtrQ19fHz4+Ppg+fToeP35cZN0xY8YUOW9DQ0M0atQIixcvRnZ2tvJ8y/KojHCiipycHCxbtgyNGzeGoaEhjI2N4eXlhXHjxuHBgwfK9c6fP485c+bwC2sF2L9/P3r37g0rKyvI5XKYmpqibdu2WLx4MVJTU4us6+TkVOw95+/vj927dwMo+X1Z0sPJyanUev7++2/ler/++muJ67Rp0wYikQje3t4V9nOoDP9+b0okEjg4OKB///64efNmhR4rMTERgwYNgo6ODlauXInNmzdDT0+vQo9BRDWPVNMFEBF9/fXXcHZ2hiAIiIuLw8aNG9GjRw/s378fvXr1Kvd+J02ahJUrV6Jv374YPnw4pFIpgoODcfDgQdStWxctW7assHNYt24dPv74Y5ibm2P48OFwd3dHXl4egoKCsGnTJixduhQvXryARCJRbqOlpYWffvoJAJCcnIydO3di2rRpuHLlCtavX4/NmzcXOcbixYsRGRmJJUuWFFluYWFRYedREQYOHIiDBw9i6NCh+PDDD5Gbm4sHDx7gwIEDaN26Ndzd3QEUBLy5c+dizJgxMDY21mzR1ZRCocD777+PjRs3okGDBvjkk09gb2+PtLQ0XLhwAV999RX++usvHD9+vMh2Pj4+mDp1KgAgOjoaa9aswYABA7Bq1Sp06dKl2LX3wQcfoEWLFhg3bpxymb6+/hvr09bWxpYtWzBixIgiy8PDw3H+/Hloa2uX99Q1bujQoejRowfy8/Nx//59rFq1CgcPHsTFixfh4+NTIce4cuUK0tLSMG/ePHTq1KlC9klEtYBARKQhP//8swBAuHLlSpHlSUlJgkwmE4YNG6ZcFhYWJgAQFi1aVOK+Fi1aJAAQwsLCBEEQhNjYWEEkEgkffvhhsXUVCoUQFxdXYedx7tw5QSKRCG3bthVSU1OLvf7ixQvhq6++EvLy8pTLRo8eLejp6RVZLz8/X2jWrJkAQIiKiiq2n549ewqOjo4VVrc6XL58WQAg/O9//yv2Wl5enpCQkKB8/u/fmSYUXoMVVUNGRkaprxVewz///HOFHEsQBOGbb74RAAhTpkwRFApFsdejo6OFb7/9tsgyR0dHoWfPnkWWxcTECHp6ekK9evVKPI6enp4wevToMtd18uRJAYAwYMAAQSqVCvHx8UVe/9///idYWVkJfn5+gpeXV5n3WxaOjo4q1foqAMLs2bNfu05pn0X79u0TAAjjxo0r17FflZ6eLgiCIPzyyy8lfkZWxL6JqOZiF00iqnKMjY2ho6MDqbT8nQzCwsIgCALatGlT7LXCbmmv82qX0LVr18LFxQVaWlpo3rw5rly5UmTduXPnQiQS4bfffoOBgUGxfWlra2PevHlFWu9KIhaL0a5dO+Xx30Zubi5MTU0xduzYYq+lpqZCW1sb06ZNUy5bvnw5vLy8oKurCxMTEzRr1gxbtmxR+biPHj0CgBJ/7hKJBGZmZgCAOXPm4LPPPgMAODs7F+tu+vPPP6NDhw6wtLSElpYWPD09sWrVqmL7dHJyQq9evXD27Fm0aNEC2traqFu3LjZt2lRs3bt376JDhw7Q0dFBnTp1MH/+fCgUimLr7d27Fz179oStrS20tLTg4uKCefPmIT8/v8h67dq1g7e3N65du4a2bdtCV1cXX3zxBYCCFtkxY8bAyMgIxsbGGD16dJm7ohZ2kTx37hwCAwNhYWEBPT099O/fH/Hx8cr1MjMzsXDhQnh5eWHRokUQiUTF9mVjY4PPP//8jce0traGh4cHwsLCylRjWfXt2xdaWlrYsWNHkeVbtmzBoEGDSnxP5OXlYd68ecr3nJOTE7744gtkZ2cXWU8QBMyfPx916tSBrq4u2rdvj7t375ZYR3JyMiZPngx7e3toaWnB1dUVCxcuLPH3X14dOnQAgCI/w0uXLqFbt24wMjKCrq4uAgICcO7cuSLbzZkzByKRCPfu3cOwYcNgYmICPz8/tGvXDqNHjwYANG/eHCKRqMi9hTt27EDTpk2ho6MDc3NzjBgxAlFRUUX2PWbMGOjr6+PRo0fo0aMHDAwMMHz4cAAFn4MTJkzAjh074OnpCR0dHbRq1Qp37twBAKxZswaurq7Q1tZGu3btin0mnTlzBu+++y4cHBygpaUFe3t7TJkyBS9evCixhqioKPTr1w/6+vqwsLDAtGnTir2nFAoFli1bhgYNGkBbWxsWFhbo1q0brl69WmS9X3/9VXnupqamGDJkCJ4+fVqWXxNRrcAumkSkcSkpKUhISIAgCHj27BmWL1+O9PT0Yt26VOHo6Aig4EvQu+++C11d3XLtZ8uWLUhLS8NHH30EkUiE//u//8OAAQPw+PFjyGQyZGZm4sSJE2jXrh3q1KlT7noLFQakwiBUXjKZDP3798euXbuwZs0ayOVy5Wt79uxBdnY2hgwZAqCge+mkSZPwzjvv4NNPP0VWVhZu376NS5cuYdiwYSodt/Dn/ttvv6FNmzalhvQBAwYgJCQEv//+O5YsWQJzc3MA/3Q3XbVqFby8vNCnTx9IpVLs378fn3zyCRQKBcaPH19kXw8fPsQ777yD999/H6NHj8aGDRswZswYNG3aFF5eXgCA2NhYtG/fHnl5eZgxYwb09PSwdu1a6OjoFKtt48aN0NfXR2BgIPT19XHixAnMmjULqampWLRoUZF1ExMT0b17dwwZMgQjRoyAlZUVBEFA3759cfbsWfznP/+Bh4cHdu/erfyyXlYTJ06EiYkJZs+ejfDwcCxduhQTJkzAtm3bAABnz55FcnIypk2b9sY/HrxJbm4unj59+tbX3b/p6uqib9+++P333/Hxxx8DAG7duoW7d+/ip59+wu3bt4tt88EHH+CXX37BO++8g6lTp+LSpUv45ptvcP/+feV9ggAwa9YszJ8/Hz169ECPHj1w/fp1dOnSBTk5OUX2l5mZiYCAAERFReGjjz6Cg4MDzp8/j5kzZyImJgZLly6tkHP993v3xIkT6N69O5o2bYrZs2dDLBYr/3Bx5swZtGjRosj27777Ltzc3LBgwQIIggA3NzfUr18fa9euVXZjd3FxAVBwjY4dOxbNmzfHN998g7i4OCxbtgznzp3DjRs3inR5zsvLQ9euXeHn54fvvvuuyGfhmTNnsG/fPuV76ptvvkGvXr0wffp0/Pjjj/jkk0/w/Plz/N///R/ee+89nDhxQrntjh07kJmZiY8//hhmZma4fPkyli9fjsjIyGKBPj8/H127doWvry++++47HDt2DIsXL4aLi4vyugCg7G7cvXt3fPDBB8jLy8OZM2dw8eJFNGvWDADwv//9D//9738xaNAgfPDBB4iPj8fy5cvRtm3bYudOVGtptP2QiGq1wu5x/35oaWkJGzduLLKuql00BUEQRo0aJQAQTExMhP79+wvfffedcP/+/TLVVng8MzMzISkpSbl87969AgBh//79giAIwq1btwQAwuTJk4vtIzExUYiPj1c+srOzla8VdtEsfO3hw4fCggULBJFIJDRs2LDEmlTtonn48OEitRbq0aOHULduXeXzvn37Vlg3OYVCIQQEBAgABCsrK2Ho0KHCypUrhYiIiGLrvq6LZmZmZrFlXbt2LVK3IBR0xwMgnD59Wrns2bNngpaWljB16lTlssmTJwsAhEuXLhVZz8jIqFgNJR37o48+EnR1dYWsrCzlssLzXL16dZF19+zZIwAQ/u///k+5LC8vT/D39y9TF83C90WnTp2KdLucMmWKIJFIhOTkZEEQBGHZsmUCAGHPnj1Fts/Lyyty3cXHxxfZj6Ojo9ClSxfla7du3RKGDBkiABAmTpxYYk3l7aK5Y8cO4cCBA4JIJBKePHkiCIIgfPbZZ8rfY0BAQJFr7+bNmwIA4YMPPiiyv2nTpgkAhBMnTgiCUPC7k8vlQs+ePYuc2xdffCEAKFLrvHnzBD09PSEkJKTIPmfMmCFIJBJlXYKgWhfNuXPnCvHx8UJsbKzw999/C40bNxYACDt37hQUCoXg5uYmdO3atUh9mZmZgrOzs9C5c2flstmzZwsAhKFDhxY7Vknd2HNycgRLS0vB29tbePHihXL5gQMHBADCrFmzlMtGjx4tABBmzJhRbN+Fn7WvXvtr1qwRAAjW1tZFupvPnDmzTO+Tb775RhCJREXe74U1fP3110XWbdy4sdC0aVPl8xMnTggAhEmTJhXbb+HPMDw8XJBIJMW6gN+5c0eQSqUldg0nqo3YRZOING7lypU4evQojh49il9//RXt27fHBx98gF27dr3Vfn/++WesWLECzs7O2L17N6ZNmwYPDw907NixWFem0gwePBgmJibK5/7+/gCgHBWzcITCkgacqFu3LiwsLJSPffv2FXk9IyND+Zqrqyu++OILtGrVqkgrxdvo0KEDzM3NlS0+APD8+XMcPXoUgwcPVi4zNjZGZGRksa6n5SESiXD48GHMnz8fJiYm+P333zF+/Hg4Ojpi8ODBZe6m+GrLWmELb0BAAB4/foyUlJQi63p6eip/L0BBK2D9+vWLjFz6119/oWXLlkVaTSwsLJTd1Uo7dlpaGhISEuDv74/MzMwio4ACBQPl/Lsb7F9//QWpVFqkZUIikWDixIllOvdC48aNK9Lt0t/fH/n5+YiIiABQ+rV3586dItedhYUFEhMTi6xz5MgR5WuNGjXCjh07MHLkSCxcuFClGsuiS5cuMDU1xdatWyEIArZu3YqhQ4eWuO5ff/0FAAgMDCyyvHBAmD///BMAcOzYMeTk5GDixIlFfkaTJ08uts8dO3bA398fJiYmSEhIUD46deqE/Px8nD59ulznNXv2bFhYWMDa2hrt2rXDo0ePsHDhQgwYMAA3b95EaGgohg0bhsTEROUxMzIy0LFjR5w+fbpY99D//Oc/ZTru1atX8ezZM3zyySdFBqnp2bMn3N3dlT+jV716Lb6qY8eORUZD9fX1BVAwUNKr3c0Ll7/6nnr1fZKRkYGEhAS0bt0agiDgxo0bxY717/Pz9/cvsr+dO3dCJBJh9uzZxbYt/B3v2rULCoUCgwYNKvK7tLa2hpubG06ePFnieRLVNuyiSUQa16JFC2X3G6BgdLrGjRtjwoQJ6NWrV5HuhW/y6pc9sViM8ePHY/z48UhMTMS5c+ewevVqHDx4EEOGDMGZM2feuD8HB4cizwvD3vPnzwFA+SUoPT292LZ79+5Fbm4ubt26VeR+t0La2trYv38/gIKg4OzsXCHdPAtJpVIMHDgQW7ZsQXZ2NrS0tLBr1y7k5uYWCXiff/45jh07hhYtWsDV1RVdunTBsGHDSryPriy0tLTw5Zdf4ssvv0RMTAxOnTqFZcuWYfv27ZDJZKUOm/+qc+fOYfbs2bhw4QIyMzOLvJaSkgIjIyPl83//joCC31Ph7wgAIiIilF9SX1W/fv1iy+7evYuvvvoKJ06cKDbFwL/DpZ2dXbHrMyIiAjY2NsWCV0nHep3yXnuurq44evQoAGDTpk3FRsQECr6wz58/HyKRCLq6uvDw8FBb1zaZTIZ3330XW7ZsQYsWLfD06dNSu/5GRERALBbD1dW1yHJra2sYGxsrw23hv25ubkXWs7CwKPIHGQAIDQ3F7du3Sx1t9tmzZ+U6r3HjxuHdd9+FWCxWTgWipaWlPCaA13bLTUlJKVKrs7NzmY5beO4lXU/u7u44e/ZskWVSqbTUz5V/X2OF7yt7e/sSl7/6nnry5AlmzZqFffv2FVkOFH+fFN5P96p/v0cfPXoEW1tbmJqallgrUPBzFV52Xy2JTCYrdVui2oQBj4iqHLFYjPbt22PZsmUIDQ2Fl5eX8i/V/76Bv1BhCCht2HUzMzP06dMHffr0Qbt27XDq1ClEREQo7xkrTWn3NgmCAKDgy7RUKkVQUFCxdQICAgCg1PvQJBKJ2oc+HzJkCNasWYODBw+iX79+2L59O9zd3dGoUSPlOh4eHggODsaBAwdw6NAh7Ny5Ez/++CNmzZqFuXPnvtXxbWxsMGTIEAwcOBBeXl7Yvn07Nm7c+NoBdB49eoSOHTvC3d0d33//Pezt7SGXy/HXX39hyZIlxVo+3vQ7UkVycjICAgJgaGiIr7/+Gi4uLtDW1sb169fx+eefFzt2SffwVZQ3nVfhdBNBQUHo27ev8nV9fX3ldfXvL/uFzM3NK3XY/WHDhmH16tWYM2cOGjVqBE9Pz9euX9KAMeWlUCjQuXNnTJ8+vcTX69WrV679urm5lfozLLxOFi1aVOqUCf/+A4C6riUtLS2IxSV32CrtGnvTtZefn4/OnTsjKSkJn3/+Odzd3aGnp4eoqCiMGTOmzO9RVSkUCohEIhw8eLDEfZZl6g6i2oABj4iqpLy8PAD/tE5YWFhAV1cXwcHBJa4fHBwMXV1d5WAdr9OsWTOcOnUKMTExbwx4b6Knp6cMjFFRUbCzs3ur/VW0tm3bwsbGBtu2bYOfnx9OnDiBL7/8sth6enp6GDx4MAYPHoycnBwMGDAA//vf/zBz5swKmatMJpOhYcOGCA0NVXapKu1L/P79+5GdnY19+/YVaWF4m+5Xjo6OylaVV/37evr777+RmJiIXbt2oW3btsrlqowu6ejoiOPHjyM9Pb3IF87Srt3y8vf3h5GREbZu3YqZM2eW+iW+KvDz84ODgwP+/vvv13YDdXR0hEKhQGhoKDw8PJTL4+LikJycrHy/Fv4bGhqKunXrKteLj48v1prk4uKC9PT0Sg20hYOhGBoaVvhxC889ODhYOXJnoeDg4Lf+TCuLO3fuICQkBL/88gtGjRqlXF7YclweLi4uOHz4MJKSkkptxXNxcYEgCHB2di53MCeqDaru/w2IqNbKzc3FkSNHIJfLlV/yJBIJunTpgv379+PJkydF1n/y5An279+PLl26KP+qGxsbi3v37hXbd05ODo4fP15iN7DymjVrFvLz8zFixIgSu2qWpyWpoojFYrzzzjvYv38/Nm/ejLy8vCLdMwEUuz9LLpfD09MTgiAgNzcXAJT3nyUkJLz2eKGhocV+P0BBy9iFCxdgYmKi7Kqlp6enfO1Vhb/DV39uKSkp+Pnnn8twxiXr0aMHLl68iMuXLyuXxcfH47fffnvjsXNycvDjjz+qdKy8vLwi0zrk5+dj+fLl5S2/RLq6upg+fTqCgoIwY8aMEq8zTV57rxKJRPjhhx8we/ZsjBw5stT1evToAQDFRrb8/vvvARTcZwYAnTp1gkwmw/Lly4ucY0kjYg4aNAgXLlzA4cOHi72WnJys/GNSRWratClcXFzw3XfflfiZ8Op0F6pq1qwZLC0tsXr16iJTRxw8eBD3799X/ozUqaT3iSAIWLZsWbn3OXDgQAiCUGKvgcLjDBgwABKJBHPnzi12bQuCUOyzjKi2YgseEWncwYMHlYNXPHv2DFu2bEFoaChmzJgBQ0ND5XoLFixAy5Yt0aRJE4wbNw5OTk4IDw/H2rVrIRKJsGDBAuW6kZGRaNGiBTp06ICOHTvC2toaz549w++//45bt25h8uTJZWrtKwt/f3+sWLECEydOhJubG4YPHw53d3fk5OQgJCQEv/32G+RyOaytrSvkeKoaPHgwli9fjtmzZ6NBgwZFWkaAgkEwrK2t0aZNG1hZWeH+/ftYsWIFevbsqbzP6/Lly2jfvj1mz56NOXPmlHqsW7duYdiwYejevTv8/f1hamqKqKgo/PLLL4iOjsbSpUuVXw6bNm0KAPjyyy8xZMgQyGQy9O7dG126dIFcLkfv3r3x0UcfIT09HevWrYOlpSViYmLK9TOYPn06Nm/ejG7duuHTTz9VTpPg6OhYZKj+1q1bw8TEBKNHj8akSZMgEomwefNmlYJS79690aZNG8yYMQPh4eHw9PTErl27it2XVBFmzJiB+/fvY9GiRThy5AgGDhyIOnXq4Pnz57h+/Tp27NgBS0vLCmmFfVt9+/Yt0pW0JI0aNcLo0aOxdu1aZXfZy5cv45dffkG/fv3Qvn17AFDOo1Y4rH+PHj1w48YNHDx4sNj7+rPPPsO+ffvQq1cv5fQZGRkZuHPnDv744w+Eh4dX2GdBIbFYjJ9++gndu3eHl5cXxo4dCzs7O0RFReHkyZMwNDRU3n+rKplMhoULF2Ls2LEICAjA0KFDldMkODk5YcqUKRV6LiVxd3eHi4sLpk2bhqioKBgaGmLnzp3FWk9V0b59e4wcORI//PADQkND0a1bNygUCpw5cwbt27fHhAkT4OLigvnz52PmzJkIDw9Hv379YGBggLCwMOzevRvjxo0r8X5nolqnMofsJCJ6VUnTJGhraws+Pj7CqlWrigwvXuj+/fvC4MGDBUtLS0EqlQqWlpbCkCFDik1/kJqaKixbtkzo2rWrUKdOHUEmkwkGBgZCq1athHXr1pW471e9bloGlDKU+o0bN4RRo0YJDg4OglwuF/T09ISGDRsKU6dOFR4+fFhk3cJpElSh6jQJhRQKhWBvby8AEObPn1/s9TVr1ght27YVzMzMBC0tLcHFxUX47LPPhJSUFOU6hcPev2kI+bi4OOHbb78VAgICBBsbG0EqlQomJiZChw4dhD/++KPY+vPmzRPs7OwEsVhcZBj2ffv2CQ0bNhS0tbUFJycnYeHChcKGDRuKDdXu6Ogo9OzZs9h+AwIChICAgCLLbt++LQQEBAja2tqCnZ2dMG/ePGH9+vXF9nnu3DmhZcuWgo6OjmBraytMnz5dOeXEyZMnixyjtOklEhMThZEjRwqGhoaCkZGRMHLkSOHGjRsqTZPw6tD4gvDP7+DVGgrt3r1b6NGjh2BhYSFIpVLB2NhY8PPzExYtWqScVuFNP7PXeZtpEl6npJ9hbm6uMHfuXMHZ2VmQyWSCvb29MHPmzCJTVAiCIOTn5wtz584VbGxsBB0dHaFdu3ZCUFCQ4OjoWKzWtLQ0YebMmYKrq6sgl8sFc3NzoXXr1sJ3330n5OTkKNcryzX+pilbXnXjxg1hwIAByveWo6OjMGjQIOH48ePKdQqnSYiPjy+2fWnXgiAIwrZt24TGjRsLWlpagqmpqTB8+HAhMjKyyDqv+5wBIIwfP75M51bS7/PevXtCp06dBH19fcHc3Fz48MMPldPGvHqNl1ZD4Xm/Ki8vT1i0aJHg7u4uyOVywcLCQujevbtw7dq1Iuvt3LlT8PPzE/T09AQ9PT3B3d1dGD9+vBAcHFziuRLVNiJBqCL9N4iIiIiIiOit8B48IiIiIiKiGoIBT80OHDiA+vXrw83NDT/99JOmyyEiIiIiohqMXTTVKC8vD56enjh58iSMjIzQtGlTnD9/HmZmZpoujYiIiIiIaiC24KnR5cuX4eXlBTs7O+jr66N79+44cuSIpssiIiIiIqIaqkoEvKioKIwYMQJmZmbQ0dFBgwYNcPXq1VLXnzNnDkQiUZGHu7t7hdd1+vRp9O7dG7a2thCJRNizZ0+xdVauXAknJydoa2vD19e3yBxL0dHRRSY9LhwimYiIiIiISB00HvCeP3+ONm3aQCaT4eDBg7h37x4WL14MExOT127n5eWFmJgY5ePs2bOlrnvu3DnlZL2vunfvHuLi4krdLiMjA40aNcLKlStLfH3btm0IDAzE7Nmzcf36dTRq1Ahdu3bFs2fPXls7ERERERGROmh8ovOFCxfC3t4eP//8s3KZs7PzG7eTSqVlmjRYoVBg/PjxcHNzw9atW5UT7AYHB6NDhw4IDAzE9OnTS9y2e/fu6N69e6n7/v777/Hhhx9i7NixAIDVq1fjzz//xIYNGzBjxgzY2toWabGLiopCixYtSt1fdnY2srOzi9SelJQEMzMziESiN54rERERERHVTIIgIC0tDba2thCLX9NOp9FZ+ARB8PDwECZPniy88847goWFheDj4yOsXbv2tdvMnj1b0NXVFWxsbARnZ2dh2LBhQkRERKnrR0VFCS4uLsKwYcOE/Px84eHDh4Ktra3w0UcflblOAMLu3buVz7OzswWJRFJkmSAIwqhRo4Q+ffoIglAwWaurq6sQGRkppKWlCfXq1RMSEhJee17416TPfPDBBx988MEHH3zwwQcfhY+nT5++NrdovAXv8ePHWLVqFQIDA/HFF1/gypUrmDRpEuRyOUaPHl3iNr6+vti4cSPq16+PmJgYzJ07F/7+/ggKCoKBgUGx9W1tbXHixAn4+/tj2LBhuHDhAjp16oRVq1aVu+6EhATk5+fDysqqyHIrKys8ePAAQEEr4+LFi9G+fXsoFApMnz79tSNozpw5E4GBgcrnKSkpcHBwQFhYWInnVZlyc3Nx8uRJtG/fHjKZ7I3rz//rAXZej8Z//J3xUcCbW2Sp5lH1miHiNUOq4jVDquI1Q6qoatdLWloanJ2d35gLNB7wFAoFmjVrhgULFgAAGjdujKCgIKxevbrUgPdqt8mGDRvC19cXjo6O2L59O95///0St3FwcMDmzZsREBCAunXrYv369ZXS7bFPnz7o06dPmdbV0tKClpZWseWmpqYwNDSs6NJUkpubC11dXZiZmZXpAjc0NIJYKxlyPQNOC1FLqXrNEPGaIVXxmiFV8ZohVVS166WwhjdlGI0PsmJjYwNPT88iyzw8PPDkyZMy78PY2Bj16tXDw4cPS10nLi4O48aNQ+/evZGZmYkpU6aUu2YAMDc3h0QiKTZIS1xcXJnuDazppJKCSytXodBwJUREREREtYfGA16bNm0QHBxcZFlISAgcHR3LvI/09HQ8evQINjY2Jb6ekJCAjh07wsPDA7t27cLx48exbds2TJs2rdx1y+VyNG3aFMePH1cuUygUOH78OFq1alXu/dYUUknBXxby8gUNV0JEREREVHtoPOBNmTIFFy9exIIFC/Dw4UNs2bIFa9euxfjx4wEAK1asQMeOHYtsM23aNJw6dQrh4eE4f/48+vfvD4lEgqFDhxbbv0KhQPfu3eHo6Iht27ZBKpXC09MTR48exc8//4wlS5aUWlt6ejpu3ryJmzdvAgDCwsJw8+ZNZetiYGAg1q1bh19++QX379/Hxx9/jIyMDOWomrWZ/GULXl4+W/CIiIiIiCqLxu/Ba968OXbv3o2ZM2fi66+/hrOzM5YuXYrhw4cDKGh9e/ToUZFtIiMjMXToUCQmJsLCwgJ+fn64ePEiLCwsiu1fLBZjwYIF8Pf3h1wuVy5v1KgRjh07VuI2ha5evYr27dsrnxcOgDJ69Ghs3LgRgwcPRnx8PGbNmoXY2Fj4+Pjg0KFDxQZeqY2kL4duzWELHhERERER8vPzS5ybu5BEIoFUKn3rcUI0HvAAoFevXujVq1eJr82ZMwdz5swpsmzr1q0q7b9z584lLm/cuPFrt2vXrh0KZkgo3YQJEzBhwgSV6qkN/umiyRY8IiIiIqrd0tPTERkZ+cZsoaurCxsbmyINU6qqEgGPah5ZYcBTsAWPiIiIiGqv/Px8REZGQldXFxYWFiW20AmCgJycHMTHxyMsLAxubm6vn8z8NRjwSC0Ku2jmsgWPiIiIiGqx3NxcCIIACwsL6OjolLqejo4OZDIZIiIikJOTA21t7XIdT+ODrFDNJOMomkRERERESmW5t668rXZF9vHWeyAqgaxwFE3Og0dEREREVGkY8EgtCic65yiaRERERESVhwGP1ELGUTSJiIiIiCodAx6pReEgK7wHj4iIiIio8jDgkVoUzoOXy3vwiIiIiIjeOAdeWdd5EwY8Ugu5hC14REREREQSiQQAkJOT88Z1MzMzAQAymazcx+M8eKQWyhY83oNHRERERLWYVCqFrq4u4uPjIZPJSpwKQRAEZGZm4tmzZzA2NlaGwnId722KJSoNJzonIiIiIiqY/87GxgZhYWGIiIh47brGxsawtrZ+q+Mx4JFaKEfRVLCLJhERERHVbnK5HG5ubq/tpimTyd6q5a4QAx6phZT34BERERERKYnFYmhra6v/OGo/AtVKUjHvwSMiIiIiqmwMeKQWcunLFjx20SQiIiIiqjQMeKQWbMEjIiIiIqp8DHikFjIJR9EkIiIiIqpsDHikFoXz4HGQFSIiIiKiysOAR2pROA9enkKAIDDkERERERFVBgY8UovCefAADrRCRERERFRZGPBILQrvwQPYTZOIiIiIqLIw4JFaSF9pwctVcKAVIiIiIqLKwIBHaiET/3Np5eYx4BERERERVQYGPFILsViEl1Ph8R48IiIiIqJKwoBHaiPlXHhERERERJWKAY/URv4y4HGQFSIiIiKiysGAR2qjnOycg6wQEREREVUKBjxSm8LJznPy2IJHRERERFQZGPBIbWRswSMiIiIiqlQMeKQ2hV00c3kPHhERERFRpWDAI7UpnAsvj6NoEhERERFVCgY8UhtZ4SianAePiIiIiKhSMOCR2vzTRZMteERERERElYEBj9Tmn4nO2YJHRERERFQZGPBIbWTil6NosgWPiIiIiKhSMOCR2ii7aPIePCIiIiKiSsGAR2qjHGSFLXhERERERJWCAY/U5p+AxxY8IiIiIqLKwIBHaiMVF3bRZAseEREREVFlYMAjtSlswcvNY8AjIiIiIqoMDHikNoWDrHCicyIiIiKiysGAR2ojFXMePCIiIiKiysSAR2ojl3IePCIiIiKiysSAR2qjbMFjF00iIiIiokrBgEdqo7wHjy14RERERESVggGP1EY5iiYDHhERERFRpWDAI7VRzoPHQVaIiIiIiCoFAx6pjfRlC14eJzonIiIiIqoUDHikNnLlPXhswSMiIiIiqgwMeKQ2UgnnwSMiIiIiqkwMeKQ2hffgsYsmEREREVHlYMAjteEomkRERERElYsBj9SmcB48dtEkIiIiIqocDHikNjLxy1E02YJHRERERFQpGPBIbWTSwnvw2IJHRERERFQZGPBIbaRi3oNHRERERFSZGPBIbWS8B4+IiIiIqFIx4JHaSHkPHhERERFRpWLAI7XhKJpERERERJWLAY/URv5yHjxOdE5EREREVDkY8EhtpIUBjy14RERERESVggGP1EbZRZMteERERERElYIBj9SmsIvmixwGPCIiIiKiysCAR2rjYKYLAEhIz8bzjBwNV0NEREREVPMx4JHaGGrL4Pgy5N2NTtVwNURERERENR8DHqmVt60RAOBudIqGKyEiIiIiqvkY8EitPG0NAQBBbMEjIiIiIlI7BjxSK2+7ly14UWzBIyIiIiJSNwY8Uiuvly14YYkZSM/O03A1REREREQ1GwMeqZW5vhasDbUhCMD9GHbTJCIiIiJSJwY8Ujtvu5f34bGbJhERERGRWjHgkdp5KkfSZAseEREREZE6MeCR2nnbsgWPiIiIiKgyMOCR2hWOpBn6LB1ZufkaroaIiIiIqOZiwCO1szHShomuDPkKASFxaZouh4iIiIioxmLAI7UTiUTKVrygKN6HR0RERESkLgx4VCm8Xg60EhTN+/CIiIiIiNSFAY8qReGE5xxJk4iIiIhIfRjwqFIUdtG8H5OK3HyFhqshIiIiIqqZGPCoUjia6kJfS4qcPAUexadruhwiIiIiohqJAY8qhVgsgqfNy26aHGiFiIiIiEgtGPCo0njZvZzwnAOtEBERERGpBQMeVRrvlyNpsgWPiIiIiEg9GPCo0hS24N2LSYVCIWi4GiIiIiKimocBjyqNq4U+tKRipGfnISIpU9PlEBERERHVOAx4VGmkEjHcXw60EhTF+/CIiIiIiCoaAx5VKk54TkRERESkPgx4anbgwAHUr18fbm5u+OmnnzRdjsYpB1rhSJpERERERBVOqukCarK8vDwEBgbi5MmTMDIyQtOmTdG/f3+YmZlpujSN8bb7p4umIAgQiUQaroiIiIiIqOZgC54aXb58GV5eXrCzs4O+vj66d++OI0eOaLosjapnZQCJWITnmbmIScnSdDlERERERDVKtQ14UVFRGDFiBMzMzKCjo4MGDRrg6tWrFbb/06dPo3fv3rC1tYVIJMKePXtKXG/lypVwcnKCtrY2fH19cfnyZeVr0dHRsLOzUz63s7NDVFRUhdVYHWnLJHCz1AfAgVaIiIiIiCpateyi+fz5c7Rp0wbt27fHwYMHYWFhgdDQUJiYmJS4/rlz59CiRQvIZLIiy+/duwczMzNYWVkV2yYjIwONGjXCe++9hwEDBpS4323btiEwMBCrV6+Gr68vli5diq5duyI4OBiWlpYqn1d2djays7OVz1NTCwYiyc3NRW5ursr7q0iFx6+IOjxtDPAgNg23nz5H+3q1t7tqTVeR1wzVDrxmSFW8ZkhVvGZIFVXteilrHSJBEKrdjNMzZszAuXPncObMmTeuq1Ao0KRJE7i5uWHr1q2QSCQAgODgYAQEBCAwMBDTp09/7T5EIhF2796Nfv36FVnu6+uL5s2bY8WKFcpj2dvbY+LEiZgxYwbOnz+PRYsWYffu3QCAyZMno0WLFhg2bFiJx5kzZw7mzp1bbPmWLVugq6v7xnOtLk7FiLArXAJvEwU+dFdouhwiIiIioiovMzMTw4YNQ0pKCgwNDUtdr1oGPE9PT3Tt2hWRkZE4deoU7Ozs8Mknn+DDDz8scf3o6Gi0bdsWvr6+2Lx5M8LCwtC2bVv07t0bq1evfuPxSgp4OTk50NXVxR9//FFk+ejRo5GcnIy9e/ciLy8PHh4e+Pvvv5WDrJw/f77UQVZKasGzt7dHQkLCa3+JlSE3NxdHjx5F586di7WEqupqxHMM/ekKrAy1cPazgAqqkKqairxmqHbgNUOq4jVDquI1Q6qoatdLamoqzM3N3xjwqmUXzcePH2PVqlUIDAzEF198gStXrmDSpEmQy+UYPXp0sfVtbW1x4sQJ+Pv7Y9iwYbhw4QI6deqEVatWlbuGhIQE5OfnF+veaWVlhQcPHgAApFIpFi9ejPbt20OhUGD69OmvHUFTS0sLWlpaxZbLZLIqcVEBFVNLA3tTiERAXGo2UrIVMNcvfs5Uc1Sl65eqB14zpCpeM6QqXjOkiqpyvZS1hmoZ8BQKBZo1a4YFCxYAABo3boygoCCsXr26xIAHAA4ODti8eTMCAgJQt25drF+/vlKG6O/Tpw/69Omj9uNUJ/paUjib6eFxQgbuRqcioJ6FpksiIiIiIqoRquUomjY2NvD09CyyzMPDA0+ePCl1m7i4OIwbNw69e/dGZmYmpkyZ8lY1mJubQyKRIC4urthxrK2t32rftYGXXcGE5xxJk4iIiIio4lTLgNemTRsEBwcXWRYSEgJHR8cS109ISEDHjh3h4eGBXbt24fjx49i2bRumTZtW7hrkcjmaNm2K48ePK5cpFAocP34crVq1Kvd+awtv24J+w3ejGfCIiIiIiCpKteyiOWXKFLRu3RoLFizAoEGDcPnyZaxduxZr164ttq5CoUD37t3h6OiIbdu2QSqVwtPTE0ePHkWHDh1gZ2dXYmteeno6Hj58qHweFhaGmzdvwtTUFA4ODgCAwMBAjB49Gs2aNUOLFi2wdOlSZGRkYOzYseo7+RrCy7agBe9udKqGKyEiIiIiqjmqZcBr3rw5du/ejZkzZ+Lrr7+Gs7Mzli5diuHDhxdbVywWY8GCBfD394dcLlcub9SoEY4dOwYLi5Lv/7p69Srat2+vfB4YGAigYJTMjRs3AgAGDx6M+Ph4zJo1C7GxsfDx8cGhQ4dKnFePivJ62YIXkZiJlBe5MNLR/I2rRERERETVXbUMeADQq1cv9OrVq0zrdu7cucTljRs3LnWbdu3aoSwzSEyYMAETJkwoUx30DxM9OeyMdRCV/AL3olPRyoUTnhMRERERva1qeQ8e1QxevA+PiIiIiKhCMeCRxnjb8T48IiIiIqKKxIBHGuNtV9CCx6kSiIiIiIgqBgMeaUzhSJqP4tPxIidfw9UQEREREVV/DHikMZYGWjDX14JCAO7HspsmEREREdHbYsAjjRGJRMpumnfZTZOIiIiI6K0x4JFG/TOSJlvwiIiIiIjeFgMeaZT3y/vwgjhVAhERERHRW2PAI40qnCohODYNOXkKDVdDRERERFS9MeCRRtUx0YGhthS5+QJCn6VpuhwiIiIiomqNAY80SiQSKadLuBvF+/CIiIiIiN4GAx5pnHLCc96HR0RERET0VhjwSOOULXgcSZOIiIiI6K0w4JHGFbbg3YtORb5C0HA1RERERETVFwMeaZyzuT50ZBK8yM1HWEK6psshIiIiIqq2GPBI4yRiETxsDACwmyYRERER0dtgwKMqoXA+vKAoDrRCRERERFReDHhUJXjbFgY8tuAREREREZUXAx5VCZ62BQOt3I1OgSBwoBUiIiIiovJgwKMqoZ6VAWQSEVKz8hD5/IWmyyEiIiIiqpYY8KhKkEvFqG9dMNAK78MjIiIiIiofBjyqMrxsOOE5EREREdHbYMCjKqNwwvOgaLbgERERERGVBwMeVRledhxJk4iIiIjobTDgUZXhYW0IsQhISM/Gs9QsTZdDRERERFTtMOBRlaEjl8DFQh8Au2kSEREREZUHAx5VKd7spklEREREVG4MeFSleL0y4TkREREREamGAY+qFC9btuAREREREZUXAx5VKZ4vW/Cikl/geUaOhqshIiIiIqpeGPCoSjHSkcHBVBcAcC+GrXhERERERKpgwKMqRznheRTvwyMiIiIiUgUDHlU5yvvwotmCR0RERESkCgY8qnIKR9IMikqBIAgaroaIiIiIqPpgwKMqp2EdY0jFIoQlZGD71aeaLoeIiIiIqNpgwKMqx1RPjimd6wEAZu29i3vsqklEREREVCYMeFQlfRzggvb1LZCdp8Anv11DalaupksiIiIiIqryGPCoShKLRfh+kA/sjHUQnpiJz/+4zfvxiIiIiIjegAGPqiwTPTlWDm8CmUSEg0Gx2HAuXNMlERERERFVaQx4VKX52Bvjyx4eAIBv/rqPaxHPNVwREREREVHVxYBHVd7o1k7o2cAGeQoBE7ZcR1JGjqZLIiIiIiKqkhjwqMoTiUT4dmADOJvrISYlC5O33YRCwfvxiIiIiIj+jQGPqgUDbRl+HN4EWlIxTofEY+XJh5ouiYiIiIioymHAo2rDw8YQ8/p5AwCWHAvBuYcJGq6IiIiIiKhqYcCjamVQM3sMalYHCgH4dOsNxKVmabokIiIiIqIqgwGPqp2v+3rD3doACek5mLjlBvLyFZouiYiIiIioSmDAo2pHWybBqhFNoa8lxeXwJCw6EqzpkoiIiIiIqgQGPKqWnM318H/vNAQArDn1GEfvxWm4IiIiIiIizWPAo2qrRwMbjGntBACYuv0mniZlarYgIiIiIiINY8Cjau2LHh7wsTdGalYePvntOrLz8jVdEhERERGRxjDgUbUml4qxcngTGOvKcCcqBfMO3NN0SUREREREGsOAR9WenbEOlgz2AQD8evEJ9t6M0mxBREREREQawoBHNUL7+paY0N4VADBz1x1EJGZouCIiIiIiosrHgEc1xpTO9dDC2RSZOfkI3H4L+QpB0yUREREREVUqBjyqMSRiEb4f1Aj6WlJci3iO1aceabokIiIiIqJKxYBHNUodE13M7u0JAFhyNARBUSkaroiIiIiIqPIw4FGN807TOujqZYU8hYAp224iK5dTJxARERFR7cCARzWOSCTCgv4NYK6vhdBn6fjucLCmSyIiIiIiqhQMeFQjmelrYeHABgCAn86G4fyjBA1XRERERESkfgx4VGN19LDC0Bb2AIBp228hNStXwxUREREREakXAx7VaF/19ISDqS6iU7IwZ99dTZdDRERERKRWDHhUo+lpSbFkcCOIRcCu61E4eCdG0yUREREREakNAx7VeE0dTfGfABcAwBe77+BZapaGKyIiIiIiUg8GPKoVJneqB08bQzzPzMXnO29DEARNl0REREREVOEY8KhWkEvFWDrEB3KpGCeD47Hl8hNNl0REREREVOEY8KjWqGdlgOld6wMA5h+4j/CEDA1XRERERERUsRjwqFZ5r40zWtU1w4vcfARuv4m8fIWmSyIiIiIiqjAMeFSriMUifDeoEQy0pLj+JBmrTz3SdElERERERBWGAY9qHTtjHczt6wUAWHosFEFRKRquiIiIiIioYjDgUa3Uv7EduntbI08hYMq2m8jKzdd0SUREREREb40Bj2olkUiE//VvAAsDLYQ+S8f/HQrWdElERERERG+NAY9qLVM9Of7vnYYAgA3nwnD+YYKGKyIiIiIiejsqB7xDhw7h7NmzyucrV66Ej48Phg0bhufPn1docUTq1r6+JYb5OgAApmy/ibOhDHlEREREVH2pHPA+++wzpKamAgDu3LmDqVOnokePHggLC0NgYGCFF0ikbl/28EBdCz3EpWZjxPpLeH/jFTyKT9d0WUREREREKlM54IWFhcHT0xMAsHPnTvTq1QsLFizAypUrcfDgwQovkEjd9LSk2PVxa4xt4wSpWITjD56h65LT+Hr/PaRk5mq6PCIiIiKiMlM54MnlcmRmZgIAjh07hi5dugAATE1NlS17RNWNsa4cs3t74fCUtujobok8hYAN58IQ8N1J/HI+HLmcEJ2IiIiIqgGVA56fnx8CAwMxb948XL58GT179gQAhISEoE6dOhVeIFFlcrHQx/oxzbH5/Raob2WA5MxczN53F92WnsbJ4GeaLo+IiIiI6LVUDngrVqyAVCrFH3/8gVWrVsHOzg4AcPDgQXTr1q3CCyTSBH83C/w5yQ/z+3nDVE+OR/EZGPvzFYzecBmhcWmaLo+IiIiIqERSVTdwcHDAgQMHii1fsmRJhRREVFVIJWKMaOmI3o1ssfLkQ/x8LgynQuJx9mEChvs6YHKnejDVk2u6TCIiIiIiJZVb8K5fv447d+4on+/duxf9+vXDF198gZycnAotjqgqMNKR4YseHjg6JQBdvayQrxCw6UIEAhadxE9nHiMnj/fnEREREVHVoHLA++ijjxASEgIAePz4MYYMGQJdXV3s2LED06dPr/ACiaoKJ3M9rBnZDL9/2BKeNoZIy8rD/D/vo/uy04hLzdJ0eUREREREqge8kJAQ+Pj4AAB27NiBtm3bYsuWLdi4cSN27txZ0fURVTmtXMywf6IfFg5sAHN9LTyKz8C0HbegUAiaLo2IiIiIajmVA54gCFAoCrqkHTt2DD169AAA2NvbIyEhoWKrI6qiJGIRBjd3wNZxLaEtE+NMaAI2X4zQdFlEREREVMupHPCaNWuG+fPnY/PmzTh16pRymoSwsDBYWVlVeIFEVZmrpT6+6OEBAFjw1308fMYRNomIiIhIc1QOeEuXLsX169cxYcIEfPnll3B1dQUA/PHHH2jdunWFF0hU1Y1s6Yi29SyQnafA5G03OegKEREREWmMytMkNGzYsMgomoUWLVoEiURSIUURVScikQiL3mmIrktPIygqFT8cD8W0rvU1XRYRERER1UIqt+AVunbtGn799Vf8+uuvuH79OrS1tSGTySqyNqJqw8pQGwv6NwAA/Pj3Q1yLSNJwRURERERUG6kc8J49e4b27dujefPmmDRpEiZNmoRmzZqhY8eOiI+PV0eNRNVCjwY2GNDYDgoBmLLtFjKy8zRdEhERERHVMioHvIkTJyI9PR13795FUlISkpKSEBQUhNTUVEyaNEkdNRJVG3P6esHOWAdPkjIx78A9TZdDRERERLWMygHv0KFD+PHHH+Hh4aFc5unpiZUrV+LgwYMVWhxRdWOoLcPiQY0gEgFbrzzF0Xtxmi6JiIiIiGoRlQOeQqEo8V47mUymnB+PqDZrWdcMH/rXBQDM2Hkb8WnZGq6IiIiIiGoLlQNehw4d8OmnnyI6Olq5LCoqClOmTEHHjh0rtDii6mpql3pwtzZAYkYOZu66DUEQNF0SEREREdUCKge8FStWIDU1FU5OTnBxcYGLiwucnZ2RmpqKH374QR01ElU7WlIJlgz2gVwixrH7z7D1ylNNl0REREREtYDK8+DZ29vj+vXrOHbsGB48eAAA8PDwQKdOnSq8OKLqzMPGENO61sOCvx5g3oF7aFXXDE7mepoui4iIiIhqMJUDHlAwsXPnzp3RuXNn5bIHDx6gT58+CAkJqbDiiKq7D/zq4sSDZ7j4OAmB229i+0etIJWUe/pJIiIiIqLXqrBvmtnZ2Xj06FFF7a7GOHDgAOrXrw83Nzf89NNPmi6HKplYLMJ37zaCgZYU158kY9XffI8QERERkfqwKUGN8vLyEBgYiBMnTuDGjRtYtGgREhMTNV0WVbI6JrqY29cLALDseChuRyZrtiAiIiIiqrEY8NTo8uXL8PLygp2dHfT19dG9e3ccOXJE02WRBvRvbIeeDWyQpxAwedtNvMjJ13RJRERERFQDaTzgzZkzByKRqMjD3d29wrcpj9OnT6N3796wtbWFSCTCnj17iq2zcuVKODk5QVtbG76+vrh8+bLytejoaNjZ2Smf29nZISoqqsLrpKpPJBJhfj9vWBpo4XF8Br49eF/TJRERERFRDVTmgGdiYgJTU9NSH/7+/uUuwsvLCzExMcrH2bNnK3Sbc+fOITc3t9jye/fuIS4urtTtMjIy0KhRI6xcubLE17dt24bAwEDMnj0b169fR6NGjdC1a1c8e/bsjfVT7WOiJ8eidxsBAH65EIFTIfEaroiIiIiIapoyj6K5dOlS9RUhlcLa2lot2ygUCowfPx5ubm7YunUrJBIJACA4OBgdOnRAYGAgpk+fXuK23bt3R/fu3Uvd9/fff48PP/wQY8eOBQCsXr0af/75JzZs2IAZM2bA1ta2SItdVFQUWrRoUer+srOzkZ2drXyempoKAMjNzS0xoFamwuNruo7qrrWzMUb62mPzpaf4bMctrBrmg4Z1jDRdllrwmiFV8ZohVfGaIVXxmiFVVLXrpax1lDngjR49utzFvEloaChsbW2hra2NVq1a4ZtvvoGDg0OFbCMWi/HXX3+hbdu2GDVqFDZv3oywsDB06NAB/fr1KzXcvUlOTg6uXbuGmTNnFjlWp06dcOHCBQBAixYtEBQUhKioKBgZGeHgwYP473//W+o+v/nmG8ydO7fY8iNHjkBXV7dcdVa0o0eParqEaq+hAFjpSBCXlo2Bay7BzVCBTnYC6hsJEIk0XV3F4zVDquI1Q6riNUOq4jVDqqgq10tmZmaZ1hMJgiCouZbXOnjwINLT01G/fn3ExMRg7ty5iIqKQlBQEAwMDCpsmydPnsDf3x+tWrXChQsX0K5dO2zcuBGiMn6jFolE2L17N/r16wfgn/vrzp8/j1atWinXmz59Ok6dOoVLly4BAPbt24dp06ZBoVBg+vTpGDduXKnHKKkFz97eHgkJCTA0NCxTneqSm5uLo0ePonPnzpDJZBqtpSaIScnCkuMPsf9WDPIUBW9BL1sDfOTvjC6eVpCIq3/S4zVDquI1Q6riNUOq4jVDqqhq10tqairMzc2RkpLy2mxQronOK9KrXSAbNmwIX19fODo6Yvv27Xj//fcrbBsHBwds3rwZAQEBqFu3LtavX1/mcPc2+vTpgz59+pRpXS0tLWhpaRVbLpPJqsRFBVStWqozB3MZlgxujGld3fHTmcfYevkp7kanYdK223Ay08VHAS4Y0MQOWlKJpkt9a7xmSFW8ZkhVvGZIVbxmSBVV5Xopaw0aH0Xz34yNjVGvXj08fPiwQreJi4vDuHHj0Lt3b2RmZmLKlClvVae5uTkkEkmxQVri4uJUvp+Qai87Yx3M7u2FczM64NOObjDSkSE8MRMzd92B/8KTWHPqEdKyqka/byIiIiKq+qpcwEtPT8ejR49gY2NTYdskJCSgY8eO8PDwwK5du3D8+HFs27YN06ZNK3edcrkcTZs2xfHjx5XLFAoFjh8/XqTLJlFZmOrJMaVzPZyf0QFf9fSAtaE2nqVl45uDD9D62xNYdPgBEtKz37wjIiIiIqrVNB7wpk2bhlOnTiE8PBznz59H//79IZFIMHToUADAihUr0LFjR5W2eZVCoUD37t3h6OiIbdu2QSqVwtPTE0ePHsXPP/+MJUuWlFpbeno6bt68iZs3bwIAwsLCcPPmTTx58gQAEBgYiHXr1uGXX37B/fv38fHHHyMjI0M5qiaRqvS0pPjAvy5OT2+P/3unIepa6CEtKw8rTz5Cm29P4L97gvA0qWw32BIRERFR7aPyPXj5+fnYuHEjjh8/jmfPnkGhUBR5/cSJEyrtLzIyEkOHDkViYiIsLCzg5+eHixcvwsLCAkBB69ujR49U2uZVYrEYCxYsgL+/P+RyuXJ5o0aNcOzYsRK3KXT16lW0b99e+TwwMBBAwYiiGzduxODBgxEfH49Zs2YhNjYWPj4+OHToEKysrFT6GRD9m1wqxqBm9ninSR0cuReHVX8/xK3IFGy+GIEtl5+gZwMbjGtbF952NXOKBSIiIiIqH5UD3qeffoqNGzeiZ8+e8Pb2fuuBSrZu3fra1+fMmYM5c+aotM2/de7cucTljRs3fu127dq1w5sGGZ0wYQImTJigUj1EZSUWi9DN2xpdvaxw4XEiVv39CGdCE7DvVjT23YqGv5s5/hPggtYuZpUyaBARERERVW0qB7ytW7di+/bt6NGjhzrqIaISiEQitHYxR2sXcwRFpWDt6cc4cDsaZ0ITcCY0Ad52hviorQu6e1tDKtF4z2siIiIi0hCVvwnK5XK4urqqoxYiKgNvOyP8MLQxTn3WHmNaO0FbJkZQVCom/n4D7Rf/jU0XwvEiJ1/TZRIRERGRBqgc8KZOnYply5a9sesiEamXvaku5vTxwvkZHTGlUz2Y6snxNOkFZu29izYLT2DZsVA8z8jRdJlEREREVIlU7qJ59uxZnDx5EgcPHoSXl1exCfd27dpVYcUR0ZuZ6snxaSc3jGtbFzuuPcW6M4/xNOkFlhwLwepTjzC4uT3e93OGvamupkslIiIiIjVTOeAZGxujf//+6qiFiN6CjlyCUa2cMKyFAw4GxWL1qUe4G52KjefDsfliBHo0sEE3L2s0dzaBpYG2psslIiIiIjVQOeD9/PPP6qiDiCqIVCJG70a26NXQBucfJWL1qYKRN/ffisb+W9EAACczXTR3MkVzZ1O0cDKFo5kuR+EkIiIiqgFUDniF4uPjERwcDACoX7/+a+eTI6LKJxKJ0MbVHG1cC0be/ONaJC6FJeFBbCrCEzMRnpiJHdciAQCWBlpo7mSKFs6maO5kivrWBpCIGfiIiIiIqhuVA15GRgYmTpyITZs2KSc5l0gkGDVqFJYvXw5dXd7nQ1TVeNsZKSdFT3mRi2sRSbgc9hxXwpNwOzIZz9Ky8eedGPx5JwYAYKAtRTNHEzR3NoWvsxmaOBizhY+IiIioGlA54AUGBuLUqVPYv38/2rRpA6Bg4JVJkyZh6tSpWLVqVYUXSUQVx0hHhg7uVujgbgUAyMrNx82nybgSloTL4Um4HvEcaVl5OBkcj5PB8QCAgU3q4Lt3GzLkEREREVVxKge8nTt34o8//kC7du2Uy3r06AEdHR0MGjSIAY+omtGWSdCyrhla1jUDAOTlK3A/Jg2XwhJxJTwJx+4/w87rkXC3NsCHbetquFoiIiIieh2V58HLzMyElZVVseWWlpbIzMyskKKISHOkEjEa1DHCB/51sWZkM8zq5QkA+ObgfZwOiddwdURERET0OioHvFatWmH27NnIyspSLnvx4gXmzp2LVq1aVWhxRKR5o1o54t2mdaAQgIm/30BEYoamSyIiIiKiUqjcRXPZsmXo2rUr6tSpg0aNGgEAbt26BW1tbRw+fLjCCyQizRKJRJjf3xuhz9Jx82kyxm26hl2ftIaeVrkH4SUiIiIiNVG5Bc/b2xuhoaH45ptv4OPjAx8fH3z77bcIDQ2Fl5eXOmokIg3TkkqwZmRTWBpoITguDVO334JCIWi6LCIiIiL6l3L9CV5XVxcffvhhRddCRFWYlaE2Vo9siiFrLuLQ3VisOPkQkzq6abosIiIiInpFmQLevn370L17d8hkMuzbt++16/bp06dCCiOiqqeJgwnm9fPC5zvv4PujIfCwMURnz+KDLhERERGRZpQp4PXr1w+xsbGwtLREv379Sl1PJBIhPz+/omojoipocHMH3I1OxaYLEZiy7Sb2jG8NV0sDTZdFRERERCjjPXgKhQKWlpbK/y7twXBHVDv8t5cnfJ1NkZ6dhw83XUPKi1xNl0REREREKMcgK5s2bUJ2dnax5Tk5Odi0aVOFFEVEVZtMIsaPw5vAzlgHYQkZ+HTrDeRz0BUiIiIijVM54I0dOxYpKSnFlqelpWHs2LEVUhQRVX1m+lpYM7IptGVi/B0cj++OBGu6JCIiIqJaT+WAJwgCRCJRseWRkZEwMjKqkKKIqHrwtjPCwoENAQCr/n6E/beiNVwRERERUe1W5mkSGjduDJFIBJFIhI4dO0Iq/WfT/Px8hIWFoVu3bmopkoiqrr4+drgXnYo1px/jsz9uwcVCH562hpoui4iIiKhWKnPAKxw98+bNm+jatSv09fWVr8nlcjg5OWHgwIEVXiARVX3Tu7njXkwqzoQm4MNNV7F/oh8M5MVb+omIiIhIvcoc8GbPng0AcHJywuDBg6Gtra22ooioepGIRVgxtAn6rDyLiMRMjP/tOtaPaqzpsoiIiIhqHZXvwRs9ejTDHREVY6Qrw7pRzaAnl+DC40R8eyhE0yURERER1ToqB7z8/Hx89913aNGiBaytrWFqalrkQUS1Vz0rAywe5AMA2HTxCQ5HipCdy/kxiYiIiCqLygFv7ty5+P777zF48GCkpKQgMDAQAwYMgFgsxpw5c9RQIhFVJ928rTGpoxsA4K+nEnRedg7brzxFXr5Cw5URERER1XwqB7zffvsN69atw9SpUyGVSjF06FD89NNPmDVrFi5evKiOGomompnSyQ0L+nnCWC4gJiUL03feRpelp/Hn7RgoOCE6ERERkdqoHPBiY2PRoEEDAIC+vr5y0vNevXrhzz//rNjqiKhaEolEeLdpHXzVOB8zu9WDia4Mj+MzMH7LdfRZeRanQuIhCBUb9LJy85HP8EhERES1nMoBr06dOoiJiQEAuLi44MiRIwCAK1euQEtLq2KrI6JqTSYG3mvjhNPT2+PTjm7Qk0sQFJWK0RsuY8jai7gW8bzc+87LV+BaxHMsOxaKd1efh/fsw+j5wxlEJb+owDMgIiIiql7KPE1Cof79++P48ePw9fXFxIkTMWLECKxfvx5PnjzBlClT1FEjEVVzBtoyTOlcD6NaOeLHvx9h88UIXApLwsBV59HJwxLTutaHu/XrJ0cXBAHhiZk4GxqPM6EJuPA4EWlZeUXWeRCbhgE/nsPPY1pwsnUiIiKqlVQOeN9++63yvwcPHgwHBwdcuHABbm5u6N27d4UWR0Q1i5m+Fv7byxPv+zlj2bFQ7Lj2FMfuP8PxB8/Qt5EtpnSuB0czPeX6zzNycO5RAs6GJuBMaEKx1jkjHRnauJqhjas5PGwMMWPnbYTEpWPQmgtYM7Ip2riaV/YpEhEREWmUygHv31q1aoVWrVpVRC1EVEvYGutg4TsNMS6gLr4/EoI/78Rgz81oHLgdg8HN7WGoI8PZ0AQERafg1Vv1ZBIRmjqawN/NAn6u5vC2M4JELFK+vuM/rfHR5qu4+DgJozdcxv+90xADmtTRwBkSERERaUaZAt6+ffvKvMM+ffqUuxgiql1cLPSxcngTfByVgv87HIzTIfH47dKTIuvUtzKAn5s5/NzM4etsCl156R9bRjoy/PJeC0zbcRv7b0UjcPstxKRk4ZN2LhCJRKVuR0RERFRTlCng9evXr8hzkUhUbAS8wi9P+fmc1JiIVONtZ4RN77XAxceJ+OV8OHRkkoJQ52oOS0NtlfalJZVg2WAf2BprY82px1h0OBjRyS8wt48XpBKVx5UiIiIiqlbK9G1HoVAoH0eOHIGPjw8OHjyI5ORkJCcn4+DBg2jSpAkOHTqk7nqJqAZrWdcMq0Y0xfeDfTCgSR2Vw10hsViEmd09MLePF0Qi4LdLT/CfX68hMyfvzRsTERERVWMq34M3efJkrF69Gn5+fsplXbt2ha6uLsaNG4f79+9XaIFEROU1urUTrAy18enWGzh2/xmGrruE9aObwVyfU7oQERFRzaRyf6VHjx7B2Ni42HIjIyOEh4dXQElERBWnm7c1tnzYEia6Mtx6moyBq84jLCFD02URERERqYXKAa958+YIDAxEXFyccllcXBw+++wztGjRokKLIyKqCE0dTbDz49awN9VBRGImBq46j+tPyj/JOhEREVFVpXLA27BhA2JiYuDg4ABXV1e4urrCwcEBUVFRWL9+vTpqJCJ6a3Ut9LHr4zZoYGeEpIwcDFt3EUfvxb15QyIiIqJqROV78FxdXXH79m0cPXoUDx48AAB4eHigU6dOHIaciKo0CwMtbB3XEhO2XMfJ4Hh8tPkq5vb1xsiWjpoujYiIiKhClGuic5FIhC5duqBLly4VXQ8RkVrpaUmxblQz/HdvEH6//BT/3ROEyKRMTO/mXmTSdCIiIqLqqEwB74cffsC4ceOgra2NH3744bXrTpo0qUIKIyJSF6lEjAX9G8DWSAeLj4ZgzenHuB2ZgmVDfWBpUL6pGYiIiIiqgjIFvCVLlmD48OHQ1tbGkiVLSl1PJBIx4BFRtSASiTCxoxsczfUwY+dtXHiciJ4/nMUPQxqjlYuZpssjIiIiKpcyBbywsLAS/5uIqLrr08gWnjaG+OS3awiJS8fwny5iapf6+DjABWJ22SQiIqJqRuVRNImIahpXS33sHe+Hd5rWgUIAFh0OxtiNV5CUkaPp0oiIiIhUUqYWvMDAwDLv8Pvvvy93MUREmqIjl+C7dxuhhbMp/rsnCKdC4tHzhzNYMawxmjqaaro8IiIiojIpU8C7ceNGmXbGaRKIqLob1MweDeyMMP6363ickIHBay5iRnd3vO/nzM84IiIiqvLKFPBOnjyp7jqIiKoMDxtD7Jvoh5m77mD/rWjM//M+LoUl4bt3GsFIV6bp8oiIiIhKxXvwiIhKoK8lxQ9DfDCvnzfkEjGO3otDrxVncCcyRdOlEREREZWqXBOdX716Fdu3b8eTJ0+Qk1N0EIJdu3ZVSGFERJomEokwsqUjfOoY45Mt1/A06QUGrjqP//bywIiWjuyySURERFWOyi14W7duRevWrXH//n3s3r0bubm5uHv3Lk6cOAEjIyN11EhEpFEN6hjhwER/dPG0Qk6+Av/dexcTf7+B9Ow8TZdGREREVITKAW/BggVYsmQJ9u/fD7lcjmXLluHBgwcYNGgQHBwc1FEjEZHGGenIsGZkU3zV0wNSsQgHbseg3aKTmPj7DWy6EI77ManIVwiaLpOIiIhqOZW7aD569Ag9e/YEAMjlcmRkZEAkEmHKlCno0KED5s6dW+FFEhFVBSKRCB/410VjBxNM3HId0SlZ2H8rGvtvRQMADLSlaOpoguZOpmjmaIJG9sbQlkk0XDURERHVJioHPBMTE6SlpQEA7OzsEBQUhAYNGiA5ORmZmZkVXiARUVXT1NEEJ6a1w/Unz3E1/DmuhCfhesRzpGXl4e/gePwdHA8AkEvEaFDHCM2cTNDc0RRNHU1goifXcPVERERUk6kc8Nq2bYujR4+iQYMGePfdd/Hpp5/ixIkTOHr0KDp27KiOGomIqhxtmQStXczR2sUcAJCXr8CD2DRcCU/C1fDnuByehPi0bFyLeI5rEc+xBo8BAG6W+ujubY1JHd0glXAgYyIiIqpYZQ54QUFB8Pb2xooVK5CVlQUA+PLLLyGTyXD+/HkMHDgQX331ldoKJSKqyqQSMbztjOBtZ4SxbZwhCAKeJr3AlfAk5eNRfAZCn6Uj9MRDGOnK8b6fs6bLJiIiohqmzAGvYcOGaN68OT744AMMGTIEACAWizFjxgy1FUdEVF2JRCI4mOnCwUwXA5vWAQAkpmfjt0tP8P3RECw5GoLeDW1gaait4UqJiIioJilz/6BTp07By8sLU6dOhY2NDUaPHo0zZ86oszYiohrFTF8LE9q7opG9MdKz87Dgr/uaLomIiIhqmDIHPH9/f2zYsAExMTFYvnw5wsPDERAQgHr16mHhwoWIjY1VZ51ERDWCWCzC/L7eEImAPTejceFRoqZLIiIiohpE5Tv89fT0MHbsWJw6dQohISF49913sXLlSjg4OKBPnz7qqJGIqEZpUMcIw30L5g2dtTcIufkKDVdERERENcVbDeHm6uqKL774Al999RUMDAzw559/VlRdREQ12rQu9WGqJ0fos3RsPBeu6XKIiIiohih3wDt9+jTGjBkDa2trfPbZZxgwYADOnTtXkbUREdVYxrpyzOjmDgBYeiwEsSlZGq6IiIiIagKVAl50dDQWLFiAevXqoV27dnj48CF++OEHREdHY926dWjZsqW66iQiqnHeaVoHjR2MkZGTj/9xwBUiIiKqAGUOeN27d4ejoyOWL1+O/v374/79+zh79izGjh0LPT09ddZIRFQjicUizOvrDbEI2H8rGucfJmi6JCIiIqrmyhzwZDIZ/vjjD0RGRmLhwoWoX7++OusiIqoVvO2MMKKlIwBg1r67yMnjgCtERERUfmUOePv27UPfvn0hkUjUWQ8RUa0ztXN9mOnJ8fBZOn4+F6bpcoiIiKgae6tRNImI6O0Z6cows4cHAGDZ8VDEpLzQcEVERERUXTHgERFVAQMa26GZowkyc/Ix/08OuEJERETlw4BHRFQFiMUifP1ywJU/b8fgbCgHXCEiIiLVMeAREVURnraGGNXKCQAwa28QsvPyNVsQERERVTsMeEREVciUzvVgrq+FxwkZWH+WA64QERGRahjwiIiqECMdGb7o4Q4AWH78IaKSOeAKERERlR0DHhFRFdO/sR2aO5ngRW4+5h+4p+lyiIiIqBphwCMiqmJEooIBVyRiEQ4GxeJUSLymSyIiIqJqggGPiKgK8rAxxOiXA67M2XeXA64QERFRmTDgERFVUZM7u8HCQAthCRn46QwHXCEiIqI3Y8AjIqqiDLVl+LKHBwBg+YlQRD7PVGn7fIWA5MwcxKS8QGpWLhQKQR1lEhERURUi1XQBRERUur4+tthy+QkuhyXhqz1BGNrCAakvcpGalffy31ykvMhF6os8pGblIvVFLtKy8pDyIhfp2XlF9iUSAfpyKfS1pTDQlsJAWwZ9rX/+20BbCoOXz/W1ZTDTl6ONiznkUv4tkIiIqLpgwCMiqsJEIhHm9fVGjx/O4O/gePwdrPqAK1KxCHkKAYIApGXnIS07DzEpZdvWwVQXU7vUQ++GthCLRSofm4iIiCoXAx4RURVX39oAX/bwwNYrT6CnJYWRjgyG2jIY6khf/isrcZmhthSGOjLIJGJk5eYjPTsPaVl5SMvKffnvP/9d8Nory7PzcC86BU+SMvHp1ptYd+YxZnTzgJ+buaZ/HERERPQaDHhERNXAe37OeM/Pudzba8sk0JZJYK6vVeZtMrLzsOFsGNacfoygqFSMWH8J/m7m+LybO7ztjMpdCxEREakPb6wgIqIS6WlJMbGjG0591g5jWjtBJhHhTGgCei0/i0+33sDTJNUGfSEiIiL1Y8AjIqLXMtPXwpw+Xjge2A59fWwBAHtvRqPD4r8xd/9dJKZna7hCIiIiKsSAR0REZeJgpotlQxrjwEQ/+LuZIzdfwM/nwhGw6G8sPx6KzJy8N++EiIiI1IoBj4iIVOJtZ4TN7/ti8/st4GVriPTsPCw+GoKARX/jt0sRyMtXaLpEIiKiWosBj4iIysXfzQL7J/hh2RAf2JvqID4tG1/uDkKXJadx6XGipssjIiKqlRjwiIio3MRiEfr62OF4YDvM6e0JUz05HidkYNhPl7DhbBgEQdB0iURERLUKAx4REb01uVSMMW2cceqzgoFY8hUCvj5wD5O33cSLnHxNl0dERFRrMOAREVGFMdCWYelgH8zu7QmJWIS9N6PR/8dzeJLIKRWIiIgqAwMeERFVKJFIhLFtnLHlA1+Y68vxIDYNvZafwcngZ5oujYiIqMZjwCMiIrXwrWuGAxP90djBGKlZeXhv4xUsPx4KhYL35REREakLAx4REamNtZE2to5rieG+DhAEYPHREIzbfA2pWbmaLo2IiKhGYsAjIiK10pJK8L/+DfB/AxtCLhXj2P049F1xDiFxaZoujYiIqMZhwCMiokoxqLk9/vhPK9gaaSMsIQP9Vp7Dn7djNF0WERFRjcKAR0RElaZhHWPsn+iH1i5myMzJx/gt1/HNwfvIy1doujQiIqIagQGPiIgqlZm+Fja91wIfta0LAFhz6jFG/3wZSRk5Gq6MiIio+mPAIyKiSieViDGzhwdWDmsCXbkE5x4mov+qiwhJEWm6NCIiomqNAY+IiDSmZ0Mb7BnfBs7meohOycLKexKM3HAFl8OSNF0aERFRtcSAR0REGlXPygB7J7TBSF97SEQCLoY9x6A1FzBy/SVci3iu6fKIiIiqFammCyAiIjLUlmFWLw+45IYhWOKEP65H4UxoAs6EJqBdfQtM6VQPjeyNNV0mERFRlccWPCIiqjJMtICv+3jixNR2GNLcHhKxCH8Hx6PvynP44JcrCIpK0XSJREREVRoDHhERVTn2prr4dmBDnJgagIFN6kAsAo7df4Zey8/io81XcT8mVdMlEhERVUnsoklERFWWo5keFg9qhPHtXfDD8VDsvRWNw3fjcPhuHHo2sMGnndxQz8rgtfsQBAHp2XlIzsxFcmYunmfm4HlmDtKy8uDnag4nc71KOhsiIiL1Y8AjIqIqr66FPpYOaYwJHVyx9Fgo/rwTgz/vxOCvoBj0amgLDxuDgvCWkYPkF7lIzszB88yCf5Mzc5GnEErcr65cgk3vtUAzJ9NKPiMiIiL1YMAjIqJqw9XSACuGNcGE2FQsOxaKg0Gx2H8rGvtvvXlbLakYJrpyGOvKYKwrw/OMXATHpWH0hsvY9L4vmjqaqP8EiIiI1IwBT80OHDiAqVOnQqFQ4PPPP8cHH3yg6ZKIiKo9d2tDrBrRFHejU/DrxSfIzVfARFcG45cBThnkdOQw0St4ri2TFNnHi5x8jN14GRcfJ2HMhsvY/IEvfDhSJxERVXMMeGqUl5eHwMBAnDx5EkZGRmjatCn69+8PMzMzTZdGRFQjeNka4ZsBDcq1rY5cgg1jmmPMzwUTq49cfwlbPmiJBnWMKrhKIiKiysNRNNXo8uXL8PLygp2dHfT19dG9e3ccOXJE02UREdFLunIpfh7THM0cTZCWlYcR6y9xKgYiIqrWqmXAmzNnDkQiUZGHu7t7hR7j9OnT6N27N2xtbSESibBnz54S11u5ciWcnJygra0NX19fXL58WfladHQ07OzslM/t7OwQFRVVoXUSEdHb0dOSYuN7LdDEwRgpL3IxYv0l3IvmNAxERFQ9Vdsuml5eXjh27JjyuVRa+qmcO3cOLVq0gEwmK7L83r17MDMzg5WVVbFtMjIy0KhRI7z33nsYMGBAifvdtm0bAgMDsXr1avj6+mLp0qXo2rUrgoODYWlpqfI5ZWdnIzs7W/k8NbXgC0Zubi5yc3NV3l9FKjy+puug6oPXDKlKk9eMlhj4aWRjjPnlGm5HpmL4Txfx63vN3jgFA2kWP2dIVbxmSBVV7Xopax0iQRBKHju6CpszZw727NmDmzdvvnFdhUKBJk2awM3NDVu3boVEUnCTfXBwMAICAhAYGIjp06e/dh8ikQi7d+9Gv379iiz39fVF8+bNsWLFCuWx7O3tMXHiRMyYMQPnz5/HokWLsHv3bgDA5MmT0aJFCwwbNqzU85o7d26x5Vu2bIGuru4bz5WIiN5OZh7w4z0JnmaIoC8VMNErH9b8+CUioiogMzMTw4YNQ0pKCgwNDUtdr9oGvEWLFsHIyAja2tpo1aoVvvnmGzg4OJS4fnR0NNq2bQtfX19s3rwZYWFhaNu2LXr37o3Vq1e/8XglBbycnBzo6urijz/+KLJ89OjRSE5Oxt69e5GXlwcPDw/8/fffykFWzp8/X+ogKyW14Nnb2yMhIeG1v8TKkJubi6NHj6Jz587FWkKJSsJrhlRVVa6Z5MxcjN54Ffdi0mCuL8ev7zWHi8XbTYaelpWLw/eeIS0rD+7W+nC3NoCJrryCKq69qso1Q9UHrxlSRVW7XlJTU2Fubv7GgFctu2j6+vpi48aNqF+/PmJiYjB37lz4+/sjKCgIBgbFu9PY2trixIkT8Pf3x7Bhw3DhwgV06tQJq1atKncNCQkJyM/PL9a908rKCg8ePABQ0G108eLFaN++PRQKBaZPn/7aETS1tLSgpaVVbLlMJqsSFxVQtWqh6oHXDKlK09eMhZEMv33QEkPXXcSD2DSM+vkqtn3UCs7mqoU8hULApbAk7Lj6FH8FxSArV1HkdRsjbXjaGMLT1hAeNobwtDGEg6kuxGJRRZ5OraDpa4aqH14zpIqqcr2UtYZqGfC6d++u/O+GDRvC19cXjo6O2L59O95///0St3FwcMDmzZsREBCAunXrYv369RCJ1P8/0T59+qBPnz5qPw4REVUcEz05fvvAF8PWXUJwXBqGrr2IbR+1hKPZm0NedPIL7LwWiR3XIvEkKVO53NVSH3XN9fAgNg1PkjIRk5KFmJQsHH/wTLmOnlwCD5uXgc+2IPTVtzYoNocfERFRaaplwPs3Y2Nj1KtXDw8fPix1nbi4OIwbNw69e/fGlStXMGXKFCxfvrzcxzQ3N4dEIkFcXFyx41hbW5d7v0REVDWY6Wvhtw99MXTtRYQ+S38Z8lrB3rT4TXnZefk4ei8O269G4kxoPApvftDXkqJ3I1sMalYHPvbGyj8spmbl4kFMGu7HpOJedCruxaQiOC4NGTn5uBrxHFcjniv3LRYBvs5mWDbUB5YG2pVy7kREVH3ViICXnp6OR48eYeTIkSW+npCQgI4dO8LDwwM7duxASEgI2rVrBy0tLXz33XflOqZcLkfTpk1x/Phx5T14CoUCx48fx4QJE8p7KkREVIWY62thy4ctMWTtBTyKz8DQdRexdVxL1DEpCHl3o1Ow42ok9tyMQnLmP6ObtaxrikHN7NHN2xq68uL/qzXUlqGFsylaOJsql+XlK/A4IQP3olMLgt/L8JeYkYMLjxMxdO1F/P5hS1gaMuQREVHpqmXAmzZtGnr37g1HR0dER0dj9uzZkEgkGDp0aLF1FQoFunfvDkdHR2zbtg1SqRSenp44evQoOnToADs7O0yZMqXYdunp6UVaBMPCwnDz5k2YmpoqB3MJDAzE6NGj0axZM7Ro0QJLly5FRkYGxo4dq76TJyKiSmVhoIXfP2yJIWsv4nFCQcgb3coJu29E4e4r8+XZGGnjnaZ18E7TOmXqyvlvUokY9awMUM/KAP0aF8yhKggCQp+lY/SGy3gUn4Eh6y5iK0MeERG9RrUMeJGRkRg6dCgSExNhYWEBPz8/XLx4ERYWFsXWFYvFWLBgAfz9/SGX/zNiWaNGjXDs2LEStwGAq1evon379srngYGBAApGydy4cSMAYPDgwYiPj8esWbMQGxsLHx8fHDp0qMR59YiIqPqyNNTGlg9bYvDaC4hIzMT8P+8DAOQSMTp7WWFQM3v4uZpDUsEDpIhEItSzMsDWcS0xdO1FPI7PwJC1F/H7uJawYsgjIqISVMuAt3XrVpXW79y5c4nLGzduXOo27dq1Q1lmkJgwYQK7ZBIR1QLWRtr4/cOW+M+v1yAIwMAmdujrYwcTPfVPd+Bopoet41ph6LqCVsQhL7trWhsx5BERUVHVMuARERFpgq2xDvZN8NPIsR3MdLF1XEFX0bCEDAxZewG/j2sJGyMdjdRDRERVk1jTBRAREVHZ2JvqYttHLVHHRAfhiZkYsvYiopNfaLosIiKqQhjwiIiIqpE6Jrovp2vQQcTLkBfFkEdERC8x4BEREVUzdsY62DauFRxMdfEkKRND1l5A5PPMN29IREQ1HgMeERFRNWRrrINtH7WEo5kunia9wJC1F/E0iSGPiKi2Y8AjIiKqpmyMClrynM31EPmcIY+IiBjwiIiIqrXC6RvqmushKrkg5D1JZMgjIqqtGPCIiIiqOWsjbfw+riXqWhSGvAuISMzQdFlERKQBDHhEREQ1gJWhNrZ+2BIuFnqITsnCkLUXEZ7AkEdEVNtwonMiIqIawtJQG1vHtcKwdRcR+iwd/X48B19nU3jbGsHLzhBetkawNNCCSCTSdKlERKQmDHhEREQ1iIWBFrZ82BIj11/Cg9g0HL4bh8N345Svm+trwcvW8OXDCN52hnAw1WXoIyKqIRjwiIiIahgLAy3sndAG1yKe4150Ku5GpyIoKgWP4tORkJ6NUyHxOBUSr1zfQEsKj5ehz9vWCE0cTeBsrqfBMyAiovJiwCMiIqqBtKQStHYxR2sXc+WyFzn5eBBbEPjuRqfgbnQqHsSmIS07D5fDknA5LEm57siWjpjZwx26cn5VICKqTvipTUREVEvoyCVo7GCCxg4mymW5+Qo8fJauDH1BUSm4Ev4cmy9G4OzDBCwe1AhNXlmfiIiqNgY8IiKiWkwmEcPDxhAeNoZ4p2kdAMDZ0AR89scthCVk4J1V5zG+vSsmdnCDXMrBt4mIqjp+UhMREVERfm7mODS5Lfo3toNCAJafeIj+P55DSFyapksjIqI3YMAjIiKiYox0ZFgy2Ac/Dm8CY10Z7kanotfys/jpzGMoFIKmyyMiolIw4BEREVGpejSwwZHJbdG+vgVy8hSY/+d9DF13EU+TMjVdGhERlYABj4iIiF7L0lAbG8Y0xzcDGkBXLsGlsCR0X3YG268+hSCwNY+IqCphwCMiIqI3EolEGNrCAQc/9UczRxOkZ+dh+h+3MW7zNSSkZ2u6PCIieokBj4iIiMrM0UwP2z5qhc+7uUMmEeHovTh0XXIaR+7Garo0IiICAx4RERGpSCIW4eN2Ltg73g/u1gZIzMjBuM3XMHX7LUQlv9B0eUREtRoDHhEREZWLp60h9k5og/8EuEAkAnZej4T/whP4cNNVnAmN52ibREQawInOiYiIqNy0pBLM6O6OTh6WWHwkBBceJ+LovTgcvRcHZ3M9DPd1wLtN7WGkK9N0qUREtQJb8IiIiOitNXMyxe/jWuJYYFuMae0EAy0pwhIyMP/P+/D95hg+/+M2gqJSNF0mEVGNxxY8IiIiqjCulgaY08cLn3Wtjz03o7D5QgQexKZh29Wn2Hb1KXzsjTGqlSN6NLCBtkyi6XKJiGocBjwiIiKqcHpaUgz3dcSwFg64FvEcmy9G4K87Mbj5NBk3nyZj3oF7GNTcHiN8HWFvqqvpcomIagwGPCIiIlIbkUiEZk6maOZkiq96emL71af47WIEolOysObUY6w9/Rjt6lmgX2M7dHC3hIE279UjInobDHhERERUKSwMtDC+vSv+E+CCEw+eYfPFCJwOicfJ4IKHXCKGn5s5unlbo7OHFUz05BV27JQXubjwKBFnH8bj1tMUjGzliEHN7Cts/0REVQUDHhEREVUqiViEzp5W6OxphbCEDOy8FomDQTF4FJ+BEw+e4cSDZ5CIRWhV1wzdvK3RxcsKlgbaKh0jN1+BG0+ScTY0HmceJuDW02S8OmvDl7vvwN3aAA3rGFfsyRERaRgDHhEREWmMs7kepnWtj2ld6yM0Lg0Hg2JxMCgW92NScfZhAs4+TMB/9wahuaMpunlbo6u3NeyMdYrtRxAEPIpPx5nQBJwNTcDFx4nIyMkvsk5dCz34u5ojPDETp0LiMen3GzgwyR/6Wvw6REQ1Bz/RiIiIqEpwszKAm5UBJnV0Q3hCBg7dLQh7t54m43J4Ei6HJ+HrA/fQqI4RunnboHVdY1yNF+HUriCcf5SE2NSsIvsz1ZOjjas5/F3N4edmDtuXwTAlMxc9fjiD8MRMzNobhO8H+WjgbImI1IMBj4iIiKocJ3M9/CfABf8JcEF08gscCorFoaBYXIlIwq3IFNyKLJxTTwIgGgAgl4rRwskUfm7m8HM1h6eNIcRiUbF9G+nKsGyIDwatuYBd16Pg72aO/o3rVN7JERGpEQMeERERVWm2xjp4z88Z7/k541laFo7cjSsIe+FJsNDKR/fGzgiob4VmTiZlnluvmZMpPu1YD0uOheCr3UFo4mACRzM9NZ8JEZH6MeARERFRtWFpoI0RLR0xoqUjcnNz8ddff6FH13qQyVSfXmFCB1ece5SAy2FJmPT7Dez4T2vIpWI1VE1EVHn4KUZERES1kkQswtLBPjDSkeFWZAoWHw3WdElERG+NAY+IiIhqLVtjHSwc2BAAsObUY5wOiddwRUREb4cBj4iIiGq1bt7WGNHSAQAQuP0WEtKzNVwREVH5MeARERFRrfdVT0/Us9JHQno2pm6/BcWrs6K/hTuRKRi69iI+23ELiQyORFQJGPCIiIio1tOWSbB8aBNoScU4FRKPDefC3mp/OXkKLD4SjH4/nsOFx4nYcS0Snb4/hT03oiAIFRMeiYhKwoBHREREBKC+tQH+28sTALDw0AMERaW8YYuSBUWloM+Ks1h+4iHyFQK6eVnD3doAzzNzMXnbTYzdeAVRyS8qsnQiIiUGPCIiIqKXhvs6oKuXFXLzBUz8/QYysvPKvG1OngLfHwlG35Xn8CA2DaZ6cvw4vAlWj2yK/RP9MK1LPcglYvwdHI8u35/CL+fDK6wrKABk5eZj+5Wn6LPiLDos/hvzDtzDpceJyK/AYxBR1cd58IiIiIheEolEWDiwIW5HnkFYQgZm77uL795t9MbtgqJSMG3HLTyITQMA9Gxgg6/7esFMXwsAIJOIMaGDG7p522DGztu4GvEcs/fdxb5b0Vg4sAFcLQ3KXfOztCz8evEJfrsYgcSMHOXyx/FhWH82DKZ6cnR0t0QXL2v4uZpDR162yeCJqHpiwCMiIiJ6hbGuHEsH+2Douov441ok/N3M0dfHrsR1c/IUWHHyIX48+RB5CgGmenLM6+uNng1tSlzf1VIf2z9qhd8uReDbgw9wLeI5eiw7iwkdXPGfABeVJloPikrBhnNh2H8rGrn5Ba10tkbaGN3aCQ6mujh6Pw7H7z9DUkYOdlyLxI5rkdCWidHWzQJdvKzR0d0SJnpy1X9ARFSlMeARERER/YtvXTNM7OCGZcdD8eXuIDS2N4GDmW6Rde5Gp2Dajtu4H5MKAOjRwBpf9/WG+ctWu9KIxSKMbOWEDh5W+Gr3HZwMjsf3R0Pw150YfDuwIXzsjUvdNl8h4Nj9OGw4G4ZLYUnK5U0cjPGenzO6eVlDKikIid0b2CAvX4HL4Uk4ei8OR+7GISr5BY7ci8ORe3EQi4DmTqbo4mWNLp5WsDfVLe2wRFSNMOARERERlWBiB1ecf5SAK+HPMXHrDfzxn1aQScQlttp93dcLvRraqrR/O2MdbBjTHPtuRWPu/nt4EJuGAT+ew9g2zpjapR505f98TUvLysX2q5HYeD4MT5MKBmiRikXo0cAGY9s4obGDSYnHkErEaO1ijtYu5pjVyxP3YlJx5G4cjt6Lw72YVFwKS8KlsCTMO3AP7tYGeKdpHbzXxhlisaj8Pzgi0igGPCIiIqISSCViLB3SGN2Xnsatp8n4/mgIejW0KdJq193bGvP6vbnVrjQikQh9fezg72aBr/ffxZ6b0Vh/NgxH7sXim/4N4WCqi43nw7H96lOkvxzwxUhHhmG+DhjVyhE2RjoqHcvL1ghetkaY0rkeniZlFrTs3YvFlfDneBCbhvl/3kdqVh4CO9cr1/kQkeYx4BERERGVws5YBwsHNsTHv13H6lOPsO70Y+QpBJjoyvB1X2/0amgDkejtW7tM9eRYOqQx+ja2w5e77uBp0guMWH8JIhFQOG2ei4Ue3vNzxoDGdSpkoBR7U1285+eM9/yc8TwjB1suP8Giw8H44Xgo6lsZlHofIRFVbZwmgYiIiOg1ujewwdAWDhAEIO/lvHZHpgSgdyPbCgl3r2pf3xJHAgMwupWjMty1rWeBjWOb4+iUAAz3dVTLKJgmenKMb++K9/2cAQBTd9ws9zyARKRZbMEjIiIieoPZvT1hbaiN+tb66OplXeHB7lX6WlLM7euNES0dIZWI4Wyup7Zj/dvM7u4IfZaO0yHxGLfpKvZO8IOFQfm6nxKRZrAFj4iIiOgNtGUSfNqpYB47dYa7V7lZGVRquAMK7jtcPrQx6prrITolC//59Rqy8/IrtQYiejsMeERERESkZKQjw7rRzWCgLcW1iOf4ancQhMIbAYmoymPAIyIiIqIiXCz0sWJYE4hFwI5rkdhwLlzTJRFRGTHgEREREVExAfUs8EUPDwDA//68h9Mh8RquiIjKggGPiIiIiEr0vp8z3mlaBwoBmLDlOh7Hp2u6JHqN25HJuPU0GfkKdqmtzTiKJhERERGVSCQS4X/9vRGWkIFrEc/xwaar2P1JGxjpyDRdGr1CEAQsOx6KpcdCAQCG2lK0cjGDn6s52riaw9lcr9IGByLNY8AjIiIiolJpSSVYPaIp+qw4i8fxGZj0+w1sGNMcEvHbBYbo5Bd4EJuK+taGsDXSZgApp6zcfMzYeRt7bkYDAPTkEqRm5eHw3TgcvhsHALA10kYbV3P4uZmjtYs5p76o4RjwiIiIiOi1LAy0sG5UM7yz+jxOhcTj24P38WVPT5X3IwgCLjxKxC8XwnH0XhwKexJaGWqhiYNJwcPRGF62RtCWVfyE7jVNYno2xm2+hmsRzyEVizCvnzfebVoHQdGpOPcwAWdDE3At4jmiU7Kw41okdlyLBAC4Wxugjas52riaoYWzGfS1GAlqEv42iYiIiOiNvO2MsPhdH4zfch3rzoShvrUh3mlap0zbpmfnYdf1SGy6EIGHz/65j8/JTBdPn79AXGo2DgbF4mBQLABAJhHBy9ZIGfiaOJjA1lhHLedVXYXGpeG9X67gadILGGhLsXpEU7RxNQcA+Ngbw8feGOPbu+JFTj6uhCfh3KMEnHuYgLvRqXgQm4YHsWlYfzYMUrEIjR2M0buRLYb7Or51yyxpHgMeEREREZVJz4Y2CI51xQ8nHuKLXXfgbK6Hpo4mpa7/8FkaNl2IwK7rUUjPzgMA6MolGNDEDqNaOaGelQEyc/JwJzIF158k4/qT57jx5DkS0nNw82kybj5NxoZzBfuyNtRGY4eCsNfMyQQ+9sa1tlvn2dAEfPzbNaRl5cHBVBcbxjSHq6V+ievqyCVoW88CbetZAACSMnJw4VEizj4sCHxPkjJxJfw5roQ/x4FbMVg8qBHsTXUr83SogjHgEREREVGZTe5UD8FxaTh8Nw4fbb6GfRPaFGldy8tX4Nj9Z9h0IRznHyUql9e10MOolo4Y0LQODLX/GaRFVy6Fb10z+NY1A1DQjfNp0gtcf/Jc+bgfk4bY1KwirXyt6pphbl8v1LMyqKQzrxp+uxSBWXvvIl8hoLmTCdaMbAZTPXmZtzfVk6NnQxv0bGgDAHialInDd2Ox5GgILocnoceyM5jb1wv9G9vV2gBd3THgEREREVGZicUifD/IBwNXnceD2DSM23wVOz5qjYycPGy78hS/XYxAdEpWwboioJOHFUa1ckIbV7MyBQaRSAQHM104mOmiX2M7ACjWync6JB4XHieix7IzGNvGCZ92qlfj7yPLVwj45q/7+OlsGACgf2M7fDuwAbSkb3evor2pLj7wr4suntaYsv0mrkU8R+D2Wzh+/xn+198bxrplD49UNdTsdwIRERERVTg9LSnWjWqGvivPISgqFX1WnEVEYiZy8hUAClqJBje3x3BfB9Qxefvufv9u5XualImvD9zD0XtxWHcmDHtvRuPLnh7o08i2SrQ6PY5Px54bUfg7JB51THTQ1csaHdwtYaBdvuklMrLz8OnWmzh2v2BUzKmd62FCB9cKPVcHM11sG9cSq089wtJjofjzTgyuRiThu3cbwd/NosKOQ+rHgEdEREREKrM31cWq4U0w/KdLCH05cEoje2OMaumIng1t1DoKpr2pLtaNaoaTD55hzv67iEjMxKdbb2LLpSf4uq836ltXfrfNxPRsHLgdg103onDrabJy+e3IFPx1JxZyiRitXc3QzcsanTytYK5ftqkKYlJe4P2NV3EvJhVyqRiL322E3o1s1XIOUokYEzq4oW09C0zedhOP4zMwcv1ljGnthBnd3avtyKYKhYDEjJxaMz0EAx4RERERlYtvXTOsGdkUZx8moJ+PHRrZG1fq8du7W6KVixnWnX6MlX8/xKWwJPT44QxGt3LC5M5uRe71U4es3Hwcux+H3dejcCokHnkv532QiEVo62aOHg1sEJ6YgUNBsXgUn4G/g+Pxd3A8xLvvoJmTKbp5WaOrtzXsShkh9E5kCt7/5QqepWXDXF+OtaOaoYlD6YPaVJSGdYzx50R/LPjrPjZfjMDG8+E49zABSwb7wNvOSO3Hr0iP4tMRuO0mbkWmoE8jW3zV0wOWhtqaLkutGPCIiIiIqNw6eliho4eVxo6vLZNgYkc39G9ih3kH7uHw3ThsOBeGfbei8WVPd/TzqdjBQhQKAZfCkrD7RiQO3olF2svRQQGgYR0j9POxQ+9GtkVaiz7r6o6HzwoGpjkUFIs7USm4HJaEy2FJ+PrAPTSwM0I3b2t09bJWjoZ5KCgWU7bdxIvcfNSz0sf60c0rdXRLHbkE8/p5o4OHJab/cRuhz9LR/8dzCOxcH+Pa1q3y0ykIgoBNFyLwzcH7yMot6Dq871Y0Tjx4hsDO9TCqlSOkErGGq1QPBjwiIiIiqvbqmOhizchmOBUSjzn77iIsIQNTtt3C75eeYm5fL3jYGL7V/kPj0rD7RhT23oxGVPIL5XI7Yx30a2yL/o3t4GpZetdQV0sDuFoaYHx7V0Q+z8SRu3E4dDcWV8OTcCcqBXeiUrDocDBcLPTQsI4x9tyMgiAAAfUssGJY43Lfv/e22te3xOHJbTFz120cvhuHhYce4OSDZ1V6OoXYlCx89sctnAlNAAD4u5njPT9nLD0WiltPk/H1gXvYcS0S8/t5v3aaj+qKAY+IiIiIaoyAehY4NNkfP50Jw4oTD3E5PAm9lp/FyJaOmNjOWblevkJAWlYukjNzkfwiFykvcpGcmfPy39xX/s1B5PMXeBCbptzWQFuKng1s0L+xHZo7mUKsYmtWHRNdvOfnjPf8nJGQno1j9wrC3rmHCXgUn4FH8RkAgFGtHDGrl6fGW5pM9eRYPaIpdlyLxNx9d3E5PAndl53B3D5eGNCkak2nsP9WNL7aE4SUF7nQkorxRQ8PjGzpCLFYhAA3C2y98hQLDz3A/ZhUDFx1HoOb2ePz7u4qTTVR1THgEREREVGNoiWVYHx7V/RrbIf5B+7hYFAsNp4Px+4bkZAqJPjvjRNIy86DIJR9n1KxCO3qW6J/Yzt09LCssAFHzPW1MKSFA4a0cEBqVi5OPniGU8HxaOFsiiEtHCrkGBVBJBJhUDN7tHQ2U06nMHXHLRy4HY0BTeqgXX0LjbUyAkBKZi7+uzcI+25FAyjoLvv9IJ8iE8CLxSIM83VAVy8rfHvwAXZci8S2q09x+F4sPu/mjsHN7FUO61URAx4RERER1Uh2xjpYNaIpzoTGY/a+u3gcnwFABOCf++b05BIY68phpCODkY4MxroFDyMdecF/68hgrCtHC2dTtbfyGGrL0NfHDn197NR6nLfx7+kUTgbH42RwvHKU0K5e1ujkYVWpI1aeDU3AtB23EJuaBYlYhPHtXTGxgytkpbR8mulrYdG7jTC4uT2+2hOEB7FpmLnrDrZdeYr5/byr3UAy/8aAR0REREQ1mr+bBQ592haXH8fj6uWL6NYhAGYGOjDSkUEurZkDbahT4XQKXbyssfN6JI7cjUNYwj+jhH4huoNmjibo4lkwcIyDmXru1XuRk4+Fhx5g4/lwAICzuR6+H9QIjcs40mgzJ1McmOiHXy5EYMnRENx8mow+Kwq68wZ2qQ/dapqUqmnZRERERERlJ5eK4etsisT7gIuFHmQyzXUnrCnqWRlgZncPzOjmjofP0nH4biwO343DnagUXAl/jivhz/G/v+7D3doAXbys0dXLCp42hhVyz97tyGRM2XZTeb/iyJaOmNnDHbpy1eKNVCLG+37O6NXQBvP/vI/9t6Lxy4UI/HknFjO6ukGqQjfeqoIBj4iIiIiIyk0kEsHNygBuVgaY0MENUckvcPRl2LscnoQHsWl4EJuGH46Hoo6JDrp4WsPPzQwmunIYvuwaa6hdttbUvHwFfvz7EX44Hoo8hQBLAy383zsN0a6+5Vudg5WhNpYPbYwhze3x371BeByfgWk7g+BqKEG95unwtKs+o20y4BERERERUYWxM9bBmDbOGNPGGc8zcnD8wTMcvhuL0yHxiHz+AhvOhWHDubBi22nLxMqw90/wkxYJgX/eicHNp8kAgJ4NbDC/nzdMKvDeyDau5jj4acEorMtPhOJhqgLrz4Vj8SAGPCIiIiIiquVM9OR4p2kdvNO0DjJz8nA6JAFH7sbiXkwq0rLykPoiVzlZfFauAlm52YhLzX7tPg20pZjX1xt9fWzVMkVD4SisPbwsMW3TKXzW2a3Cj6FODHhERERERKR2unIpunlbo5u3dZHl+QoB6Vl5SM0qmH8w9UUuUrNykfoir+B5VuGyPOjKC8KXrbGO2uutY6KDUW4KmOlX3oigFYEBj4iIiIiINEYiFsFIVwYjXRnsNV1MDcBxYYmIiIiIiGoIBjwiIiIiIqIaggGPiIiIiIiohmDAIyIiIiIiqiEY8IiIiIiIiGoIBjwiIiIiIqIaggGPiIiIiIiohmDAIyIiIiIiqiEY8IiIiIiIiGoIBjwiIiIiIqIaggGPiIiIiIiohmDAIyIiIiIiqiEY8IiIiIiIiGoIBjwiIiIiIqIaggGPiIiIiIiohmDAIyIiIiIiqiEY8IiIiIiIiGoIBjwiIiIiIqIaggGPiIiIiIiohmDAIyIiIiIiqiEY8IiIiIiIiGoIBjwiIiIiIqIaggGPiIiIiIiohmDAIyL6//buPqiqOv8D+PvC5V5gebgoylMCEoqhgV2I2910zWAjtqQcKx+YzZ4oCyeMyrQdI9sazCZzNWMdK2mqEbWCHDNHFgUfUlHkIojLqotpykNCKCiLwP3sH/46P288KK5w4cz7NfOd4Zzv55z7/epnLvPhe+/3EBEREakECzwiIiIiIiKVYIFHRERERESkEizwiIiIiIiIVIIFHhERERERkUqwwCMiIiIiIlIJFnhEREREREQqwQKPiIiIiIhIJVjgERERERERqQQLPCIiIiIiIpVggUdERERERKQSLPCIiIiIiIhUggUeERERERGRSrDAIyIiIiIiUgkWeERERERERCrBAo+IiIiIiEglWOARERERERGpBAs8IiIiIiIilWCB18c2b96MsLAwjBo1Ch9//LG9h0NERERERCqmtfcA1Ky9vR1paWnYsWMHPD09ERUVhalTp2Lo0KH2HhoREREREakQV/D6UFFREcaOHYuAgAC4ubkhISEB27Zts/ewiIiIiIhIpQZUgbdkyRJoNBrMmzevx7g333wTGo3Gpo0ZM+amj2fnzp2YMmUK/P39odFokJub2ylm1apVCA4OhrOzM0wmE4qKipS+s2fPIiAgQDkOCAjAmTNnbvo4iYiIiIiIgAFU4B04cACrV69GRETEdcWPHTsW1dXVStu9e3e3sXv27EFbW1un8xUVFaitre32uosXLyIyMhKrVq3qsn/9+vVIS0tDeno6Dh06hMjISMTHx6Ouru665kBERERERHQzDYjv4DU3NyMpKQlr1qzB22+/fV3XaLVa+Pr6XjPOarUiJSUFo0aNQnZ2NhwdHQEAlZWVuPfee5GWlob58+d3eW1CQgISEhK6vfeyZcuQnJyMJ598EgDw97//Hd999x0+/fRTLFiwAP7+/jYrdmfOnEFMTEy392ttbUVra6tyfP78eQBAQ0NDlwVqf2pra8OlS5dQX18PJycnu46FBgfmDPUWc4Z6izlDvcWcod4YaPnS1NQEABCRngNlAHj88cdl3rx5IiIyadIkSU1N7TE+PT1dXF1dxc/PT0aOHCmzZs2SH3/8sdv4M2fOyK233iqzZs2Sjo4OOX78uPj7+8tzzz133WMEIDk5Ocpxa2urODo62pz7dS6JiYkiItLW1iahoaHy008/SVNTk4wePVrOnTvX47wAsLGxsbGxsbGxsbGxddlOnz7dY91i9xW87OxsHDp0CAcOHLjua0wmE7KyshAWFobq6mosXrwYEydORHl5Odzd3TvF+/v7Y/v27Zg4cSJmzZqFvXv3Ii4uDpmZmTc87nPnzqGjowM+Pj425318fPDPf/4TwJVVxvfffx+TJ0+G1WrF/Pnze9xBc+HChUhLS1OOrVYrGhoaMHToUGg0mhse681w4cIFjBgxAqdPn4aHh4ddx0KDA3OGeos5Q73FnKHeYs5Qbwy0fBERNDU1wd/fv8c4uxZ4p0+fRmpqKvLy8uDs7Hzd1139scmIiAiYTCYEBQVhw4YNePrpp7u8JjAwEJ9//jkmTZqEkJAQfPLJJ/1SNCUmJiIxMfG6YvV6PfR6vc05g8HQB6O6cR4eHgMiwWnwYM5QbzFnqLeYM9RbzBnqjYGUL56enteMsesmK8XFxairq4PRaIRWq4VWq0VhYSFWrFgBrVaLjo6O67qPwWDA6NGjcfz48W5jamtr8eyzz2LKlCm4dOkSXnrppf9p7N7e3nB0dOy0SUttbe11fTeQiIiIiIjoZrNrgRcbG4uysjJYLBalRUdHIykpCRaLRdkQ5Vqam5tx4sQJ+Pn5ddl/7tw5xMbG4rbbbsM333yD/Px8rF+/Hq+88soNj12n0yEqKgr5+fnKOavVivz8fJjN5hu+LxERERER0Y2y60c03d3dMW7cOJtzv/vd7zB06FDl/IcffoicnBybQuqVV17BlClTEBQUhLNnzyI9PR2Ojo6YOXNmp9ewWq1ISEhAUFAQ1q9fD61Wi/DwcOTl5eHee+9FQEBAt6t5zc3NNquCVVVVsFgsGDJkCAIDA5GWlobZs2cjOjoaMTExWL58OS5evKjsqqkmer0e6enpnT5CStQd5gz1FnOGeos5Q73FnKHeGKz5ovm/HSIHjHvuuQfjx4/H8uXLAVx5qHlWVhZOnjypxMyYMQM7d+5EfX09hg0bhgkTJuCdd97Brbfe2uU98/LyMHHixE7f8yspKcGwYcNwyy23dHldQUEBJk+e3On87NmzkZWVBeBKAfree++hpqYG48ePx4oVK2AymXo/cSIiIiIiov/RgCvwiIiIiIiI6MbY9Tt4REREREREdPOwwCMiIiIiIlIJFnhEREREREQqwQKPrmnVqlUIDg6Gs7MzTCYTioqK7D0k6ic7d+7ElClT4O/vD41Gg9zcXJt+EcEbb7wBPz8/uLi4IC4uDseOHbOJaWhoQFJSEjw8PGAwGPD000+jubnZJubw4cPKRkgjRozA0qVL+3pq1AcyMjJw5513wt3dHcOHD8fDDz+MyspKm5j//Oc/SElJwdChQ+Hm5oZp06Z1ep7oqVOn8MADD8DV1RXDhw/Hq6++ivb2dpuYgoICGI1G6PV6hIaGKhtf0eCSmZmJiIgI5SHCZrMZ33//vdLPfKFrWbJkCTQaDebNm6ecY97Q1d58801oNBqbNmbMGKVflfkiRD3Izs4WnU4nn376qRw5ckSSk5PFYDBIbW2tvYdG/WDLli3yl7/8Rb755hsBIDk5OTb9S5YsEU9PT8nNzZXS0lJJTEyUkSNHSktLixJz//33S2RkpOzbt0927doloaGhMnPmTKX//Pnz4uPjI0lJSVJeXi7r1q0TFxcXWb16dX9Nk26S+Ph4Wbt2rZSXl4vFYpE//elPEhgYKM3NzUrMnDlzZMSIEZKfny8HDx6Uu+66S37/+98r/e3t7TJu3DiJi4uTkpIS2bJli3h7e8vChQuVmH//+9/i6uoqaWlpUlFRIStXrhRHR0fZunVrv86X/nebNm2S7777Tv71r39JZWWlvP766+Lk5CTl5eUiwnyhnhUVFUlwcLBERERIamqqcp55Q1dLT0+XsWPHSnV1tdJ+/vlnpV+N+cICj3oUExMjKSkpynFHR4f4+/tLRkaGHUdF9vDbAs9qtYqvr6+89957yrnGxkbR6/Wybt06ERGpqKgQAHLgwAEl5vvvvxeNRiNnzpwREZGPPvpIvLy8pLW1VYl57bXXJCwsrI9nRH2trq5OAEhhYaGIXMkPJycn2bhxoxJz9OhRASB79+4VkSt/VHBwcJCamholJjMzUzw8PJQcmT9/vowdO9bmtaZPny7x8fF9PSXqB15eXvLxxx8zX6hHTU1NMmrUKMnLy5NJkyYpBR7zhn4rPT1dIiMju+xTa77wI5rUrcuXL6O4uBhxcXHKOQcHB8TFxWHv3r12HBkNBFVVVaipqbHJD09PT5hMJiU/9u7dC4PBgOjoaCUmLi4ODg4O2L9/vxLzhz/8ATqdTomJj49HZWUlfvnll36aDfWF8+fPAwCGDBkCACguLkZbW5tNzowZMwaBgYE2OXP77bfDx8dHiYmPj8eFCxdw5MgRJebqe/waw/elwa2jowPZ2dm4ePEizGYz84V6lJKSggceeKDT/y3zhrpy7Ngx+Pv7IyQkBElJSTh16hQA9eYLCzzq1rlz59DR0WGT0ADg4+ODmpoaO42KBopfc6Cn/KipqcHw4cNt+rVaLYYMGWIT09U9rn4NGnysVivmzZuHu+++G+PGjQNw5f9Tp9PBYDDYxP42Z66VD93FXLhwAS0tLX0xHepDZWVlcHNzg16vx5w5c5CTk4Pw8HDmC3UrOzsbhw4dQkZGRqc+5g39lslkQlZWFrZu3YrMzExUVVVh4sSJaGpqUm2+aPv9FYmISPVSUlJQXl6O3bt323soNMCFhYXBYrHg/Pnz+OqrrzB79mwUFhbae1g0QJ0+fRqpqanIy8uDs7OzvYdDg0BCQoLyc0REBEwmE4KCgrBhwwa4uLjYcWR9hyt41C1vb284Ojp22kmotrYWvr6+dhoVDRS/5kBP+eHr64u6ujqb/vb2djQ0NNjEdHWPq1+DBpe5c+di8+bN2LFjB2655RblvK+vLy5fvozGxkab+N/mzLXyobsYDw8P1f6yVjOdTofQ0FBERUUhIyMDkZGR+Nvf/sZ8oS4VFxejrq4ORqMRWq0WWq0WhYWFWLFiBbRaLXx8fJg31CODwYDRo0fj+PHjqn2fYYFH3dLpdIiKikJ+fr5yzmq1Ij8/H2az2Y4jo4Fg5MiR8PX1tcmPCxcuYP/+/Up+mM1mNDY2ori4WInZvn07rFYrTCaTErNz5060tbUpMXl5eQgLC4OXl1c/zYZuBhHB3LlzkZOTg+3bt2PkyJE2/VFRUXBycrLJmcrKSpw6dcomZ8rKymz+MJCXlwcPDw+Eh4crMVff49cYvi+pg9VqRWtrK/OFuhQbG4uysjJYLBalRUdHIykpSfmZeUM9aW5uxokTJ+Dn56fe9xm7bO1Cg0Z2drbo9XrJysqSiooKefbZZ8VgMNjsJETq1dTUJCUlJVJSUiIAZNmyZVJSUiI//vijiFx5TILBYJBvv/1WDh8+LA899FCXj0m44447ZP/+/bJ7924ZNWqUzWMSGhsbxcfHR/785z9LeXm5ZGdni6urKx+TMAg9//zz4unpKQUFBTbbUV+6dEmJmTNnjgQGBsr27dvl4MGDYjabxWw2K/2/bkd93333icVika1bt8qwYcO63I761VdflaNHj8qqVau4ffkgtWDBAiksLJSqqio5fPiwLFiwQDQajWzbtk1EmC90fa7eRVOEeUO2Xn75ZSkoKJCqqirZs2ePxMXFibe3t9TV1YmIOvOFBR5d08qVKyUwMFB0Op3ExMTIvn377D0k6ic7duwQAJ3a7NmzReTKoxIWLVokPj4+otfrJTY2ViorK23uUV9fLzNnzhQ3Nzfx8PCQJ598UpqammxiSktLZcKECaLX6yUgIECWLFnSX1Okm6irXAEga9euVWJaWlrkhRdeEC8vL3F1dZWpU6dKdXW1zX1OnjwpCQkJ4uLiIt7e3vLyyy9LW1ubTcyOHTtk/PjxotPpJCQkxOY1aPB46qmnJCgoSHQ6nQwbNkxiY2OV4k6E+ULX57cFHvOGrjZ9+nTx8/MTnU4nAQEBMn36dDl+/LjSr8Z80YiI2GftkIiIiIiIiG4mfgePiIiIiIhIJVjgERERERERqQQLPCIiIiIiIpVggUdERERERKQSLPCIiIiIiIhUggUeERERERGRSrDAIyIiIiIiUgkWeERERERERCrBAo+IiIiIiEglWOARERH1oZ9//hnPP/88AgMDodfr4evri/j4eOzZswcAoNFokJuba99BEhGRamjtPQAiIiI1mzZtGi5fvozPPvsMISEhqK2tRX5+Purr6+09NCIiUiGu4BEREfWRxsZG7Nq1C++++y4mT56MoKAgxMTEYOHChUhMTERwcDAAYOrUqdBoNMoxAHz77bcwGo1wdnZGSEgIFi9ejPb2dqVfo9EgMzMTCQkJcHFxQUhICL766iul//Lly5g7dy78/Pzg7OyMoKAgZGRk9NfUiYjITljgERER9RE3Nze4ubkhNzcXra2tnfoPHDgAAFi7di2qq6uV4127duHxxx9HamoqKioqsHr1amRlZeGdd96xuX7RokWYNm0aSktLkZSUhBkzZuDo0aMAgBUrVmDTpk3YsGEDKisr8eWXX9oUkEREpE4aERF7D4KIiEitvv76ayQnJ6OlpQVGoxGTJk3CjBkzEBERAeDKSlxOTg4efvhh5Zq4uDjExsZi4cKFyrkvvvgC8+fPx9mzZ5Xr5syZg8zMTCXmrrvugtFoxEcffYQXX3wRR44cwT/+8Q9oNJr+mSwREdkdV/CIiIj60LRp03D27Fls2rQJ999/PwoKCmA0GpGVldXtNaWlpXjrrbeUFUA3NzckJyejuroaly5dUuLMZrPNdWazWVnBe+KJJ2CxWBAWFoYXX3wR27Zt65P5ERHRwMICj4iIqI85Ozvjj3/8IxYtWoQffvgBTzzxBNLT07uNb25uxuLFi2GxWJRWVlaGY8eOwdnZ+bpe02g0oqqqCn/961/R0tKCxx57DI888sjNmhIREQ1QLPCIiIj6WXh4OC5evAgAcHJyQkdHh02/0WhEZWUlQkNDOzUHh///1b1v3z6b6/bt24fbbrtNOfbw8MD06dOxZs0arF+/Hl9//TUaGhr6cGZERGRvfEwCERFRH6mvr8ejjz6Kp556ChEREXB3d8fBgwexdOlSPPTQQwCA4OBg5Ofn4+6774Zer4eXlxfeeOMNPPjggwgMDMQjjzwCBwcHlJaWory8HG+//bZy/40bNyI6OhoTJkzAl19+iaKiInzyyScAgGXLlsHPzw933HEHHBwcsHHjRvj6+sJgMNjjn4KIiPoJCzwiIqI+4ubmBpPJhA8++AAnTpxAW1sbRowYgeTkZLz++usAgPfffx9paWlYs2YNAgICcPLkScTHx2Pz5s1466238O6778LJyQljxozBM888Y3P/xYsXIzs7Gy+88AL8/Pywbt06hIeHAwDc3d2xdOlSHDt2DI6OjrjzzjuxZcsWmxVAIiJSH+6iSURENAh1tfsmERER/4xHRERERESkEizwiIiIiIiIVILfwSMiIhqE+A0LIiLqClfwiIiIiIiIVIIFHhERERERkUqwwCMiIiIiIlIJFnhEREREREQqwQKPiIiIiIhIJVjgERERERERqQQLPCIiIiIiIpVggUdERERERKQS/wWdIXz7qFEz/wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x, y)\n",
    "plt.yscale('log')\n",
    "# plt.ticklabel_format(scilimits=(-5,8))\n",
    "plt.ylim([4.75, 6.25])\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.yticks([4.5, 5, 5.5, 6, 6.5])\n",
    "plt.title('BUS nGPT vs. Standard nGPT Model Performance')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 22:35:49.166974: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732941349.185029  202481 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732941349.190484  202481 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-29 22:35:49.208146: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments, EvalPrediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('stanfordnlp/snli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = BertTokenizerFast.from_pretrained('google-bert/bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tok(examples[\"premise\"] + examples['hypothesis'] , padding=False, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_acc(eval: EvalPrediction):\n",
    "    return {\n",
    "        'accuracy' : (np.argmax(\n",
    "            eval.predictions,\n",
    "            axis=1) == eval.label_ids).astype(\n",
    "            np.float32).mean().item()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tok = dataset.map(tokenize_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_func(example):\n",
    "    return {'label': example['label']} if example['label'] >= 0 else {'label':-example['label']}\n",
    "\n",
    "test_tok = test_tok.map(abs_func, batched=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([183416, 183549, 183187]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(test_tok['train']['label'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_202481/1794072402.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load('101M-512-std-model-512con.pt')\n",
      "/home/brian/Desktop/school/extra/transformer_pretrain/transfer_transformers/NLP/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_202481/1794072402.py:16: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('101M-512-std-model-512con.pt')\n",
    "model.to('cuda')\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "\toutput_dir=\"output\", \n",
    "\tevaluation_strategy=\"steps\", \n",
    "\tnum_train_epochs = 2,\n",
    "\twarmup_steps = 10,\n",
    "\tlogging_steps = 2000,\n",
    "\tsave_steps = 2000,\n",
    "\tload_best_model_at_end = True,\n",
    "\tlearning_rate = 5e-4,\n",
    "    per_device_train_batch_size=64\n",
    "\t)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=test_tok['train'],\n",
    "    eval_dataset=test_tok['validation'],\n",
    "    tokenizer=tok,\n",
    "    compute_metrics=compute_acc\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51c2bdfaffe743ee901ccb9a5bdaa52a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17194 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided ['label']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/school/extra/transformer_pretrain/transfer_transformers/NLP/lib/python3.10/site-packages/transformers/trainer.py:2123\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2121\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2124\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/school/extra/transformer_pretrain/transfer_transformers/NLP/lib/python3.10/site-packages/transformers/trainer.py:2427\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2425\u001b[0m update_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2426\u001b[0m num_batches \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps \u001b[38;5;28;01mif\u001b[39;00m update_step \u001b[38;5;241m!=\u001b[39m (total_updates \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m remainder\n\u001b[0;32m-> 2427\u001b[0m batch_samples, num_items_in_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_batch_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_batches\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2428\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch_samples):\n\u001b[1;32m   2429\u001b[0m     step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/school/extra/transformer_pretrain/transfer_transformers/NLP/lib/python3.10/site-packages/transformers/trainer.py:5045\u001b[0m, in \u001b[0;36mTrainer.get_batch_samples\u001b[0;34m(self, epoch_iterator, num_batches)\u001b[0m\n\u001b[1;32m   5043\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_batches):\n\u001b[1;32m   5044\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 5045\u001b[0m         batch_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m   5046\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m   5047\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/school/extra/transformer_pretrain/transfer_transformers/NLP/lib/python3.10/site-packages/accelerate/data_loader.py:552\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 552\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/school/extra/transformer_pretrain/transfer_transformers/NLP/lib/python3.10/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/Desktop/school/extra/transformer_pretrain/transfer_transformers/NLP/lib/python3.10/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/Desktop/school/extra/transformer_pretrain/transfer_transformers/NLP/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/school/extra/transformer_pretrain/transfer_transformers/NLP/lib/python3.10/site-packages/transformers/data/data_collator.py:271\u001b[0m, in \u001b[0;36mDataCollatorWithPadding.__call__\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, features: List[Dict[\u001b[38;5;28mstr\u001b[39m, Any]]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m--> 271\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[43mpad_without_fast_tokenizer_warning\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m batch:\n\u001b[1;32m    280\u001b[0m         batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/school/extra/transformer_pretrain/transfer_transformers/NLP/lib/python3.10/site-packages/transformers/data/data_collator.py:66\u001b[0m, in \u001b[0;36mpad_without_fast_tokenizer_warning\u001b[0;34m(tokenizer, *pad_args, **pad_kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mdeprecation_warnings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsking-to-pad-a-fast-tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 66\u001b[0m     padded \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpad_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpad_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# Restore the state of the warning.\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     tokenizer\u001b[38;5;241m.\u001b[39mdeprecation_warnings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsking-to-pad-a-fast-tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m warning_state\n",
      "File \u001b[0;32m~/Desktop/school/extra/transformer_pretrain/transfer_transformers/NLP/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3458\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.pad\u001b[0;34m(self, encoded_inputs, padding, max_length, pad_to_multiple_of, padding_side, return_attention_mask, return_tensors, verbose)\u001b[0m\n\u001b[1;32m   3456\u001b[0m \u001b[38;5;66;03m# The model's main input name, usually `input_ids`, has been passed for padding\u001b[39;00m\n\u001b[1;32m   3457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_input_names[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m encoded_inputs:\n\u001b[0;32m-> 3458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3459\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou should supply an encoding or a list of encodings to this method \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3460\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthat includes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_input_names[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but you provided \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(encoded_inputs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3461\u001b[0m     )\n\u001b[1;32m   3463\u001b[0m required_input \u001b[38;5;241m=\u001b[39m encoded_inputs[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_input_names[\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m   3465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m required_input \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(required_input, Sized) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(required_input) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n",
      "\u001b[0;31mValueError\u001b[0m: You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided ['label']"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'premise': 'This church choir sings to the masses as they sing joyous songs from the book at a church.',\n",
       " 'hypothesis': 'The church has cracks in the ceiling.',\n",
       " 'label': 1,\n",
       " 'input_ids': [[101,\n",
       "   2023,\n",
       "   2277,\n",
       "   6596,\n",
       "   10955,\n",
       "   2000,\n",
       "   1996,\n",
       "   11678,\n",
       "   2004,\n",
       "   2027,\n",
       "   6170,\n",
       "   6569,\n",
       "   3560,\n",
       "   2774,\n",
       "   2013,\n",
       "   1996,\n",
       "   2338,\n",
       "   2012,\n",
       "   1037,\n",
       "   2277,\n",
       "   1012,\n",
       "   1996,\n",
       "   2277,\n",
       "   2038,\n",
       "   15288,\n",
       "   1999,\n",
       "   1996,\n",
       "   5894,\n",
       "   1012,\n",
       "   102]],\n",
       " 'token_type_ids': [[0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0]],\n",
       " 'attention_mask': [[1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1]]}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tok[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_fn(x):\n",
    "    ids, lab = [], []\n",
    "    for i in x:\n",
    "        ids.append(i['input_ids'])\n",
    "        lab.append(i['label'])\n",
    "    return torch.tensor(ids), torch.tensor(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "DL = DataLoader(test_tok, batch_size=32, shuffle=True, collate_fn=col_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'premise': 'A man is celebrating his victory while smiling and shooting champagne in the air with his teammate.', 'hypothesis': 'A man is celebrating his victory while smiling and shooting champagne in the air', 'label': 0, 'input_ids': [101, 1037, 2158, 2003, 12964, 2010, 3377, 2096, 5629, 1998, 5008, 12327, 1999, 1996, 2250, 2007, 2010, 10809, 1012, 1037, 2158, 2003, 12964, 2010, 3377, 2096, 5629, 1998, 5008, 12327, 1999, 1996, 2250, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'An emergency worker directs a man pulling a sled with emergency equipment on a snowy path.', 'hypothesis': 'An emergency worker works at a crash scene.', 'label': 1, 'input_ids': [101, 2019, 5057, 7309, 23303, 1037, 2158, 4815, 1037, 22889, 2098, 2007, 5057, 3941, 2006, 1037, 20981, 4130, 1012, 2019, 5057, 7309, 2573, 2012, 1037, 5823, 3496, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'A man wearing an oxford shirt, sunglasses, and a hat smirks.', 'hypothesis': 'A man with his outfit', 'label': 0, 'input_ids': [101, 1037, 2158, 4147, 2019, 4345, 3797, 1010, 17072, 1010, 1998, 1037, 6045, 15081, 2015, 1012, 1037, 2158, 2007, 2010, 11018, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'A crowd of people shopping at a street market in an urban area with buildings and a statue in background.', 'hypothesis': 'The crowd of people are inside a mall.', 'label': 2, 'input_ids': [101, 1037, 4306, 1997, 2111, 6023, 2012, 1037, 2395, 3006, 1999, 2019, 3923, 2181, 2007, 3121, 1998, 1037, 6231, 1999, 4281, 1012, 1996, 4306, 1997, 2111, 2024, 2503, 1037, 6670, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'A female within the foreground is heading towards a large white colored pillar that is apart of a large building with people are loitering or waiting on the steps of said building.', 'hypothesis': 'There are several people outside of a building.', 'label': 0, 'input_ids': [101, 1037, 2931, 2306, 1996, 18921, 16365, 2003, 5825, 2875, 1037, 2312, 2317, 6910, 14809, 2008, 2003, 4237, 1997, 1037, 2312, 2311, 2007, 2111, 2024, 8840, 21646, 2075, 2030, 3403, 2006, 1996, 4084, 1997, 2056, 2311, 1012, 2045, 2024, 2195, 2111, 2648, 1997, 1037, 2311, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'Three children are playing on a swing in the garden.', 'hypothesis': 'Three children are playing on a blue swing set.', 'label': 1, 'input_ids': [101, 2093, 2336, 2024, 2652, 2006, 1037, 7370, 1999, 1996, 3871, 1012, 2093, 2336, 2024, 2652, 2006, 1037, 2630, 7370, 2275, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'A black dog is swimming with a ball in his mouth.', 'hypothesis': 'The dog is asleep in the grass.', 'label': 2, 'input_ids': [101, 1037, 2304, 3899, 2003, 5742, 2007, 1037, 3608, 1999, 2010, 2677, 1012, 1996, 3899, 2003, 6680, 1999, 1996, 5568, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'A woman in a spaghetti strap tank wearing a flower in her hair is staring towards the right.', 'hypothesis': 'A woman is looking at something to her right.', 'label': 0, 'input_ids': [101, 1037, 2450, 1999, 1037, 26666, 16195, 4951, 4147, 1037, 6546, 1999, 2014, 2606, 2003, 4582, 2875, 1996, 2157, 1012, 1037, 2450, 2003, 2559, 2012, 2242, 2000, 2014, 2157, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'Woman is looking something.', 'hypothesis': 'A woman is looking', 'label': 0, 'input_ids': [101, 2450, 2003, 2559, 2242, 1012, 1037, 2450, 2003, 2559, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'A dirty, shirtless homeless man sits on the sidewalk, holding his cup up to passerby asking for change.', 'hypothesis': 'A homeless man begs.', 'label': 0, 'input_ids': [101, 1037, 6530, 1010, 3797, 3238, 11573, 2158, 7719, 2006, 1996, 11996, 1010, 3173, 2010, 2452, 2039, 2000, 3413, 2121, 3762, 4851, 2005, 2689, 1012, 1037, 11573, 2158, 27591, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'A female in the middle of a vehicle is holding a camera and is pointing it towards the backseat.', 'hypothesis': 'A girl is inside a vehicle.', 'label': 0, 'input_ids': [101, 1037, 2931, 1999, 1996, 2690, 1997, 1037, 4316, 2003, 3173, 1037, 4950, 1998, 2003, 7302, 2009, 2875, 1996, 19978, 1012, 1037, 2611, 2003, 2503, 1037, 4316, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'A worker shoveling dirt into a wheelbarrow.', 'hypothesis': 'A worker uses a shovel.', 'label': 0, 'input_ids': [101, 1037, 7309, 24596, 2075, 6900, 2046, 1037, 5217, 8237, 10524, 1012, 1037, 7309, 3594, 1037, 24596, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'Two men prepare a fish at a dock.', 'hypothesis': 'Two men are cleaning their fish', 'label': 0, 'input_ids': [101, 2048, 2273, 7374, 1037, 3869, 2012, 1037, 8946, 1012, 2048, 2273, 2024, 9344, 2037, 3869, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'Two African American men laughing with aprons on, while a third man wearing a chef jacket is on a cellular phone.', 'hypothesis': 'Three African American men work together in the food industry.', 'label': 1, 'input_ids': [101, 2048, 3060, 2137, 2273, 5870, 2007, 20376, 2015, 2006, 1010, 2096, 1037, 2353, 2158, 4147, 1037, 10026, 6598, 2003, 2006, 1037, 12562, 3042, 1012, 2093, 3060, 2137, 2273, 2147, 2362, 1999, 1996, 2833, 3068, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'A young man in a backwards baseball cap balances his skateboard on the edge of the concrete.', 'hypothesis': 'The man breaks his skateboard', 'label': 2, 'input_ids': [101, 1037, 2402, 2158, 1999, 1037, 11043, 3598, 6178, 5703, 2015, 2010, 17260, 6277, 2006, 1996, 3341, 1997, 1996, 5509, 1012, 1996, 2158, 7807, 2010, 17260, 6277, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'People dressed in traditional Japanese garb walk in a procession through a courtyard paved with paving stones.', 'hypothesis': \"People dressed like circus clowns entertain at a child's birthday party.\", 'label': 2, 'input_ids': [101, 2111, 5102, 1999, 3151, 2887, 11721, 15185, 3328, 1999, 1037, 14385, 2083, 1037, 10119, 12308, 2007, 28007, 6386, 1012, 2111, 5102, 2066, 9661, 15912, 2015, 20432, 2012, 1037, 2775, 1005, 1055, 5798, 2283, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'A man in a navy blue shirt is tossing a boy with a large smile on his face high into the air.', 'hypothesis': 'A man tossing a child into the air.', 'label': 0, 'input_ids': [101, 1037, 2158, 1999, 1037, 3212, 2630, 3797, 2003, 15021, 1037, 2879, 2007, 1037, 2312, 2868, 2006, 2010, 2227, 2152, 2046, 1996, 2250, 1012, 1037, 2158, 15021, 1037, 2775, 2046, 1996, 2250, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'A man in orange and a man in a light blue top are walking down the street towards something.', 'hypothesis': 'Two men are watchin TV inside', 'label': 2, 'input_ids': [101, 1037, 2158, 1999, 4589, 1998, 1037, 2158, 1999, 1037, 2422, 2630, 2327, 2024, 3788, 2091, 1996, 2395, 2875, 2242, 1012, 2048, 2273, 2024, 3422, 2378, 2694, 2503, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'People enjoying food outside of a restaurant.', 'hypothesis': \"Some people enjoying their brunch together in the outdoor seating area of a restaurant for mother's day.\", 'label': 1, 'input_ids': [101, 2111, 9107, 2833, 2648, 1997, 1037, 4825, 1012, 2070, 2111, 9107, 2037, 7987, 4609, 2818, 2362, 1999, 1996, 7254, 10747, 2181, 1997, 1037, 4825, 2005, 2388, 1005, 1055, 2154, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'Guy in uniform standing on the side of a boat moving through the water.', 'hypothesis': 'A man in the Navy stands on a boat in the cool air.', 'label': 1, 'input_ids': [101, 3124, 1999, 6375, 3061, 2006, 1996, 2217, 1997, 1037, 4049, 3048, 2083, 1996, 2300, 1012, 1037, 2158, 1999, 1996, 3212, 4832, 2006, 1037, 4049, 1999, 1996, 4658, 2250, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': \"A man in a gray shirt and blue shorts is standing outside of an old fashioned ice cream shop named Sara's Old Fashioned Ice Cream, holding his bike up, with a wood like table, chairs, benches in front of him.\", 'hypothesis': 'A man is riding his bike', 'label': 1, 'input_ids': [101, 1037, 2158, 1999, 1037, 3897, 3797, 1998, 2630, 9132, 2003, 3061, 2648, 1997, 2019, 2214, 13405, 3256, 6949, 4497, 2315, 7354, 1005, 1055, 2214, 13405, 3256, 6949, 1010, 3173, 2010, 7997, 2039, 1010, 2007, 1037, 3536, 2066, 2795, 1010, 8397, 1010, 19571, 1999, 2392, 1997, 2032, 1012, 1037, 2158, 2003, 5559, 2010, 7997, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'A group of men in blue shirts, banded hats, and red bandannas stand in a group.', 'hypothesis': 'a bunch of eagles are eating a bug', 'label': 2, 'input_ids': [101, 1037, 2177, 1997, 2273, 1999, 2630, 11344, 1010, 25264, 16717, 1010, 1998, 2417, 24112, 9516, 2015, 3233, 1999, 1037, 2177, 1012, 1037, 9129, 1997, 8125, 2024, 5983, 1037, 11829, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'an old shoemaker in his factory', 'hypothesis': 'The shoemaker is getting ready for his 16th birthday.', 'label': 2, 'input_ids': [101, 2019, 2214, 10818, 8571, 1999, 2010, 4713, 10760, 10818, 8571, 2003, 2893, 3201, 2005, 2010, 5767, 5798, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'At least six individuals are on a team wearing helmets and knee pads while rollerblading around a skating rink.', 'hypothesis': \"People don't know how to skate.\", 'label': 2, 'input_ids': [101, 2012, 2560, 2416, 3633, 2024, 2006, 1037, 2136, 4147, 22674, 1998, 6181, 19586, 2096, 11220, 28522, 4667, 2105, 1037, 10080, 18416, 1012, 2111, 2123, 1005, 1056, 2113, 2129, 2000, 17260, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'A man is shooting a gun outdoors, on what looks like a beautiful sunny day.', 'hypothesis': 'A man is shooting a bow and arrow on a rainy day.', 'label': 2, 'input_ids': [101, 1037, 2158, 2003, 5008, 1037, 3282, 19350, 1010, 2006, 2054, 3504, 2066, 1037, 3376, 11559, 2154, 1012, 1037, 2158, 2003, 5008, 1037, 6812, 1998, 8612, 2006, 1037, 16373, 2154, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'A couple is sitting down smiling, with the woman linking arms with the man.', 'hypothesis': 'A couple is sitting down and smiling.', 'label': 0, 'input_ids': [101, 1037, 3232, 2003, 3564, 2091, 5629, 1010, 2007, 1996, 2450, 11383, 2608, 2007, 1996, 2158, 1012, 1037, 3232, 2003, 3564, 2091, 1998, 5629, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'A man with a blue helmet and orange shirt.', 'hypothesis': 'A man wears a helmet.', 'label': 0, 'input_ids': [101, 1037, 2158, 2007, 1037, 2630, 10412, 1998, 4589, 3797, 1012, 1037, 2158, 11651, 1037, 10412, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'A man and a young girl swimming.', 'hypothesis': 'a mother and son eating lunch', 'label': 2, 'input_ids': [101, 1037, 2158, 1998, 1037, 2402, 2611, 5742, 1012, 1037, 2388, 1998, 2365, 5983, 6265, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'Three men are working with their bikes in the shoulder of a road.', 'hypothesis': 'The men are driving cars.', 'label': 2, 'input_ids': [101, 2093, 2273, 2024, 2551, 2007, 2037, 18105, 1999, 1996, 3244, 1997, 1037, 2346, 1012, 1996, 2273, 2024, 4439, 3765, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'A person in blue is the only person currently throwing their ball at a bowling alley.', 'hypothesis': 'The person is eating nachos.', 'label': 2, 'input_ids': [101, 1037, 2711, 1999, 2630, 2003, 1996, 2069, 2711, 2747, 6886, 2037, 3608, 2012, 1037, 9116, 8975, 1012, 1996, 2711, 2003, 5983, 6583, 9905, 2015, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'Three children in a black dog kennel.', 'hypothesis': 'Kids are in a cage.', 'label': 1, 'input_ids': [101, 2093, 2336, 1999, 1037, 2304, 3899, 6358, 11877, 1012, 4268, 2024, 1999, 1037, 7980, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}, {'premise': 'A child and a parent or older sibling going for a hike.', 'hypothesis': \"It is the child's first time hiking.\", 'label': 1, 'input_ids': [101, 1037, 2775, 1998, 1037, 6687, 2030, 3080, 22941, 2183, 2005, 1037, 21857, 1012, 2009, 2003, 1996, 2775, 1005, 1055, 2034, 2051, 13039, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}]\n",
      "32\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m DL:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(x)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/school/extra/transformer_pretrain/transfer_transformers/NLP/lib/python3.10/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/Desktop/school/extra/transformer_pretrain/transfer_transformers/NLP/lib/python3.10/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/Desktop/school/extra/transformer_pretrain/transfer_transformers/NLP/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[51], line 4\u001b[0m, in \u001b[0;36mcol_fn\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(x)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(x))\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "for x in DL:\n",
    "    print(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = load_dataset('Salesforce/wikitext', 'wikitext-103-raw-v1')\n",
    "# data1 = load_dataset('Skylion007/openwebtext')\n",
    "data = load_dataset('bookcorpus/bookcorpus')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_bf16_supported()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 74004228\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"he 'd seen the movie almost by mistake , considering he was a little young for the pg cartoon , but with older cousins , along with her brothers , mason was often exposed to things that were older .\"}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train'].__getitem__(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data['train']\n",
    "# validation = data['validation']\n",
    "# test = data['test']\n",
    "# validation_owt = data1['train']['text'][int(0.8*len(data1['train']['text']))+1:int(0.9*len(data1['train']['text']))]\n",
    "# test_owt = data1['train']['text'][int(0.9*len(data1['train']['text']))+1:]\n",
    "# train_owt = data1['train']['text'][:int(0.8*len(data1['train']['text']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 74004228\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bos_token = \"<|BOS|>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def data_clean(input: list[str], seq_len=135) -> str:\n",
    "    ret = \"\"\n",
    "    for line in input:\n",
    "        if len(line) == 0:  continue\n",
    "        # remove @'s surrounding some characters\n",
    "        line = re.sub(r' @([.,\\-])@ ', r'\\1', line)\n",
    "        # find titles of articles and add bos_token\n",
    "        matches = re.match(r'^ = ?(.+?) =?\\n', line)    # this finds all title and subsection text\n",
    "        if matches != None:\n",
    "            c = line.count('=')\n",
    "            if c == 2:\n",
    "                # start new article\n",
    "                ret += \" \" + bos_token\n",
    "        ret += line\n",
    "\n",
    "    ret = ret.split(\" \")\n",
    "    chunks = []\n",
    "    curr_chunk = []\n",
    "    cur_len = 0\n",
    "    \n",
    "    for word in ret:\n",
    "        if cur_len > seq_len:\n",
    "            chunks.append(\" \". join(curr_chunk))\n",
    "            curr_chunk = [word]\n",
    "            cur_len = 1\n",
    "\n",
    "        else:\n",
    "            curr_chunk.append(word)\n",
    "            cur_len += 1\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_join = data_clean(train['text']) + data_clean(train_owt)\n",
    "# val_join = data_clean(validation['text']) + data_clean(validation_owt)\n",
    "# test_join = data_clean(test['text']) + data_clean(test_owt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_all(ex):\n",
    "    return tokenizer(ex['text'], truncation=False, padding=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5098ef9a19c48cc98bb99306d9d4774",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/74004228 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1119 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tok_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumn_names\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/school/extra/transformer_pretrain/transfer_transformers/NLP/lib/python3.10/site-packages/datasets/arrow_dataset.py:560\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[1;32m    555\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[1;32m    558\u001b[0m }\n\u001b[1;32m    559\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 560\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    562\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/school/extra/transformer_pretrain/transfer_transformers/NLP/lib/python3.10/site-packages/datasets/arrow_dataset.py:3055\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3050\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[1;32m   3051\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3052\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[1;32m   3053\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3054\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m-> 3055\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m rank, done, content \u001b[38;5;129;01min\u001b[39;00m Dataset\u001b[38;5;241m.\u001b[39m_map_single(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdataset_kwargs):\n\u001b[1;32m   3056\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[1;32m   3057\u001b[0m                 shards_done \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/school/extra/transformer_pretrain/transfer_transformers/NLP/lib/python3.10/site-packages/datasets/arrow_dataset.py:3458\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   3454\u001b[0m indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m   3455\u001b[0m     \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mslice\u001b[39m(i, i \u001b[38;5;241m+\u001b[39m batch_size)\u001b[38;5;241m.\u001b[39mindices(shard\u001b[38;5;241m.\u001b[39mnum_rows)))\n\u001b[1;32m   3456\u001b[0m )  \u001b[38;5;66;03m# Something simpler?\u001b[39;00m\n\u001b[1;32m   3457\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3458\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[43mapply_function_on_filtered_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3461\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_same_num_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mshard\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_indexes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3462\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3463\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3464\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NumExamplesMismatchError:\n\u001b[1;32m   3465\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetTransformationNotAllowedError(\n\u001b[1;32m   3466\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3467\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/school/extra/transformer_pretrain/transfer_transformers/NLP/lib/python3.10/site-packages/datasets/arrow_dataset.py:3320\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[0;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   3318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_rank:\n\u001b[1;32m   3319\u001b[0m     additional_args \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (rank,)\n\u001b[0;32m-> 3320\u001b[0m processed_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[1;32m   3322\u001b[0m     processed_inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   3323\u001b[0m         k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mkeys_to_format\n\u001b[1;32m   3324\u001b[0m     }\n",
      "Cell \u001b[0;32mIn[29], line 2\u001b[0m, in \u001b[0;36mtoken_all\u001b[0;34m(ex)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtoken_all\u001b[39m(ex):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mex\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/school/extra/transformer_pretrain/transfer_transformers/NLP/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3021\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   3019\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   3020\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 3021\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3022\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3023\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[0;32m~/Desktop/school/extra/transformer_pretrain/transfer_transformers/NLP/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3109\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   3104\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3105\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch length of `text`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match batch length of `text_pair`:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3106\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text_pair)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3107\u001b[0m         )\n\u001b[1;32m   3108\u001b[0m     batch_text_or_text_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(text, text_pair)) \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m text\n\u001b[0;32m-> 3109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3111\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3123\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3127\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3128\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3129\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3130\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_plus(\n\u001b[1;32m   3132\u001b[0m         text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[1;32m   3133\u001b[0m         text_pair\u001b[38;5;241m=\u001b[39mtext_pair,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3151\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3152\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/school/extra/transformer_pretrain/transfer_transformers/NLP/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3311\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   3301\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   3302\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   3303\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m   3304\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3308\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3309\u001b[0m )\n\u001b[0;32m-> 3311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3313\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3315\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3317\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3318\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3322\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3327\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3329\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3330\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3331\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/school/extra/transformer_pretrain/transfer_transformers/NLP/lib/python3.10/site-packages/transformers/models/gpt2/tokenization_gpt2_fast.py:127\u001b[0m, in \u001b[0;36mGPT2TokenizerFast._batch_encode_plus\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m is_split_into_words \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_split_into_words\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_prefix_space \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_split_into_words, (\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou need to instantiate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with add_prefix_space=True \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto use it with pretokenized inputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    125\u001b[0m )\n\u001b[0;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/school/extra/transformer_pretrain/transfer_transformers/NLP/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py:517\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens)\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_text_or_text_pairs has to be a list or a tuple (got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(batch_text_or_text_pairs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    514\u001b[0m     )\n\u001b[1;32m    516\u001b[0m \u001b[38;5;66;03m# Set the truncation and padding strategy and restore the initial configuration\u001b[39;00m\n\u001b[0;32m--> 517\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_truncation_and_padding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenizer\u001b[38;5;241m.\u001b[39mencode_special_tokens \u001b[38;5;241m!=\u001b[39m split_special_tokens:\n\u001b[1;32m    527\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenizer\u001b[38;5;241m.\u001b[39mencode_special_tokens \u001b[38;5;241m=\u001b[39m split_special_tokens\n",
      "File \u001b[0;32m~/Desktop/school/extra/transformer_pretrain/transfer_transformers/NLP/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py:450\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast.set_truncation_and_padding\u001b[0;34m(self, padding_strategy, truncation_strategy, max_length, stride, pad_to_multiple_of, padding_side)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;66;03m# Set truncation and padding on the backend tokenizer\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m truncation_strategy \u001b[38;5;241m==\u001b[39m TruncationStrategy\u001b[38;5;241m.\u001b[39mDO_NOT_TRUNCATE:\n\u001b[0;32m--> 450\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _truncation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    451\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenizer\u001b[38;5;241m.\u001b[39mno_truncation()\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tok_dataset = train.map(token_all, batched=True, remove_columns=train.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedSentenceDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, tokenized_dataset, max_length=128):\n",
    "        self.tokenized_dataset = tokenized_dataset\n",
    "        self.max_length = max_length\n",
    "        self.samples = self._create_samples()\n",
    "\n",
    "    def _create_samples(self):\n",
    "        samples = []\n",
    "        current_sample = []\n",
    "        current_length = 0\n",
    "\n",
    "        for sentence in self.tokenized_dataset[\"input_ids\"]:\n",
    "            sentence_length = len(sentence)\n",
    "\n",
    "            if current_length + sentence_length <= self.max_length:\n",
    "                current_sample.extend(sentence)\n",
    "                current_length += sentence_length\n",
    "            else:\n",
    "                if current_length > 0:\n",
    "                    # Pad the current sample if needed\n",
    "                    padding_length = self.max_length - current_length\n",
    "                    current_sample.extend([tokenizer.pad_token_id] * padding_length)\n",
    "                    samples.append(current_sample)\n",
    "\n",
    "                # Start a new sample with the current sentence\n",
    "                current_sample = sentence[:self.max_length]\n",
    "                current_length = min(sentence_length, self.max_length)\n",
    "\n",
    "            # If we've reached exactly max_length, add the sample and reset\n",
    "            if current_length == self.max_length:\n",
    "                samples.append(current_sample)\n",
    "                current_sample = []\n",
    "                current_length = 0\n",
    "\n",
    "        # Add the last sample if it's not empty\n",
    "        if current_length > 0:\n",
    "            padding_length = self.max_length - current_length\n",
    "            current_sample.extend([tokenizer.pad_token_id] * padding_length)\n",
    "            samples.append(current_sample)\n",
    "\n",
    "        return samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ids = torch.tensor(self.samples[idx])\n",
    "        attention_mask = (input_ids != tokenizer.pad_token_id).long()\n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"attention_mask\": attention_mask\n",
    "        }\n",
    "\n",
    "# Create the combined sentence dataset\n",
    "combined_dataset = CombinedSentenceDataset(tokenized_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 737084/737084 [05:41<00:00, 2156.80it/s]\n"
     ]
    }
   ],
   "source": [
    "train_tok = [tokenizer(chunk, truncation=False, return_tensors='pt')['input_ids'] for chunk in tqdm.tqdm(train)]\n",
    "# val_tok = [tokenizer(chunk, max_length=129, truncation=True, return_tensors='pt')['input_ids'] for chunk in val_join]\n",
    "# test_tok = [tokenizer(chunk, max_length=129, truncation=True, return_tensors='pt')['input_ids'] for chunk in test_join]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_tok, 'data/train_data_bookcorp.pt')\n",
    "# torch.save(val_tok, 'data/val_data_token_owt.pt')\n",
    "# torch.save(test_tok, 'data/test_data_token_owt.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "737084"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_tok)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
